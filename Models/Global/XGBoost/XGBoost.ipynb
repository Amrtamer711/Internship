{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UiR3fmx7CA4k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import ast\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from matplotlib.backends.backend_pdf import PdfPages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kHGp1xjdeuoP"
      },
      "outputs": [],
      "source": [
        "path = \"/Users/amrtamer/Documents/Internship\"\n",
        "# path = \"/content/drive/MyDrive/Internship\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "oMm8nN82aHf-",
        "outputId": "fed32d11-70a4-498e-f709-dca40ae29df9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>WELL_BORE_CODE</th>\n",
              "      <th>date</th>\n",
              "      <th>prod_hrs</th>\n",
              "      <th>bhp</th>\n",
              "      <th>bht</th>\n",
              "      <th>dp_tubing</th>\n",
              "      <th>AVG_ANNULUS_PRESS</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>whp</th>\n",
              "      <th>...</th>\n",
              "      <th>linear_regressor</th>\n",
              "      <th>EMA_short</th>\n",
              "      <th>EMA_medium</th>\n",
              "      <th>EMA_long</th>\n",
              "      <th>Rolling_short</th>\n",
              "      <th>Rolling_medium</th>\n",
              "      <th>Rolling_long</th>\n",
              "      <th>Lag_short</th>\n",
              "      <th>Lag_medium</th>\n",
              "      <th>Lag_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>1.029309</td>\n",
              "      <td>0.605973</td>\n",
              "      <td>0.396165</td>\n",
              "      <td>-2.015211</td>\n",
              "      <td>-0.533280</td>\n",
              "      <td>3.281836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.489929</td>\n",
              "      <td>-0.495877</td>\n",
              "      <td>-0.498713</td>\n",
              "      <td>-0.502834</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.845793</td>\n",
              "      <td>0.634777</td>\n",
              "      <td>0.239816</td>\n",
              "      <td>0.088574</td>\n",
              "      <td>-0.419656</td>\n",
              "      <td>2.849981</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.489929</td>\n",
              "      <td>-0.363747</td>\n",
              "      <td>-0.426301</td>\n",
              "      <td>-0.464667</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.775023</td>\n",
              "      <td>0.639809</td>\n",
              "      <td>0.199889</td>\n",
              "      <td>-0.687843</td>\n",
              "      <td>-0.402874</td>\n",
              "      <td>2.607708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.146007</td>\n",
              "      <td>-0.180982</td>\n",
              "      <td>-0.315168</td>\n",
              "      <td>-0.402787</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.09810136648612545]</td>\n",
              "      <td>[0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.705031</td>\n",
              "      <td>0.642083</td>\n",
              "      <td>0.161491</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.379061</td>\n",
              "      <td>2.364038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024781</td>\n",
              "      <td>-0.133505</td>\n",
              "      <td>-0.264997</td>\n",
              "      <td>-0.368282</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[-0.4905010756171413, -0.09810136648612545, 0....</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413, -0.09810136648...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-26</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.625355</td>\n",
              "      <td>0.643889</td>\n",
              "      <td>0.117219</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.340115</td>\n",
              "      <td>2.088747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057726</td>\n",
              "      <td>-0.077878</td>\n",
              "      <td>-0.210807</td>\n",
              "      <td>-0.330137</td>\n",
              "      <td>-0.084172</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[-0.09810136648612545, 0.18307478352672518, -0...</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.0981013664861254...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   well_name WELL_BORE_CODE        date  prod_hrs       bhp       bht  \\\n",
              "0       7405  NO 15/9-F-1 C  2014-04-22  0.268405  1.029309  0.605973   \n",
              "1       7405  NO 15/9-F-1 C  2014-04-23  0.268405  0.845793  0.634777   \n",
              "2       7405  NO 15/9-F-1 C  2014-04-24  0.268405  0.775023  0.639809   \n",
              "3       7405  NO 15/9-F-1 C  2014-04-25  0.268405  0.705031  0.642083   \n",
              "4       7405  NO 15/9-F-1 C  2014-04-26  0.268405  0.625355  0.643889   \n",
              "\n",
              "   dp_tubing  AVG_ANNULUS_PRESS  AVG_CHOKE_SIZE_P       whp  ...  \\\n",
              "0   0.396165          -2.015211         -0.533280  3.281836  ...   \n",
              "1   0.239816           0.088574         -0.419656  2.849981  ...   \n",
              "2   0.199889          -0.687843         -0.402874  2.607708  ...   \n",
              "3   0.161491           1.145565         -0.379061  2.364038  ...   \n",
              "4   0.117219           1.145565         -0.340115  2.088747  ...   \n",
              "\n",
              "   linear_regressor  EMA_short  EMA_medium  EMA_long  Rolling_short  \\\n",
              "0         -0.489929  -0.495877   -0.498713 -0.502834      -0.001433   \n",
              "1         -0.489929  -0.363747   -0.426301 -0.464667      -0.001433   \n",
              "2         -0.146007  -0.180982   -0.315168 -0.402787      -0.001433   \n",
              "3          0.024781  -0.133505   -0.264997 -0.368282      -0.001433   \n",
              "4          0.057726  -0.077878   -0.210807 -0.330137      -0.084172   \n",
              "\n",
              "   Rolling_medium Rolling_long  \\\n",
              "0         -0.0027    -0.005271   \n",
              "1         -0.0027    -0.005271   \n",
              "2         -0.0027    -0.005271   \n",
              "3         -0.0027    -0.005271   \n",
              "4         -0.0027    -0.005271   \n",
              "\n",
              "                                           Lag_short  \\\n",
              "0                                    [0.0, 0.0, 0.0]   \n",
              "1                    [0.0, 0.0, -0.4905010756171413]   \n",
              "2   [0.0, -0.4905010756171413, -0.09810136648612545]   \n",
              "3  [-0.4905010756171413, -0.09810136648612545, 0....   \n",
              "4  [-0.09810136648612545, 0.18307478352672518, -0...   \n",
              "\n",
              "                                          Lag_medium  \\\n",
              "0                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "1          [0.0, 0.0, 0.0, 0.0, -0.4905010756171413]   \n",
              "2  [0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...   \n",
              "3  [0.0, 0.0, -0.4905010756171413, -0.09810136648...   \n",
              "4  [0.0, -0.4905010756171413, -0.0981013664861254...   \n",
              "\n",
              "                                            Lag_long  \n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...  \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_pickle(path + r'/data/Volve/Volve_cleaned_prepared.pkl')\n",
        "if \"Unnamed: 0\" in data.columns:\n",
        "    data = data.drop(columns=\"Unnamed: 0\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZmGsFefnB3G",
        "outputId": "18484778-96e2-4ffa-95bf-a34702b9403d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{5769: 'NO 15/9-F-5 AH',\n",
              " 5599: 'NO 15/9-F-12 H',\n",
              " 7405: 'NO 15/9-F-1 C',\n",
              " 7078: 'NO 15/9-F-11 H',\n",
              " 5351: 'NO 15/9-F-14 H',\n",
              " 7289: 'NO 15/9-F-15 D'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "well_info = dict(set([(j, i) for i, j in data[['WELL_BORE_CODE', 'well_name']].values.tolist()])) # creating a dictionary of well identiification with {code: name} structure\n",
        "well_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KJZoa8Qneyzy"
      },
      "outputs": [],
      "source": [
        "identification_column = ['well_name', 'WELL_BORE_CODE', 'date']\n",
        "single_feature_columns = ['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']\n",
        "multiple_feature_columns = ['Lag_short', 'Lag_medium', 'Lag_long']\n",
        "feature_columns = single_feature_columns + multiple_feature_columns\n",
        "target_column = ['oil_rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr-v7jdxLqsb",
        "outputId": "73925800-f094-4b66-c1cb-9938d7309fb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7987, 26)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[identification_column + feature_columns]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prod_hrs                -0.0\n",
            "bhp                      0.0\n",
            "bht                     -0.0\n",
            "dp_tubing                0.0\n",
            "AVG_ANNULUS_PRESS        0.0\n",
            "AVG_CHOKE_SIZE_P        -0.0\n",
            "whp                     -0.0\n",
            "wht                     -0.0\n",
            "choke_size_percentage    0.0\n",
            "oil_vol                  0.0\n",
            "gas_vol                 -0.0\n",
            "water_vol                0.0\n",
            "linear_regressor         0.0\n",
            "EMA_short                0.0\n",
            "EMA_medium              -0.0\n",
            "EMA_long                 0.0\n",
            "Rolling_short            0.0\n",
            "Rolling_medium           0.0\n",
            "Rolling_long            -0.0\n",
            "oil_rate                -0.0\n",
            "dtype: float64\n",
            "prod_hrs                 1.0\n",
            "bhp                      1.0\n",
            "bht                      1.0\n",
            "dp_tubing                1.0\n",
            "AVG_ANNULUS_PRESS        1.0\n",
            "AVG_CHOKE_SIZE_P         1.0\n",
            "whp                      1.0\n",
            "wht                      1.0\n",
            "choke_size_percentage    1.0\n",
            "oil_vol                  1.0\n",
            "gas_vol                  1.0\n",
            "water_vol                1.0\n",
            "linear_regressor         1.0\n",
            "EMA_short                1.0\n",
            "EMA_medium               1.0\n",
            "EMA_long                 1.0\n",
            "Rolling_short            1.0\n",
            "Rolling_medium           1.0\n",
            "Rolling_long             1.0\n",
            "oil_rate                 1.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(data[['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']].mean().round(4))\n",
        "print(data[['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']].std().round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "58-XDpb-EO82",
        "outputId": "6ec059d5-a866-4f03-e039-26f48f023028"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>WELL_BORE_CODE</th>\n",
              "      <th>date</th>\n",
              "      <th>prod_hrs</th>\n",
              "      <th>bhp</th>\n",
              "      <th>bht</th>\n",
              "      <th>dp_tubing</th>\n",
              "      <th>AVG_ANNULUS_PRESS</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>whp</th>\n",
              "      <th>...</th>\n",
              "      <th>EMA_short</th>\n",
              "      <th>EMA_medium</th>\n",
              "      <th>EMA_long</th>\n",
              "      <th>Rolling_short</th>\n",
              "      <th>Rolling_medium</th>\n",
              "      <th>Rolling_long</th>\n",
              "      <th>oil_rate</th>\n",
              "      <th>Lag_short</th>\n",
              "      <th>Lag_medium</th>\n",
              "      <th>Lag_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>1.029309</td>\n",
              "      <td>0.605973</td>\n",
              "      <td>0.396165</td>\n",
              "      <td>-2.015211</td>\n",
              "      <td>-0.533280</td>\n",
              "      <td>3.281836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.495877</td>\n",
              "      <td>-0.498713</td>\n",
              "      <td>-0.502834</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>-0.490501</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.845793</td>\n",
              "      <td>0.634777</td>\n",
              "      <td>0.239816</td>\n",
              "      <td>0.088574</td>\n",
              "      <td>-0.419656</td>\n",
              "      <td>2.849981</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.363747</td>\n",
              "      <td>-0.426301</td>\n",
              "      <td>-0.464667</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>-0.098101</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.775023</td>\n",
              "      <td>0.639809</td>\n",
              "      <td>0.199889</td>\n",
              "      <td>-0.687843</td>\n",
              "      <td>-0.402874</td>\n",
              "      <td>2.607708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.180982</td>\n",
              "      <td>-0.315168</td>\n",
              "      <td>-0.402787</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>0.183075</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.09810136648612545]</td>\n",
              "      <td>[0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.705031</td>\n",
              "      <td>0.642083</td>\n",
              "      <td>0.161491</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.379061</td>\n",
              "      <td>2.364038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.133505</td>\n",
              "      <td>-0.264997</td>\n",
              "      <td>-0.368282</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>-0.037781</td>\n",
              "      <td>[-0.4905010756171413, -0.09810136648612545, 0....</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413, -0.09810136648...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-26</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.625355</td>\n",
              "      <td>0.643889</td>\n",
              "      <td>0.117219</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.340115</td>\n",
              "      <td>2.088747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.077878</td>\n",
              "      <td>-0.210807</td>\n",
              "      <td>-0.330137</td>\n",
              "      <td>-0.084172</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>0.033425</td>\n",
              "      <td>[-0.09810136648612545, 0.18307478352672518, -0...</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.0981013664861254...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7982</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814176</td>\n",
              "      <td>1.149547</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.140330</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.693212</td>\n",
              "      <td>-0.702888</td>\n",
              "      <td>-0.716277</td>\n",
              "      <td>-0.692951</td>\n",
              "      <td>-0.704178</td>\n",
              "      <td>-0.725482</td>\n",
              "      <td>-0.681306</td>\n",
              "      <td>[-0.6834479858098645, -0.6925870358402809, -0....</td>\n",
              "      <td>[-0.6915821804196012, -0.6860958165169114, -0....</td>\n",
              "      <td>[-0.7117159623886966, -0.7111878631895072, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7983</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814176</td>\n",
              "      <td>1.159077</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.136215</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.689899</td>\n",
              "      <td>-0.699999</td>\n",
              "      <td>-0.713993</td>\n",
              "      <td>-0.690916</td>\n",
              "      <td>-0.70061</td>\n",
              "      <td>-0.723721</td>\n",
              "      <td>-0.676011</td>\n",
              "      <td>[-0.6925870358402809, -0.6822891014560878, -0....</td>\n",
              "      <td>[-0.6860958165169114, -0.6834479858098645, -0....</td>\n",
              "      <td>[-0.7111878631895072, -0.7027822842690761, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7984</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814176</td>\n",
              "      <td>1.141368</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.137527</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.688108</td>\n",
              "      <td>-0.697863</td>\n",
              "      <td>-0.712046</td>\n",
              "      <td>-0.689665</td>\n",
              "      <td>-0.69802</td>\n",
              "      <td>-0.72149</td>\n",
              "      <td>-0.677250</td>\n",
              "      <td>[-0.6822891014560878, -0.6813062501687076, -0....</td>\n",
              "      <td>[-0.6834479858098645, -0.6925870358402809, -0....</td>\n",
              "      <td>[-0.7027822842690761, -0.695718957479918, -0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7985</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-1.334973</td>\n",
              "      <td>-1.285316</td>\n",
              "      <td>-1.327392</td>\n",
              "      <td>1.140972</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.140776</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.686771</td>\n",
              "      <td>-0.696038</td>\n",
              "      <td>-0.710244</td>\n",
              "      <td>-0.686483</td>\n",
              "      <td>-0.696104</td>\n",
              "      <td>-0.719541</td>\n",
              "      <td>-0.676825</td>\n",
              "      <td>[-0.6813062501687076, -0.6760105887546141, -0....</td>\n",
              "      <td>[-0.6925870358402809, -0.6822891014560878, -0....</td>\n",
              "      <td>[-0.695718957479918, -0.689095713356751, -0.69...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7986</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-26</td>\n",
              "      <td>-0.744073</td>\n",
              "      <td>-0.434705</td>\n",
              "      <td>-0.323038</td>\n",
              "      <td>-0.323129</td>\n",
              "      <td>1.128012</td>\n",
              "      <td>0.671086</td>\n",
              "      <td>-1.123420</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.684923</td>\n",
              "      <td>-0.69402</td>\n",
              "      <td>-0.708337</td>\n",
              "      <td>-0.684807</td>\n",
              "      <td>-0.694571</td>\n",
              "      <td>-0.717138</td>\n",
              "      <td>-0.673985</td>\n",
              "      <td>[-0.6760105887546141, -0.6772501549304891, -0....</td>\n",
              "      <td>[-0.6822891014560878, -0.6813062501687076, -0....</td>\n",
              "      <td>[-0.689095713356751, -0.6915821804196012, -0.6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7987 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      well_name  WELL_BORE_CODE        date  prod_hrs       bhp       bht  \\\n",
              "0          7405   NO 15/9-F-1 C  2014-04-22  0.268405  1.029309  0.605973   \n",
              "1          7405   NO 15/9-F-1 C  2014-04-23  0.268405  0.845793  0.634777   \n",
              "2          7405   NO 15/9-F-1 C  2014-04-24  0.268405  0.775023  0.639809   \n",
              "3          7405   NO 15/9-F-1 C  2014-04-25  0.268405  0.705031  0.642083   \n",
              "4          7405   NO 15/9-F-1 C  2014-04-26  0.268405  0.625355  0.643889   \n",
              "...         ...             ...         ...       ...       ...       ...   \n",
              "7982       5769  NO 15/9-F-5 AH  2016-08-22  0.268405 -0.880933 -0.806036   \n",
              "7983       5769  NO 15/9-F-5 AH  2016-08-23  0.268405 -0.880933 -0.806036   \n",
              "7984       5769  NO 15/9-F-5 AH  2016-08-24  0.268405 -0.880933 -0.806036   \n",
              "7985       5769  NO 15/9-F-5 AH  2016-08-25  0.268405 -1.334973 -1.285316   \n",
              "7986       5769  NO 15/9-F-5 AH  2016-08-26 -0.744073 -0.434705 -0.323038   \n",
              "\n",
              "      dp_tubing  AVG_ANNULUS_PRESS  AVG_CHOKE_SIZE_P       whp  ...  \\\n",
              "0      0.396165          -2.015211         -0.533280  3.281836  ...   \n",
              "1      0.239816           0.088574         -0.419656  2.849981  ...   \n",
              "2      0.199889          -0.687843         -0.402874  2.607708  ...   \n",
              "3      0.161491           1.145565         -0.379061  2.364038  ...   \n",
              "4      0.117219           1.145565         -0.340115  2.088747  ...   \n",
              "...         ...                ...               ...       ...  ...   \n",
              "7982  -0.814176           1.149547          1.150153 -1.140330  ...   \n",
              "7983  -0.814176           1.159077          1.150153 -1.136215  ...   \n",
              "7984  -0.814176           1.141368          1.150153 -1.137527  ...   \n",
              "7985  -1.327392           1.140972          1.150153 -1.140776  ...   \n",
              "7986  -0.323129           1.128012          0.671086 -1.123420  ...   \n",
              "\n",
              "      EMA_short  EMA_medium  EMA_long  Rolling_short  Rolling_medium  \\\n",
              "0     -0.495877   -0.498713 -0.502834      -0.001433         -0.0027   \n",
              "1     -0.363747   -0.426301 -0.464667      -0.001433         -0.0027   \n",
              "2     -0.180982   -0.315168 -0.402787      -0.001433         -0.0027   \n",
              "3     -0.133505   -0.264997 -0.368282      -0.001433         -0.0027   \n",
              "4     -0.077878   -0.210807 -0.330137      -0.084172         -0.0027   \n",
              "...         ...         ...       ...            ...             ...   \n",
              "7982  -0.693212   -0.702888 -0.716277      -0.692951       -0.704178   \n",
              "7983  -0.689899   -0.699999 -0.713993      -0.690916        -0.70061   \n",
              "7984  -0.688108   -0.697863 -0.712046      -0.689665        -0.69802   \n",
              "7985  -0.686771   -0.696038 -0.710244      -0.686483       -0.696104   \n",
              "7986  -0.684923    -0.69402 -0.708337      -0.684807       -0.694571   \n",
              "\n",
              "     Rolling_long  oil_rate  \\\n",
              "0       -0.005271 -0.490501   \n",
              "1       -0.005271 -0.098101   \n",
              "2       -0.005271  0.183075   \n",
              "3       -0.005271 -0.037781   \n",
              "4       -0.005271  0.033425   \n",
              "...           ...       ...   \n",
              "7982    -0.725482 -0.681306   \n",
              "7983    -0.723721 -0.676011   \n",
              "7984     -0.72149 -0.677250   \n",
              "7985    -0.719541 -0.676825   \n",
              "7986    -0.717138 -0.673985   \n",
              "\n",
              "                                              Lag_short  \\\n",
              "0                                       [0.0, 0.0, 0.0]   \n",
              "1                       [0.0, 0.0, -0.4905010756171413]   \n",
              "2      [0.0, -0.4905010756171413, -0.09810136648612545]   \n",
              "3     [-0.4905010756171413, -0.09810136648612545, 0....   \n",
              "4     [-0.09810136648612545, 0.18307478352672518, -0...   \n",
              "...                                                 ...   \n",
              "7982  [-0.6834479858098645, -0.6925870358402809, -0....   \n",
              "7983  [-0.6925870358402809, -0.6822891014560878, -0....   \n",
              "7984  [-0.6822891014560878, -0.6813062501687076, -0....   \n",
              "7985  [-0.6813062501687076, -0.6760105887546141, -0....   \n",
              "7986  [-0.6760105887546141, -0.6772501549304891, -0....   \n",
              "\n",
              "                                             Lag_medium  \\\n",
              "0                             [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "1             [0.0, 0.0, 0.0, 0.0, -0.4905010756171413]   \n",
              "2     [0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...   \n",
              "3     [0.0, 0.0, -0.4905010756171413, -0.09810136648...   \n",
              "4     [0.0, -0.4905010756171413, -0.0981013664861254...   \n",
              "...                                                 ...   \n",
              "7982  [-0.6915821804196012, -0.6860958165169114, -0....   \n",
              "7983  [-0.6860958165169114, -0.6834479858098645, -0....   \n",
              "7984  [-0.6834479858098645, -0.6925870358402809, -0....   \n",
              "7985  [-0.6925870358402809, -0.6822891014560878, -0....   \n",
              "7986  [-0.6822891014560878, -0.6813062501687076, -0....   \n",
              "\n",
              "                                               Lag_long  \n",
              "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...  \n",
              "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...  \n",
              "...                                                 ...  \n",
              "7982  [-0.7117159623886966, -0.7111878631895072, -0....  \n",
              "7983  [-0.7111878631895072, -0.7027822842690761, -0....  \n",
              "7984  [-0.7027822842690761, -0.695718957479918, -0.6...  \n",
              "7985  [-0.695718957479918, -0.689095713356751, -0.69...  \n",
              "7986  [-0.689095713356751, -0.6915821804196012, -0.6...  \n",
              "\n",
              "[7987 rows x 26 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in multiple_feature_columns:\n",
        "    try:\n",
        "        data[column] = data[column].apply(ast.literal_eval)\n",
        "    except Exception:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OdDuXzow20l",
        "outputId": "60546539-9373-402b-ec44-a3a87204c154"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "well_name                False\n",
              "WELL_BORE_CODE           False\n",
              "date                     False\n",
              "prod_hrs                 False\n",
              "bhp                      False\n",
              "bht                      False\n",
              "dp_tubing                False\n",
              "AVG_ANNULUS_PRESS        False\n",
              "AVG_CHOKE_SIZE_P         False\n",
              "whp                      False\n",
              "wht                      False\n",
              "choke_size_percentage    False\n",
              "oil_vol                  False\n",
              "gas_vol                  False\n",
              "water_vol                False\n",
              "linear_regressor         False\n",
              "EMA_short                False\n",
              "EMA_medium               False\n",
              "EMA_long                 False\n",
              "Rolling_short            False\n",
              "Rolling_medium           False\n",
              "Rolling_long             False\n",
              "oil_rate                 False\n",
              "Lag_short                False\n",
              "Lag_medium               False\n",
              "Lag_long                 False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the numerical index of the column 'oil_rate'\n",
        "column_name = 'oil_rate'\n",
        "column_index = data[feature_columns].columns.get_loc(column_name)\n",
        "column_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1n-IMFYvNIta"
      },
      "outputs": [],
      "source": [
        "days_window = 5\n",
        "predictions_days = 14\n",
        "training_gap = predictions_days + days_window\n",
        "batch_size = 96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "H77kZkM1lU5_",
        "outputId": "57fda9a0-8141-4450-9f89-3f4e8c43cffb"
      },
      "outputs": [],
      "source": [
        "# sequences = []\n",
        "# for well_name in data['well_name'].unique():\n",
        "#     well_data = data[data['well_name'] == well_name].sort_values(by='date').reset_index()\n",
        "#     for i in range(len(well_data) - training_gap + 1):\n",
        "#         single_features = np.array(well_data.iloc[i:i + days_window][single_feature_columns])\n",
        "#         multiple_features = np.array(well_data.iloc[i:i + days_window][multiple_feature_columns])\n",
        "#         multiple_flattened = []\n",
        "#         for k in multiple_features:\n",
        "#            flattened_list = [item for sublist in k for item in sublist]\n",
        "#            multiple_flattened.append(flattened_list)\n",
        "#         multiple_flattened = np.array(multiple_flattened)\n",
        "#         inputs = np.concatenate((single_features, multiple_flattened), axis=1)\n",
        "#         targets = well_data.iloc[i + days_window:i + days_window + predictions_days][target_column].values\n",
        "#         inputs_dates = list(well_data.iloc[i:i + days_window]['date'])\n",
        "#         targets_dates = list(well_data.iloc[i + days_window:i + days_window + predictions_days]['date'])\n",
        "#         inputs_index = list(well_data.iloc[i:i + days_window]['index'])\n",
        "#         targets_index = list(well_data.iloc[i + days_window:i + days_window + predictions_days]['index'])\n",
        "#         sequences.append((well_name, inputs_dates, targets_dates, inputs_index, targets_index, inputs, targets))\n",
        "#         if len(well_data.iloc[i:i + days_window + predictions_days]['well_name'].unique()) > 1:\n",
        "#           print('violation')\n",
        "\n",
        "# dataset = pd.DataFrame(sequences, columns=['well_name', 'inputs_dates', 'targets_dates', 'inputs_index', 'targets_index', 'inputs', 'targets', ])\n",
        "# dataset.to_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_size = 0.6\n",
        "val_size = 0.2\n",
        "test_size = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_size_param1 = test_size\n",
        "test_size_param2 = val_size / (1 - test_size_param1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_wells = []\n",
        "# test_wells = []\n",
        "# for i in well_info.keys():\n",
        "#     well = dataset[dataset['well_name'] == i]\n",
        "#     train_set_length = int((train_size + val_size) * len(well))\n",
        "#     train_wells.append(well[:train_set_length + 1])\n",
        "#     test_set_length = int(test_size * len(well))\n",
        "#     test_wells.append(well[-test_set_length:])\n",
        "\n",
        "# # Flatten the lists of DataFrames\n",
        "# temp_data = pd.concat(train_wells).reset_index(drop=True)\n",
        "# data_test = pd.concat(test_wells).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# data_train, data_val = train_test_split(temp_data, test_size=test_size_param2, stratify=temp_data['well_name'], shuffle=True)\n",
        "\n",
        "# data_train.reset_index(drop=True, inplace=True)\n",
        "# data_val.reset_index(drop=True, inplace=True)\n",
        "# data_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# data_train.to_pickle(path + \"/data/Volve/data_train.pkl\")\n",
        "# data_val.to_pickle(path + \"/data/Volve/data_val.pkl\")\n",
        "# data_test.to_pickle(path + \"/data/Volve/data_test.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data = pd.read_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "data_train = pd.read_pickle(path + \"/data/Volve/data_train.pkl\")\n",
        "data_val = pd.read_pickle(path + \"/data/Volve/data_val.pkl\")\n",
        "data_test = pd.read_pickle(path + \"/data/Volve/data_test.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4730, 7), (1577, 7), (1573, 7))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train.shape, data_val.shape, data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHPKLHzqZEG-",
        "outputId": "3162efb7-1305-47a6-eca8-396e96e41184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input/output gap is fine\n"
          ]
        }
      ],
      "source": [
        "check = True\n",
        "for i, j in well_info.items():\n",
        "    if len(all_data[all_data['well_name'] == i]) < 10:\n",
        "        print(\"The input/output gap is too high for well\", i)\n",
        "        check = False\n",
        "if check:\n",
        "    print(\"The input/output gap is fine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All datasets have all wells\n"
          ]
        }
      ],
      "source": [
        "check=True\n",
        "for i in [data_train, data_val, data_test]:\n",
        "    for j in well_info.keys():\n",
        "        if j not in set(list(i['well_name'])):\n",
        "            print(\"Some datasets do not have specific well\")\n",
        "            check = False\n",
        "            break\n",
        "if check:\n",
        "    print(\"All datasets have all wells\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5, 38), (14, 1))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train['inputs'][0].shape, data_train['targets'][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "Yc5pZXS0uaZW",
        "outputId": "df791313-0c99-46f3-a399-185479a9e287"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>inputs_dates</th>\n",
              "      <th>targets_dates</th>\n",
              "      <th>inputs_index</th>\n",
              "      <th>targets_index</th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5351</td>\n",
              "      <td>[2013-12-01, 2013-12-02, 2013-12-03, 2013-12-0...</td>\n",
              "      <td>[2013-12-06, 2013-12-07, 2013-12-08, 2013-12-0...</td>\n",
              "      <td>[6157, 6158, 6159, 6160, 6161]</td>\n",
              "      <td>[6162, 6163, 6164, 6165, 6166, 6167, 6168, 616...</td>\n",
              "      <td>[[0.2684054414666464, 0.6661194675873554, 0.46...</td>\n",
              "      <td>[[-0.5952839563372336], [-0.5301158502674453],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5599</td>\n",
              "      <td>[2014-10-04, 2014-10-05, 2014-10-06, 2014-10-0...</td>\n",
              "      <td>[2014-10-09, 2014-10-10, 2014-10-11, 2014-10-1...</td>\n",
              "      <td>[3742, 3743, 3744, 3745, 3746]</td>\n",
              "      <td>[3747, 3748, 3749, 3750, 3751, 3752, 3753, 375...</td>\n",
              "      <td>[[0.2684054414666464, -1.7396742091238298, -1....</td>\n",
              "      <td>[[-0.8235409678170497], [-0.8219053272417826],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5351</td>\n",
              "      <td>[2012-02-17, 2012-02-18, 2012-02-19, 2012-02-2...</td>\n",
              "      <td>[2012-02-22, 2012-02-23, 2012-02-24, 2012-02-2...</td>\n",
              "      <td>[5572, 5573, 5574, 5575, 5576]</td>\n",
              "      <td>[5577, 5578, 5579, 5580, 5581, 5582, 5583, 558...</td>\n",
              "      <td>[[0.2684054414666464, 0.3592646569197392, 0.57...</td>\n",
              "      <td>[[-0.0394163429762045], [-0.0372892767572474],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7078</td>\n",
              "      <td>[2014-07-25, 2014-07-26, 2014-07-27, 2014-07-2...</td>\n",
              "      <td>[2014-07-30, 2014-07-31, 2014-08-01, 2014-08-0...</td>\n",
              "      <td>[781, 782, 783, 784, 785]</td>\n",
              "      <td>[786, 787, 788, 789, 790, 791, 792, 793, 794, ...</td>\n",
              "      <td>[[0.2684054414666464, 0.3662688240726383, 0.61...</td>\n",
              "      <td>[[-0.2221166617624337], [-0.0329764666305339],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5599</td>\n",
              "      <td>[2013-10-16, 2013-10-17, 2013-10-18, 2013-10-1...</td>\n",
              "      <td>[2013-10-21, 2013-10-22, 2013-10-23, 2013-10-2...</td>\n",
              "      <td>[3416, 3417, 3418, 3419, 3420]</td>\n",
              "      <td>[3421, 3422, 3423, 3424, 3425, 3426, 3427, 342...</td>\n",
              "      <td>[[0.2684054414666464, -1.7396742091238298, -1....</td>\n",
              "      <td>[[-0.7467832161570921], [-0.7441940631388441],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4725</th>\n",
              "      <td>5599</td>\n",
              "      <td>[2008-05-11, 2008-05-12, 2008-05-13, 2008-05-1...</td>\n",
              "      <td>[2008-05-16, 2008-05-17, 2008-05-18, 2008-05-1...</td>\n",
              "      <td>[1636, 1637, 1638, 1639, 1640]</td>\n",
              "      <td>[1641, 1642, 1643, 1644, 1645, 1646, 1647, 164...</td>\n",
              "      <td>[[0.2684054414666464, 0.7869355293686349, 0.59...</td>\n",
              "      <td>[[2.407758672511925], [2.477086361827733], [2....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4726</th>\n",
              "      <td>5351</td>\n",
              "      <td>[2013-08-04, 2013-08-05, 2013-08-06, 2013-08-0...</td>\n",
              "      <td>[2013-08-09, 2013-08-10, 2013-08-11, 2013-08-1...</td>\n",
              "      <td>[6041, 6042, 6043, 6044, 6045]</td>\n",
              "      <td>[6046, 6047, 6048, 6049, 6050, 6051, 6052, 605...</td>\n",
              "      <td>[[0.2684054414666464, 0.6073164371268952, 0.47...</td>\n",
              "      <td>[[-0.3845951820463691], [-0.3835683224923899],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4727</th>\n",
              "      <td>5599</td>\n",
              "      <td>[2014-11-04, 2014-11-05, 2014-11-06, 2014-11-0...</td>\n",
              "      <td>[2014-11-09, 2014-11-10, 2014-11-11, 2014-11-1...</td>\n",
              "      <td>[3773, 3774, 3775, 3776, 3777]</td>\n",
              "      <td>[3778, 3779, 3780, 3781, 3782, 3783, 3784, 378...</td>\n",
              "      <td>[[0.2684054414666464, -1.7396742091238298, -1....</td>\n",
              "      <td>[[-0.816008219517501], [-0.822184046263577], [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4728</th>\n",
              "      <td>7078</td>\n",
              "      <td>[2015-06-19, 2015-06-20, 2015-06-21, 2015-06-2...</td>\n",
              "      <td>[2015-06-24, 2015-06-25, 2015-06-26, 2015-06-2...</td>\n",
              "      <td>[1104, 1105, 1106, 1107, 1108]</td>\n",
              "      <td>[1109, 1110, 1111, 1112, 1113, 1114, 1115, 111...</td>\n",
              "      <td>[[0.2684054414666464, 0.3673082899790074, 0.59...</td>\n",
              "      <td>[[0.2366988563777476], [0.256187183770056], [0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4729</th>\n",
              "      <td>5599</td>\n",
              "      <td>[2011-09-27, 2011-09-28, 2011-09-29, 2011-09-3...</td>\n",
              "      <td>[2011-10-02, 2011-10-03, 2011-10-04, 2011-10-0...</td>\n",
              "      <td>[2797, 2798, 2799, 2800, 2801]</td>\n",
              "      <td>[2802, 2803, 2804, 2805, 2806, 2807, 2808, 280...</td>\n",
              "      <td>[[0.2684054414666464, -1.7396742091238298, -1....</td>\n",
              "      <td>[[-0.2418396999099374], [-0.2387004435592005],...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4730 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      well_name                                       inputs_dates  \\\n",
              "0          5351  [2013-12-01, 2013-12-02, 2013-12-03, 2013-12-0...   \n",
              "1          5599  [2014-10-04, 2014-10-05, 2014-10-06, 2014-10-0...   \n",
              "2          5351  [2012-02-17, 2012-02-18, 2012-02-19, 2012-02-2...   \n",
              "3          7078  [2014-07-25, 2014-07-26, 2014-07-27, 2014-07-2...   \n",
              "4          5599  [2013-10-16, 2013-10-17, 2013-10-18, 2013-10-1...   \n",
              "...         ...                                                ...   \n",
              "4725       5599  [2008-05-11, 2008-05-12, 2008-05-13, 2008-05-1...   \n",
              "4726       5351  [2013-08-04, 2013-08-05, 2013-08-06, 2013-08-0...   \n",
              "4727       5599  [2014-11-04, 2014-11-05, 2014-11-06, 2014-11-0...   \n",
              "4728       7078  [2015-06-19, 2015-06-20, 2015-06-21, 2015-06-2...   \n",
              "4729       5599  [2011-09-27, 2011-09-28, 2011-09-29, 2011-09-3...   \n",
              "\n",
              "                                          targets_dates  \\\n",
              "0     [2013-12-06, 2013-12-07, 2013-12-08, 2013-12-0...   \n",
              "1     [2014-10-09, 2014-10-10, 2014-10-11, 2014-10-1...   \n",
              "2     [2012-02-22, 2012-02-23, 2012-02-24, 2012-02-2...   \n",
              "3     [2014-07-30, 2014-07-31, 2014-08-01, 2014-08-0...   \n",
              "4     [2013-10-21, 2013-10-22, 2013-10-23, 2013-10-2...   \n",
              "...                                                 ...   \n",
              "4725  [2008-05-16, 2008-05-17, 2008-05-18, 2008-05-1...   \n",
              "4726  [2013-08-09, 2013-08-10, 2013-08-11, 2013-08-1...   \n",
              "4727  [2014-11-09, 2014-11-10, 2014-11-11, 2014-11-1...   \n",
              "4728  [2015-06-24, 2015-06-25, 2015-06-26, 2015-06-2...   \n",
              "4729  [2011-10-02, 2011-10-03, 2011-10-04, 2011-10-0...   \n",
              "\n",
              "                        inputs_index  \\\n",
              "0     [6157, 6158, 6159, 6160, 6161]   \n",
              "1     [3742, 3743, 3744, 3745, 3746]   \n",
              "2     [5572, 5573, 5574, 5575, 5576]   \n",
              "3          [781, 782, 783, 784, 785]   \n",
              "4     [3416, 3417, 3418, 3419, 3420]   \n",
              "...                              ...   \n",
              "4725  [1636, 1637, 1638, 1639, 1640]   \n",
              "4726  [6041, 6042, 6043, 6044, 6045]   \n",
              "4727  [3773, 3774, 3775, 3776, 3777]   \n",
              "4728  [1104, 1105, 1106, 1107, 1108]   \n",
              "4729  [2797, 2798, 2799, 2800, 2801]   \n",
              "\n",
              "                                          targets_index  \\\n",
              "0     [6162, 6163, 6164, 6165, 6166, 6167, 6168, 616...   \n",
              "1     [3747, 3748, 3749, 3750, 3751, 3752, 3753, 375...   \n",
              "2     [5577, 5578, 5579, 5580, 5581, 5582, 5583, 558...   \n",
              "3     [786, 787, 788, 789, 790, 791, 792, 793, 794, ...   \n",
              "4     [3421, 3422, 3423, 3424, 3425, 3426, 3427, 342...   \n",
              "...                                                 ...   \n",
              "4725  [1641, 1642, 1643, 1644, 1645, 1646, 1647, 164...   \n",
              "4726  [6046, 6047, 6048, 6049, 6050, 6051, 6052, 605...   \n",
              "4727  [3778, 3779, 3780, 3781, 3782, 3783, 3784, 378...   \n",
              "4728  [1109, 1110, 1111, 1112, 1113, 1114, 1115, 111...   \n",
              "4729  [2802, 2803, 2804, 2805, 2806, 2807, 2808, 280...   \n",
              "\n",
              "                                                 inputs  \\\n",
              "0     [[0.2684054414666464, 0.6661194675873554, 0.46...   \n",
              "1     [[0.2684054414666464, -1.7396742091238298, -1....   \n",
              "2     [[0.2684054414666464, 0.3592646569197392, 0.57...   \n",
              "3     [[0.2684054414666464, 0.3662688240726383, 0.61...   \n",
              "4     [[0.2684054414666464, -1.7396742091238298, -1....   \n",
              "...                                                 ...   \n",
              "4725  [[0.2684054414666464, 0.7869355293686349, 0.59...   \n",
              "4726  [[0.2684054414666464, 0.6073164371268952, 0.47...   \n",
              "4727  [[0.2684054414666464, -1.7396742091238298, -1....   \n",
              "4728  [[0.2684054414666464, 0.3673082899790074, 0.59...   \n",
              "4729  [[0.2684054414666464, -1.7396742091238298, -1....   \n",
              "\n",
              "                                                targets  \n",
              "0     [[-0.5952839563372336], [-0.5301158502674453],...  \n",
              "1     [[-0.8235409678170497], [-0.8219053272417826],...  \n",
              "2     [[-0.0394163429762045], [-0.0372892767572474],...  \n",
              "3     [[-0.2221166617624337], [-0.0329764666305339],...  \n",
              "4     [[-0.7467832161570921], [-0.7441940631388441],...  \n",
              "...                                                 ...  \n",
              "4725  [[2.407758672511925], [2.477086361827733], [2....  \n",
              "4726  [[-0.3845951820463691], [-0.3835683224923899],...  \n",
              "4727  [[-0.816008219517501], [-0.822184046263577], [...  \n",
              "4728  [[0.2366988563777476], [0.256187183770056], [0...  \n",
              "4729  [[-0.2418396999099374], [-0.2387004435592005],...  \n",
              "\n",
              "[4730 rows x 7 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nOvIN5gRcsc",
        "outputId": "e49dfea8-6830-47a9-d4fa-afe6adc8c056"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4730, 190), (4730, 14), (1577, 190), (1577, 14), (1573, 190), (1573, 14))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split sequences into input features and targets\n",
        "X_train = np.array([i for i in data_train['inputs']])\n",
        "Y_train = np.array([i for i in data_train['targets']]).squeeze()\n",
        "\n",
        "X_val = np.array([i for i in data_val['inputs']])\n",
        "Y_val = np.array([i for i in data_val['targets']]).squeeze()\n",
        "\n",
        "X_test = np.array([i for i in data_test['inputs']])\n",
        "Y_test = np.array([i for i in data_test['targets']]).squeeze()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, sequences_df):\n",
        "        self.sequences_df = sequences_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.sequences_df.iloc[idx]['inputs']\n",
        "        targets = self.sequences_df.iloc[idx]['targets']\n",
        "        inputs, targets = np.array(inputs, np.float32), np.array(targets, np.float32)\n",
        "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).squeeze()\n",
        "\n",
        "train_dataset = TimeSeriesDataset(data_train)\n",
        "val_dataset = TimeSeriesDataset(data_val)\n",
        "test_dataset = TimeSeriesDataset(data_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VisualizationTimeSeriesDataset(Dataset):\n",
        "    def __init__(self, sequences_df):\n",
        "        self.sequences_df = sequences_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.sequences_df.iloc[idx]['inputs']\n",
        "        targets = self.sequences_df.iloc[idx]['targets']\n",
        "        well_name = self.sequences_df.iloc[idx]['well_name']\n",
        "        inputs_dates = self.sequences_df.iloc[idx]['inputs_dates']\n",
        "        targets_dates = self.sequences_df.iloc[idx]['targets_dates']\n",
        "\n",
        "        return well_name, inputs_dates, targets_dates, torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).squeeze()\n",
        "\n",
        "visualization_test_dataset = VisualizationTimeSeriesDataset(data_test)\n",
        "\n",
        "visualization_test_loader = DataLoader(visualization_test_dataset, batch_size=int(len(test_dataset) / 50), shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0h7KW6y9PatC"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    # Calculate metrics for the predictions\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred, multioutput='uniform_average')\n",
        "    loss = mean_squared_error(y_true, y_pred)\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'Loss': loss}\n",
        "\n",
        "def evaluate(mode, model):\n",
        "    X_modes = {'train': X_train, 'val': X_val, 'test': X_test}\n",
        "    Y_modes = {'train': Y_train, 'val': Y_val, 'test': Y_test}\n",
        "    X = X_modes[mode]\n",
        "    Y = Y_modes[mode].reshape(-1)\n",
        "    outputs = model.predict(X).reshape(-1)\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_metrics(Y, outputs)\n",
        "    print(f\"Loss is {metrics['Loss']:.4f}\")\n",
        "    print(f\"MAE is {metrics['MAE']:.4f}\")\n",
        "    print(f\"RMSE is {metrics['RMSE']:.4f}\")\n",
        "    print(f\"R² is {metrics['R2']:.4f}\")\n",
        "    print(\"\\n\")\n",
        "    return metrics\n",
        "\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
        "    lr = trial.suggest_float('lr', 1e-4, 0.4, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 30)\n",
        "    min_child_weight = trial.suggest_int('min_child_weight', 1, 50)\n",
        "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
        "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
        "    xgb = XGBRegressor(output_length= predictions_days, n_estimators=n_estimators, learning_rate=lr, max_depth=max_depth, min_child_weight=min_child_weight, subsample=subsample, colsample_bytree=colsample_bytree)\n",
        "    model = MultiOutputRegressor(xgb)\n",
        "    model.fit(X_train, Y_train)\n",
        "    val_preds = model.predict(X_val)\n",
        "    val_loss = mean_squared_error(Y_val, val_preds)\n",
        "    return val_loss\n",
        "\n",
        "def save_model(model, name=\"\"): # function to save parameters, optimizer and scheduler states\n",
        "    config_path = path + r'/Models/Global/XGBoost/Model/'\n",
        "    if name != \"\":\n",
        "        name = f'{name}_'\n",
        "    joblib.dump(model, config_path + f'{name}XGBoost.lib')\n",
        "\n",
        "def load_model(name=\"\"): \n",
        "    config_path = path + r'/Models/Global/XGBoost/Model/'\n",
        "    if name != \"\":\n",
        "        name = f'{name}_'\n",
        "    model = joblib.load(config_path + f'{name}XGBoost.lib')\n",
        "    return model\n",
        "\n",
        "def get_oil_history(date, well_name):\n",
        "    well = data[data[\"well_name\"] == int(well_name)].reset_index(drop=True)\n",
        "    well = well[pd.to_datetime(well['date']) < date]\n",
        "    return well['oil_rate']\n",
        "    \n",
        "def label_model_files(old_name=\"\", new_name=\"\"):\n",
        "    if old_name != \"\":\n",
        "        old_name = f'{old_name}_'\n",
        "    if new_name != \"\":\n",
        "        new_name = f'{new_name}_'\n",
        "    config_path = path + r'/Models/Global/XGBoost/Model/'\n",
        "    if os.path.exists(config_path + f'{new_name}state_params.pth'):\n",
        "        try:\n",
        "            user_choice = int(input(\"File with new name already exists. Enter 1 if you want to overwrite the files. Otherwise press 2: \"))\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter 1 or 2.\")\n",
        "            return\n",
        "        if user_choice == 1:\n",
        "            try:\n",
        "                os.rename(config_path + f'{old_name}XGBoost.lib', config_path + f'{new_name}XGBoost.lib')\n",
        "                print(\"Files have been renamed successfully.\")\n",
        "            except FileNotFoundError:\n",
        "                print(\"One or more files not found.\")\n",
        "        elif user_choice == 2:\n",
        "            print(\"Operation cancelled by the user.\")\n",
        "        else:\n",
        "            print(\"Invalid choice. Operation cancelled.\")\n",
        "    else:\n",
        "        try:\n",
        "            os.rename(config_path + f'{old_name}XGBoost.lib', config_path + f'{new_name}XGBoost.lib')\n",
        "            print(\"Files have been renamed successfully.\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"One or more files not found.\")\n",
        "\n",
        "def predictions_with_history_graphs(model, visualization_loader, path):\n",
        "    pdf = PdfPages(path + \"/predictions_with_history.pdf\")\n",
        "    for well_name, inputs_dates, targets_dates, X_batch, Y_batch in visualization_loader:\n",
        "        choice = random.randint(0, len(X_batch) - 1)\n",
        "        X_batch = X_batch[choice].reshape(1, -1)\n",
        "        Y_batch = Y_batch[choice]\n",
        "        well_name = well_name[choice]\n",
        "        inputs_dates = [i[choice] for i in inputs_dates]\n",
        "        targets_dates = [i[choice] for i in targets_dates]\n",
        "\n",
        "        history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "        prediction = model.predict(X_batch).reshape(-1)\n",
        "        label = Y_batch\n",
        "        loss = mean_squared_error(label, prediction)\n",
        "        rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "        # Plotting\n",
        "        forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(range(1, len(history) + 1), history, label='Input Values')\n",
        "        plt.plot(forecast_index, prediction, label='Forecasted Values')\n",
        "        plt.plot(forecast_index, label, label='Actual Values')\n",
        "        # Determine the interval for ticks to have approximately 10 ticks\n",
        "        tick_interval = max(10, round((len(history) + predictions_days + 1) / 10 / 10) * 10)\n",
        "        # Generate tick positions\n",
        "        tick_positions = np.arange(0, len(history) + predictions_days + 1, tick_interval)\n",
        "        tick_positions[0] = 1  # Start tick at 1 instead of 0\n",
        "\n",
        "        # Generate tick labels\n",
        "        tick_labels = tick_positions\n",
        "        plt.xticks(ticks=tick_positions, labels=tick_labels)\n",
        "        plt.axvline(x=len(history), color='r', linestyle='--', label='Forecast Start')\n",
        "        plt.xlabel('Day')\n",
        "        plt.ylabel('Value')\n",
        "        plt.title(f'Well: {well_name}, Loss: {loss:.4f}, RMSE = {rmse:.4f}')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        # Save the current figure to the PDF\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def predictions_graphs(model, visualization_loader, path):\n",
        "    pdf = PdfPages(path + \"/predictions.pdf\")\n",
        "    for well_name, inputs_dates, targets_dates, X_batch, Y_batch in visualization_loader:\n",
        "        choice = random.randint(0, len(X_batch) - 1)\n",
        "        B, T, C = X_batch.shape\n",
        "        X_batch = X_batch[choice].reshape(1, -1)\n",
        "        Y_batch = Y_batch[choice]\n",
        "        well_name = well_name[choice]\n",
        "        inputs_dates = [i[choice] for i in inputs_dates]\n",
        "        targets_dates = [i[choice] for i in targets_dates]\n",
        "\n",
        "        history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "        prediction = model.predict(X_batch).reshape(-1)\n",
        "        label = Y_batch\n",
        "        loss = mean_squared_error(label, prediction)\n",
        "        rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "\n",
        "        inputs = X_batch.reshape(1, T, C)[0][:, column_index]\n",
        "        # Plotting\n",
        "        forecast_index = range(len(inputs) + 1, len(inputs) + predictions_days + 1)\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(range(1, len(inputs) + 1), inputs, marker='o', label='Input Values')\n",
        "        plt.plot(forecast_index, prediction, marker='o', label='Forecasted Values')\n",
        "        plt.plot(forecast_index, label, marker='o', label='Actual Values')\n",
        "        plt.xticks(ticks=np.arange(1, len(inputs) + predictions_days + 1), labels=np.arange(1, len(inputs) + predictions_days + 1))\n",
        "        plt.axvline(x=len(inputs), color='r', linestyle='--', label='Forecast Start')\n",
        "        plt.xlabel('Day')\n",
        "        plt.ylabel('Value')\n",
        "        plt.title(f'Well: {well_name}, Loss: {loss:.4f}, RMSE = {rmse:.4f}')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        # Save the current figure to the PDF\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def all_predictions_graphs(model, data, data_test, path):\n",
        "    well_dataloaders = {}\n",
        "    pdf = PdfPages(path + \"/all_predictions.pdf\")\n",
        "    for well_name in well_info.keys():\n",
        "        well = data[data['well_name'] == well_name].reset_index(drop=True)\n",
        "        fig, ax = plt.subplots(figsize=(15, 6))\n",
        "        ax.plot(well.index, well['oil_rate'], label='Well Production')\n",
        "        ax.axvline(x=int((1 - test_size) * len(well) - days_window - 2), color='r', linestyle='--',)\n",
        "        well_dataset = VisualizationTimeSeriesDataset(data_test[data_test['well_name'] == well_name].reset_index(drop=True))\n",
        "        well_dataloaders[well_name] = DataLoader(well_dataset, batch_size=1, shuffle=False)\n",
        "        total_loss = 0\n",
        "        total_rmse = 0\n",
        "        for i, (_, inputs_dates, targets_dates, X_batch, Y_batch) in enumerate(well_dataloaders[well_name]):\n",
        "            B, T, C = X_batch.shape\n",
        "            inputs_dates = np.array(inputs_dates).T[0]\n",
        "            targets_dates = np.array(targets_dates).T[0]\n",
        "            history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "            X_batch = X_batch.reshape(B, T*C)\n",
        "            prediction = model.predict(X_batch).reshape(-1)\n",
        "            label = Y_batch.reshape(-1)\n",
        "            loss = mean_squared_error(label, prediction)\n",
        "            rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "            total_loss += loss\n",
        "            total_rmse += rmse\n",
        "            forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "            ax.plot(forecast_index, prediction, label='Forecasted Values', color='y')\n",
        "            if i == 0:\n",
        "                ax.legend()\n",
        "        avg_loss = total_loss / len(well_dataloaders[well_name]) \n",
        "        avg_rmse = total_rmse / len(well_dataloaders[well_name]) \n",
        "        ax.set_xlabel('Day')\n",
        "        ax.set_ylabel('Value')\n",
        "        ax.set_title(f'Well: {well_name}, Loss: {avg_loss:.4f}, RMSE = {avg_rmse:.4f}')\n",
        "        ax.grid(True)\n",
        "        pdf.savefig(fig)\n",
        "        plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def all_predictions_with_gaps_graphs(model, data, data_test, path):\n",
        "    well_plots = {}\n",
        "    well_dataloaders = {}   \n",
        "    pdf = PdfPages(path + \"/all_predictions_with_gaps.pdf\")\n",
        "    for well_name in well_info.keys():\n",
        "        well = data[data['well_name'] == well_name].reset_index(drop=True)\n",
        "        fig, ax = plt.subplots(figsize=(15, 6))\n",
        "        ax.plot(well.index, well['oil_rate'], label='Well Production')\n",
        "        ax.axvline(x=int((1 - test_size) * len(well) - days_window - 2), color='r', linestyle='--',)\n",
        "        well_dataset = VisualizationTimeSeriesDataset(data_test[data_test['well_name'] == well_name].reset_index(drop=True))\n",
        "        well_dataloaders[well_name] = DataLoader(well_dataset, batch_size=1, shuffle=False)\n",
        "        total_loss = 0\n",
        "        total_rmse = 0\n",
        "        for i, (_, inputs_dates, targets_dates, X_batch, Y_batch) in enumerate(well_dataloaders[well_name]):\n",
        "            if i % predictions_days == 0 or i == len(well_dataloaders[well_name]) - 1:\n",
        "                B, T, C = X_batch.shape\n",
        "                inputs_dates = np.array(inputs_dates).T[0]\n",
        "                targets_dates = np.array(targets_dates).T[0]\n",
        "                history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "                X_batch = X_batch.reshape(B, T*C)\n",
        "                prediction = model.predict(X_batch).reshape(-1)\n",
        "                label = Y_batch.reshape(-1)\n",
        "                loss = mean_squared_error(label, prediction)\n",
        "                rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "                total_loss += loss\n",
        "                total_rmse += rmse\n",
        "                forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "                ax.plot(forecast_index, prediction, label='Forecasted Values', color='y')\n",
        "                if i == 0:\n",
        "                    ax.legend()\n",
        "        avg_loss = total_loss / len(well_dataloaders[well_name]) \n",
        "        avg_rmse = total_rmse / len(well_dataloaders[well_name]) \n",
        "        ax.set_xlabel('Day')\n",
        "        ax.set_ylabel('Value')\n",
        "        ax.set_title(f'Well: {well_name}, Loss: {avg_loss:.4f}, RMSE = {avg_rmse:.4f}')\n",
        "        ax.grid(True)\n",
        "        pdf.savefig(fig)\n",
        "        plt.close()\n",
        "    pdf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ojIveoyloEz6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-07-02 14:53:20,150] A new study created in memory with name: no-name-0dbfd818-6c65-4881-a15f-f42b6644bd43\n",
            "[I 2024-07-02 14:55:04,966] Trial 0 finished with value: 0.029965498943533227 and parameters: {'n_estimators': 806, 'lr': 0.0055242708973689885, 'max_depth': 23, 'min_child_weight': 34, 'subsample': 0.9276311307669547, 'colsample_bytree': 0.8895332353188312}. Best is trial 0 with value: 0.029965498943533227.\n",
            "[I 2024-07-02 14:56:33,209] Trial 1 finished with value: 0.6925375320870095 and parameters: {'n_estimators': 559, 'lr': 0.0004101348293390399, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.7218004340618807, 'colsample_bytree': 0.6437446549615271}. Best is trial 0 with value: 0.029965498943533227.\n",
            "[I 2024-07-02 14:58:39,561] Trial 2 finished with value: 0.02355662488090007 and parameters: {'n_estimators': 752, 'lr': 0.021883664323391568, 'max_depth': 30, 'min_child_weight': 16, 'subsample': 0.5216476775900352, 'colsample_bytree': 0.8877023913280608}. Best is trial 2 with value: 0.02355662488090007.\n",
            "[I 2024-07-02 14:59:54,746] Trial 3 finished with value: 0.02566218704450307 and parameters: {'n_estimators': 307, 'lr': 0.013961361970690022, 'max_depth': 16, 'min_child_weight': 9, 'subsample': 0.8868489733041969, 'colsample_bytree': 0.8581127642533048}. Best is trial 2 with value: 0.02355662488090007.\n",
            "[I 2024-07-02 15:00:52,909] Trial 4 finished with value: 0.053777097538515964 and parameters: {'n_estimators': 829, 'lr': 0.002647402545829262, 'max_depth': 14, 'min_child_weight': 36, 'subsample': 0.533236729747758, 'colsample_bytree': 0.8851073685652946}. Best is trial 2 with value: 0.02355662488090007.\n",
            "[I 2024-07-02 15:02:16,493] Trial 5 finished with value: 0.02571285966661917 and parameters: {'n_estimators': 883, 'lr': 0.014531643233627541, 'max_depth': 22, 'min_child_weight': 37, 'subsample': 0.8301600203369986, 'colsample_bytree': 0.7608883340267283}. Best is trial 2 with value: 0.02355662488090007.\n",
            "[I 2024-07-02 15:03:35,900] Trial 6 finished with value: 0.6714382662417643 and parameters: {'n_estimators': 927, 'lr': 0.00026497749060024685, 'max_depth': 28, 'min_child_weight': 27, 'subsample': 0.7804897191570328, 'colsample_bytree': 0.9585735979222656}. Best is trial 2 with value: 0.02355662488090007.\n",
            "[I 2024-07-02 15:04:30,365] Trial 7 finished with value: 0.02273936084650543 and parameters: {'n_estimators': 418, 'lr': 0.0386901039399975, 'max_depth': 14, 'min_child_weight': 9, 'subsample': 0.6917298537464773, 'colsample_bytree': 0.6654412546968491}. Best is trial 7 with value: 0.02273936084650543.\n",
            "[I 2024-07-02 15:05:04,017] Trial 8 finished with value: 0.02514384558753252 and parameters: {'n_estimators': 310, 'lr': 0.03501668012274614, 'max_depth': 25, 'min_child_weight': 33, 'subsample': 0.9847125481171184, 'colsample_bytree': 0.6890018121671109}. Best is trial 7 with value: 0.02273936084650543.\n",
            "[I 2024-07-02 15:05:48,078] Trial 9 finished with value: 0.14312124771509885 and parameters: {'n_estimators': 631, 'lr': 0.0018567513000554408, 'max_depth': 9, 'min_child_weight': 48, 'subsample': 0.9033442415961555, 'colsample_bytree': 0.6845713070630889}. Best is trial 7 with value: 0.02273936084650543.\n",
            "[I 2024-07-02 15:05:51,059] Trial 10 finished with value: 0.03379073801392795 and parameters: {'n_estimators': 133, 'lr': 0.37148197542362077, 'max_depth': 3, 'min_child_weight': 16, 'subsample': 0.6719294957690907, 'colsample_bytree': 0.5232629574732486}. Best is trial 7 with value: 0.02273936084650543.\n",
            "[I 2024-07-02 15:07:06,311] Trial 11 finished with value: 0.023696452647170137 and parameters: {'n_estimators': 407, 'lr': 0.09285410032815915, 'max_depth': 30, 'min_child_weight': 16, 'subsample': 0.5063654616081685, 'colsample_bytree': 0.7819591960816384}. Best is trial 7 with value: 0.02273936084650543.\n",
            "[I 2024-07-02 15:08:27,461] Trial 12 finished with value: 0.022816577673050925 and parameters: {'n_estimators': 667, 'lr': 0.07191776285274858, 'max_depth': 19, 'min_child_weight': 16, 'subsample': 0.6138410630800526, 'colsample_bytree': 0.5504972295245941}. Best is trial 7 with value: 0.02273936084650543.\n",
            "[I 2024-07-02 15:09:45,758] Trial 13 finished with value: 0.025716018647870573 and parameters: {'n_estimators': 423, 'lr': 0.1338333099157989, 'max_depth': 19, 'min_child_weight': 3, 'subsample': 0.631490314058971, 'colsample_bytree': 0.5136912869986956}. Best is trial 7 with value: 0.02273936084650543.\n",
            "[I 2024-07-02 15:10:44,159] Trial 14 finished with value: 0.022409956642222412 and parameters: {'n_estimators': 658, 'lr': 0.0656752795328417, 'max_depth': 10, 'min_child_weight': 11, 'subsample': 0.6121425523470315, 'colsample_bytree': 0.6193158388116011}. Best is trial 14 with value: 0.022409956642222412.\n",
            "[I 2024-07-02 15:11:25,054] Trial 15 finished with value: 0.030643274608823916 and parameters: {'n_estimators': 528, 'lr': 0.3632566826640869, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.6051312038952337, 'colsample_bytree': 0.611774450597884}. Best is trial 14 with value: 0.022409956642222412.\n",
            "[I 2024-07-02 15:12:32,231] Trial 16 finished with value: 0.022295847648868824 and parameters: {'n_estimators': 992, 'lr': 0.043496128482686316, 'max_depth': 10, 'min_child_weight': 24, 'subsample': 0.7126137206605649, 'colsample_bytree': 0.5945913805013363}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:13:40,006] Trial 17 finished with value: 0.028277718556932094 and parameters: {'n_estimators': 965, 'lr': 0.00573010198949485, 'max_depth': 9, 'min_child_weight': 25, 'subsample': 0.7717064714273532, 'colsample_bytree': 0.5817830630419905}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:14:00,613] Trial 18 finished with value: 0.025102194168575835 and parameters: {'n_estimators': 712, 'lr': 0.1666681961698889, 'max_depth': 5, 'min_child_weight': 23, 'subsample': 0.5797989338081773, 'colsample_bytree': 0.5945817827434268}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:15:04,067] Trial 19 finished with value: 0.23743299474012788 and parameters: {'n_estimators': 982, 'lr': 0.0008588161127767328, 'max_depth': 11, 'min_child_weight': 44, 'subsample': 0.6657438628910961, 'colsample_bytree': 0.7477247613033021}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:15:10,019] Trial 20 finished with value: 0.03056492993026464 and parameters: {'n_estimators': 131, 'lr': 0.04117795692668542, 'max_depth': 6, 'min_child_weight': 21, 'subsample': 0.7294086315585753, 'colsample_bytree': 0.6212323575186669}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:16:02,624] Trial 21 finished with value: 0.022315706577991107 and parameters: {'n_estimators': 472, 'lr': 0.04203447360297365, 'max_depth': 12, 'min_child_weight': 9, 'subsample': 0.6793557573883515, 'colsample_bytree': 0.6999377859796139}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:17:03,468] Trial 22 finished with value: 0.025109430894799344 and parameters: {'n_estimators': 552, 'lr': 0.011307132597847339, 'max_depth': 11, 'min_child_weight': 11, 'subsample': 0.6507051839146235, 'colsample_bytree': 0.7212537822552195}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:17:21,181] Trial 23 finished with value: 0.026917758642798162 and parameters: {'n_estimators': 268, 'lr': 0.05981698321238281, 'max_depth': 12, 'min_child_weight': 29, 'subsample': 0.5723679891346994, 'colsample_bytree': 0.8087768330574028}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:18:00,374] Trial 24 finished with value: 0.957699671929202 and parameters: {'n_estimators': 484, 'lr': 0.00011394836250516675, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8149583449369611, 'colsample_bytree': 0.5578321050954071}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:18:59,604] Trial 25 finished with value: 0.02949592896036692 and parameters: {'n_estimators': 633, 'lr': 0.20929257332790357, 'max_depth': 18, 'min_child_weight': 1, 'subsample': 0.7064006748246825, 'colsample_bytree': 0.70786011141199}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:19:11,030] Trial 26 finished with value: 0.03057400971018629 and parameters: {'n_estimators': 216, 'lr': 0.023670636914748553, 'max_depth': 6, 'min_child_weight': 19, 'subsample': 0.757308978936833, 'colsample_bytree': 0.6476035857043501}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:20:18,632] Trial 27 finished with value: 0.02333871748460099 and parameters: {'n_estimators': 779, 'lr': 0.09428898936930505, 'max_depth': 12, 'min_child_weight': 13, 'subsample': 0.5763738214565712, 'colsample_bytree': 0.5621258080227665}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:23:36,221] Trial 28 finished with value: 0.023082140222157675 and parameters: {'n_estimators': 865, 'lr': 0.009010615646612524, 'max_depth': 16, 'min_child_weight': 6, 'subsample': 0.8214641891491644, 'colsample_bytree': 0.6349456062146133}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:23:51,886] Trial 29 finished with value: 0.05466202794333685 and parameters: {'n_estimators': 709, 'lr': 0.003542274860039588, 'max_depth': 3, 'min_child_weight': 30, 'subsample': 0.693174402252068, 'colsample_bytree': 0.8196813062035391}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:24:26,646] Trial 30 finished with value: 0.025568397612177003 and parameters: {'n_estimators': 477, 'lr': 0.021194154747278954, 'max_depth': 10, 'min_child_weight': 20, 'subsample': 0.6437416263659388, 'colsample_bytree': 0.7214590780964629}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:25:26,845] Trial 31 finished with value: 0.022621328352446967 and parameters: {'n_estimators': 417, 'lr': 0.041057255091040586, 'max_depth': 14, 'min_child_weight': 8, 'subsample': 0.6846896439021383, 'colsample_bytree': 0.6710140405259717}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:26:27,189] Trial 32 finished with value: 0.023160527847757396 and parameters: {'n_estimators': 363, 'lr': 0.06332600932851812, 'max_depth': 13, 'min_child_weight': 6, 'subsample': 0.7220500494038197, 'colsample_bytree': 0.6704870801126008}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:27:23,406] Trial 33 finished with value: 0.02257537572325322 and parameters: {'n_estimators': 466, 'lr': 0.033930829575026945, 'max_depth': 15, 'min_child_weight': 12, 'subsample': 0.6745977858592235, 'colsample_bytree': 0.6130076254103647}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:28:39,655] Trial 34 finished with value: 0.02260291184716697 and parameters: {'n_estimators': 577, 'lr': 0.022050627391442427, 'max_depth': 17, 'min_child_weight': 13, 'subsample': 0.7396040738782501, 'colsample_bytree': 0.5978844724552039}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:29:38,149] Trial 35 finished with value: 0.023776860809129434 and parameters: {'n_estimators': 480, 'lr': 0.13971015157346842, 'max_depth': 15, 'min_child_weight': 13, 'subsample': 0.6167801128820298, 'colsample_bytree': 0.6399031935214086}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:30:44,894] Trial 36 finished with value: 0.03089512235942669 and parameters: {'n_estimators': 611, 'lr': 0.006827363890122993, 'max_depth': 21, 'min_child_weight': 18, 'subsample': 0.536261401440639, 'colsample_bytree': 0.5349011767168518}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:31:11,860] Trial 37 finished with value: 0.025005126800488258 and parameters: {'n_estimators': 350, 'lr': 0.028093255125581574, 'max_depth': 12, 'min_child_weight': 23, 'subsample': 0.7968760832744365, 'colsample_bytree': 0.5016568419532977}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:32:46,906] Trial 38 finished with value: 0.024171978925808718 and parameters: {'n_estimators': 824, 'lr': 0.05636018938653516, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.6633464774518669, 'colsample_bytree': 0.5781368728985591}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:33:28,093] Trial 39 finished with value: 0.028078038072211025 and parameters: {'n_estimators': 507, 'lr': 0.01483450831564385, 'max_depth': 15, 'min_child_weight': 39, 'subsample': 0.865374653497332, 'colsample_bytree': 0.6166158695987959}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:33:54,915] Trial 40 finished with value: 0.025206425163522672 and parameters: {'n_estimators': 581, 'lr': 0.2239818767907034, 'max_depth': 6, 'min_child_weight': 12, 'subsample': 0.7118812582143305, 'colsample_bytree': 0.6549023293076865}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:35:04,359] Trial 41 finished with value: 0.023080553544503928 and parameters: {'n_estimators': 562, 'lr': 0.019029882871495468, 'max_depth': 17, 'min_child_weight': 14, 'subsample': 0.7342463162720704, 'colsample_bytree': 0.5944537233599666}. Best is trial 16 with value: 0.022295847648868824.\n",
            "[I 2024-07-02 15:37:39,952] Trial 42 finished with value: 0.02207002981755572 and parameters: {'n_estimators': 740, 'lr': 0.029276235360537833, 'max_depth': 21, 'min_child_weight': 8, 'subsample': 0.7439436414232604, 'colsample_bytree': 0.5999896824207098}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:39:56,145] Trial 43 finished with value: 0.023198845772651033 and parameters: {'n_estimators': 908, 'lr': 0.09054281892233806, 'max_depth': 21, 'min_child_weight': 8, 'subsample': 0.7559282992418409, 'colsample_bytree': 0.7023716123661758}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:43:30,174] Trial 44 finished with value: 0.02283099387601867 and parameters: {'n_estimators': 744, 'lr': 0.03343943160721722, 'max_depth': 25, 'min_child_weight': 8, 'subsample': 0.6930326635958584, 'colsample_bytree': 0.943270622720251}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:46:21,887] Trial 45 finished with value: 0.02329616040570024 and parameters: {'n_estimators': 709, 'lr': 0.050088546025283585, 'max_depth': 24, 'min_child_weight': 5, 'subsample': 0.8494765341343066, 'colsample_bytree': 0.5374856474669577}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:47:32,447] Trial 46 finished with value: 0.02481006663631522 and parameters: {'n_estimators': 855, 'lr': 0.009729143542047843, 'max_depth': 10, 'min_child_weight': 17, 'subsample': 0.7968802930733141, 'colsample_bytree': 0.7481217403779413}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:48:44,599] Trial 47 finished with value: 0.022959653175445332 and parameters: {'n_estimators': 656, 'lr': 0.10226965625180794, 'max_depth': 13, 'min_child_weight': 10, 'subsample': 0.9701387100055334, 'colsample_bytree': 0.5722654300541019}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:49:27,623] Trial 48 finished with value: 0.07110857459345667 and parameters: {'n_estimators': 442, 'lr': 0.0039063861841753976, 'max_depth': 20, 'min_child_weight': 15, 'subsample': 0.5992580693255735, 'colsample_bytree': 0.613789901988692}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:50:28,221] Trial 49 finished with value: 0.026949739215014732 and parameters: {'n_estimators': 916, 'lr': 0.014645167783302687, 'max_depth': 15, 'min_child_weight': 34, 'subsample': 0.6251229409214271, 'colsample_bytree': 0.6342874488181768}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:55:39,946] Trial 50 finished with value: 0.023435090743855774 and parameters: {'n_estimators': 787, 'lr': 0.029683184530569662, 'max_depth': 26, 'min_child_weight': 3, 'subsample': 0.6438709970329702, 'colsample_bytree': 0.6840059906469089}. Best is trial 42 with value: 0.02207002981755572.\n",
            "[I 2024-07-02 15:57:03,576] Trial 51 finished with value: 0.021817494771666338 and parameters: {'n_estimators': 594, 'lr': 0.045570993763519016, 'max_depth': 17, 'min_child_weight': 12, 'subsample': 0.7433625471337193, 'colsample_bytree': 0.5992551725398402}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 15:58:59,983] Trial 52 finished with value: 0.022001367435357386 and parameters: {'n_estimators': 616, 'lr': 0.04495848323405745, 'max_depth': 22, 'min_child_weight': 11, 'subsample': 0.778934589945399, 'colsample_bytree': 0.5861344584094492}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:01:17,566] Trial 53 finished with value: 0.022426944264705213 and parameters: {'n_estimators': 673, 'lr': 0.06467237599168611, 'max_depth': 22, 'min_child_weight': 10, 'subsample': 0.7721269848426932, 'colsample_bytree': 0.5896599293844209}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:03:57,848] Trial 54 finished with value: 0.022360846691170073 and parameters: {'n_estimators': 605, 'lr': 0.043889289685397556, 'max_depth': 23, 'min_child_weight': 7, 'subsample': 0.7859227546090444, 'colsample_bytree': 0.545133174293182}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:06:38,373] Trial 55 finished with value: 0.022472445401944957 and parameters: {'n_estimators': 615, 'lr': 0.041428074304728724, 'max_depth': 23, 'min_child_weight': 7, 'subsample': 0.7938273368851653, 'colsample_bytree': 0.544071265013749}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:07:43,894] Trial 56 finished with value: 0.2562385685141016 and parameters: {'n_estimators': 516, 'lr': 0.0015274505868459636, 'max_depth': 28, 'min_child_weight': 9, 'subsample': 0.7537224548123901, 'colsample_bytree': 0.5201889423639425}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:09:22,803] Trial 57 finished with value: 0.023989554113999036 and parameters: {'n_estimators': 601, 'lr': 0.08269490423180721, 'max_depth': 19, 'min_child_weight': 4, 'subsample': 0.8516933870540948, 'colsample_bytree': 0.5627810744388192}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:10:13,546] Trial 58 finished with value: 0.027833480417830157 and parameters: {'n_estimators': 536, 'lr': 0.017338929595372973, 'max_depth': 27, 'min_child_weight': 40, 'subsample': 0.783917123044846, 'colsample_bytree': 0.5267022302408532}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:11:59,897] Trial 59 finished with value: 0.02340275390630483 and parameters: {'n_estimators': 997, 'lr': 0.12133854089113559, 'max_depth': 23, 'min_child_weight': 31, 'subsample': 0.7153381257481548, 'colsample_bytree': 0.5042173308256063}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:13:11,683] Trial 60 finished with value: 0.02219212127705491 and parameters: {'n_estimators': 731, 'lr': 0.04719828153372697, 'max_depth': 20, 'min_child_weight': 26, 'subsample': 0.8093297056914087, 'colsample_bytree': 0.5522239753409169}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:14:45,739] Trial 61 finished with value: 0.022093893051698475 and parameters: {'n_estimators': 951, 'lr': 0.04942410151445094, 'max_depth': 21, 'min_child_weight': 27, 'subsample': 0.813697203460173, 'colsample_bytree': 0.5704502809031545}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:16:19,586] Trial 62 finished with value: 0.02239536500164564 and parameters: {'n_estimators': 946, 'lr': 0.07597315490133598, 'max_depth': 20, 'min_child_weight': 27, 'subsample': 0.8106506554492104, 'colsample_bytree': 0.5702372269682224}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:17:34,745] Trial 63 finished with value: 0.024271947835608727 and parameters: {'n_estimators': 744, 'lr': 0.18328226887410043, 'max_depth': 18, 'min_child_weight': 25, 'subsample': 0.7683109624572134, 'colsample_bytree': 0.5993837323482734}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:19:05,593] Trial 64 finished with value: 0.02237952463262641 and parameters: {'n_estimators': 890, 'lr': 0.026112557063210893, 'max_depth': 21, 'min_child_weight': 23, 'subsample': 0.8331361894726135, 'colsample_bytree': 0.5806163490362647}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:20:05,917] Trial 65 finished with value: 0.022164926331215164 and parameters: {'n_estimators': 680, 'lr': 0.05128396962142193, 'max_depth': 18, 'min_child_weight': 28, 'subsample': 0.9006818446378013, 'colsample_bytree': 0.5515349806069696}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:21:11,534] Trial 66 finished with value: 0.02485532543158645 and parameters: {'n_estimators': 680, 'lr': 0.25105151668614245, 'max_depth': 18, 'min_child_weight': 27, 'subsample': 0.9113183681628662, 'colsample_bytree': 0.5565533613975219}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:22:50,979] Trial 67 finished with value: 0.02281800716066329 and parameters: {'n_estimators': 957, 'lr': 0.10957275145430583, 'max_depth': 20, 'min_child_weight': 28, 'subsample': 0.950102536331246, 'colsample_bytree': 0.5176512414011888}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:24:05,778] Trial 68 finished with value: 0.022464529604235894 and parameters: {'n_estimators': 766, 'lr': 0.054100384581985655, 'max_depth': 22, 'min_child_weight': 32, 'subsample': 0.8780664817322597, 'colsample_bytree': 0.6252152023540668}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:25:37,854] Trial 69 finished with value: 0.02321600598613675 and parameters: {'n_estimators': 837, 'lr': 0.1360706362251221, 'max_depth': 19, 'min_child_weight': 22, 'subsample': 0.740926693919418, 'colsample_bytree': 0.5504494348073053}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:26:54,923] Trial 70 finished with value: 0.022503648253395354 and parameters: {'n_estimators': 811, 'lr': 0.03440330838467032, 'max_depth': 17, 'min_child_weight': 25, 'subsample': 0.9298038622519668, 'colsample_bytree': 0.6554390045152763}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:27:54,879] Trial 71 finished with value: 0.022810776530151854 and parameters: {'n_estimators': 641, 'lr': 0.052598529419698156, 'max_depth': 20, 'min_child_weight': 34, 'subsample': 0.8359245358420221, 'colsample_bytree': 0.6041005483417118}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:29:31,109] Trial 72 finished with value: 0.022406855439875112 and parameters: {'n_estimators': 692, 'lr': 0.07136904989275651, 'max_depth': 22, 'min_child_weight': 20, 'subsample': 0.8088657104056414, 'colsample_bytree': 0.580418482232528}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:31:03,800] Trial 73 finished with value: 0.024418774846652225 and parameters: {'n_estimators': 1000, 'lr': 0.011622025673997184, 'max_depth': 18, 'min_child_weight': 29, 'subsample': 0.8920412489364531, 'colsample_bytree': 0.5660749583636963}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:32:15,599] Trial 74 finished with value: 0.022750381542771984 and parameters: {'n_estimators': 732, 'lr': 0.039411280663233086, 'max_depth': 16, 'min_child_weight': 26, 'subsample': 0.7052125206328703, 'colsample_bytree': 0.7710613406062434}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:33:42,451] Trial 75 finished with value: 0.024240281121735933 and parameters: {'n_estimators': 790, 'lr': 0.026810107488383875, 'max_depth': 24, 'min_child_weight': 36, 'subsample': 0.7659729440889874, 'colsample_bytree': 0.8236524185673263}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:34:17,290] Trial 76 finished with value: 0.023764929439184533 and parameters: {'n_estimators': 392, 'lr': 0.04736909568967881, 'max_depth': 21, 'min_child_weight': 29, 'subsample': 0.7480332568237332, 'colsample_bytree': 0.5335512030746022}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:35:48,266] Trial 77 finished with value: 0.023384653327223785 and parameters: {'n_estimators': 936, 'lr': 0.018192569174649273, 'max_depth': 19, 'min_child_weight': 24, 'subsample': 0.7261305843503961, 'colsample_bytree': 0.589116851865234}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:36:48,340] Trial 78 finished with value: 0.024649108006462576 and parameters: {'n_estimators': 568, 'lr': 0.022204729938041994, 'max_depth': 24, 'min_child_weight': 31, 'subsample': 0.8245460552496404, 'colsample_bytree': 0.6300094313940406}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:37:42,917] Trial 79 finished with value: 0.02262264907678193 and parameters: {'n_estimators': 635, 'lr': 0.07745967153049636, 'max_depth': 14, 'min_child_weight': 21, 'subsample': 0.6793626534322175, 'colsample_bytree': 0.6039821004122176}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:39:15,537] Trial 80 finished with value: 0.02501179550562024 and parameters: {'n_estimators': 974, 'lr': 0.006976775412012422, 'max_depth': 9, 'min_child_weight': 11, 'subsample': 0.7036620362101516, 'colsample_bytree': 0.8771106305262668}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:42:24,476] Trial 81 finished with value: 0.022666812909497843 and parameters: {'n_estimators': 722, 'lr': 0.04474727630993432, 'max_depth': 23, 'min_child_weight': 6, 'subsample': 0.7911873059358245, 'colsample_bytree': 0.5461832799534624}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:43:28,776] Trial 82 finished with value: 0.022401180128570806 and parameters: {'n_estimators': 497, 'lr': 0.03205448532557828, 'max_depth': 22, 'min_child_weight': 15, 'subsample': 0.7800604177285039, 'colsample_bytree': 0.5618562395776889}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:45:06,606] Trial 83 finished with value: 0.022769626681565035 and parameters: {'n_estimators': 542, 'lr': 0.06001159089527443, 'max_depth': 16, 'min_child_weight': 7, 'subsample': 0.8070354136708395, 'colsample_bytree': 0.5465612419816731}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:49:05,760] Trial 84 finished with value: 0.024062067093234052 and parameters: {'n_estimators': 693, 'lr': 0.0377481193280327, 'max_depth': 25, 'min_child_weight': 2, 'subsample': 0.7286483851246548, 'colsample_bytree': 0.5874269386364211}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:50:01,875] Trial 85 finished with value: 0.7608659432216752 and parameters: {'n_estimators': 656, 'lr': 0.00027183602630837146, 'max_depth': 21, 'min_child_weight': 18, 'subsample': 0.6573344315678737, 'colsample_bytree': 0.7335373551979038}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:51:24,035] Trial 86 finished with value: 0.022733422916009043 and parameters: {'n_estimators': 456, 'lr': 0.09420284861305168, 'max_depth': 20, 'min_child_weight': 10, 'subsample': 0.7774459883957274, 'colsample_bytree': 0.5339185892712407}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:52:06,320] Trial 87 finished with value: 0.02465113575406628 and parameters: {'n_estimators': 591, 'lr': 0.048684479413627156, 'max_depth': 19, 'min_child_weight': 50, 'subsample': 0.8504457338204351, 'colsample_bytree': 0.5718497185952932}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:56:30,736] Trial 88 finished with value: 0.023408852160722186 and parameters: {'n_estimators': 622, 'lr': 0.026523592741757366, 'max_depth': 23, 'min_child_weight': 4, 'subsample': 0.7464811463166863, 'colsample_bytree': 0.99159954073945}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:58:33,485] Trial 89 finished with value: 0.023109515246538585 and parameters: {'n_estimators': 875, 'lr': 0.06247269832709022, 'max_depth': 17, 'min_child_weight': 12, 'subsample': 0.9983465593630518, 'colsample_bytree': 0.6080474334642109}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 16:59:00,177] Trial 90 finished with value: 0.023433738230750196 and parameters: {'n_estimators': 554, 'lr': 0.15377083674325662, 'max_depth': 7, 'min_child_weight': 14, 'subsample': 0.7641648907587372, 'colsample_bytree': 0.5083307479337186}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:00:36,963] Trial 91 finished with value: 0.022394273467249416 and parameters: {'n_estimators': 914, 'lr': 0.024617862171090608, 'max_depth': 21, 'min_child_weight': 23, 'subsample': 0.8351383498585296, 'colsample_bytree': 0.5522778846023498}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:02:10,904] Trial 92 finished with value: 0.02239917090426442 and parameters: {'n_estimators': 888, 'lr': 0.03077090056672839, 'max_depth': 21, 'min_child_weight': 26, 'subsample': 0.8657757919956695, 'colsample_bytree': 0.5786761717700255}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:03:41,330] Trial 93 finished with value: 0.022332930454879357 and parameters: {'n_estimators': 764, 'lr': 0.03966816746487953, 'max_depth': 22, 'min_child_weight': 24, 'subsample': 0.8018680531685175, 'colsample_bytree': 0.6461371744052951}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:05:08,994] Trial 94 finished with value: 0.022457780418525853 and parameters: {'n_estimators': 750, 'lr': 0.043823193904294004, 'max_depth': 24, 'min_child_weight': 28, 'subsample': 0.7993574467279825, 'colsample_bytree': 0.6464401826538346}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:05:52,429] Trial 95 finished with value: 0.02243562381644581 and parameters: {'n_estimators': 592, 'lr': 0.07188785374255302, 'max_depth': 11, 'min_child_weight': 24, 'subsample': 0.8194862680747426, 'colsample_bytree': 0.6885576721769466}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:07:17,918] Trial 96 finished with value: 0.02295645926421882 and parameters: {'n_estimators': 766, 'lr': 0.03501495595045374, 'max_depth': 23, 'min_child_weight': 28, 'subsample': 0.7585006006361598, 'colsample_bytree': 0.6228037210686304}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:09:36,595] Trial 97 finished with value: 0.022366079678398137 and parameters: {'n_estimators': 704, 'lr': 0.02062805541881759, 'max_depth': 22, 'min_child_weight': 9, 'subsample': 0.6895148867720488, 'colsample_bytree': 0.6644315481606838}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:11:52,000] Trial 98 finished with value: 0.022633962673744592 and parameters: {'n_estimators': 649, 'lr': 0.01668871871473887, 'max_depth': 18, 'min_child_weight': 7, 'subsample': 0.7844413382981283, 'colsample_bytree': 0.5957978686278892}. Best is trial 51 with value: 0.021817494771666338.\n",
            "[I 2024-07-02 17:14:21,407] Trial 99 finished with value: 0.022701550514169756 and parameters: {'n_estimators': 668, 'lr': 0.05832230069922448, 'max_depth': 20, 'min_child_weight': 8, 'subsample': 0.699460612702646, 'colsample_bytree': 0.6772678896568525}. Best is trial 51 with value: 0.021817494771666338.\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "# Create a study and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "best_params = study.best_params\n",
        "n_estimators = best_params['n_estimators']\n",
        "lr = best_params['lr']\n",
        "max_depth = best_params['max_depth']\n",
        "min_child_weight = best_params['min_child_weight']\n",
        "subsample = best_params['subsample']\n",
        "colsample_bytree = best_params['colsample_bytree']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'n_estimators': 594, 'lr': 0.045570993763519016, 'max_depth': 17, 'min_child_weight': 12, 'subsample': 0.7433625471337193, 'colsample_bytree': 0.5992551725398402}\n"
          ]
        }
      ],
      "source": [
        "print('Best hyperparameters:', best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_estimators = 594\n",
        "lr = 0.045570993763519016 \n",
        "max_depth = 17\n",
        "min_child_weight = 12\n",
        "subsample = 0.7433625471337193 \n",
        "colsample_bytree = 0.5992551725398402"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "i-Vd70O8oFL5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=0.5992551725398402,\n",
              "                                            device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.045570993763519016,\n",
              "                                            max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=17,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=12, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=594, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=0.5992551725398402,\n",
              "                                            device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.045570993763519016,\n",
              "                                            max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=17,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=12, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=594, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.5992551725398402, device=None,\n",
              "             early_stopping_rounds=None, enable_categorical=False,\n",
              "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
              "             importance_type=None, interaction_constraints=None,\n",
              "             learning_rate=0.045570993763519016, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=17, max_leaves=None,\n",
              "             min_child_weight=12, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=594, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.5992551725398402, device=None,\n",
              "             early_stopping_rounds=None, enable_categorical=False,\n",
              "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
              "             importance_type=None, interaction_constraints=None,\n",
              "             learning_rate=0.045570993763519016, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=17, max_leaves=None,\n",
              "             min_child_weight=12, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=594, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=0.5992551725398402,\n",
              "                                            device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.045570993763519016,\n",
              "                                            max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=17,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=12, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=594, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create and configure the XGBoost regressor with hyperparameters\n",
        "xgb = XGBRegressor(n_estimators=n_estimators, learning_rate=lr, max_depth=max_depth, min_child_weight=min_child_weight, subsample=subsample, colsample_bytree=colsample_bytree) \n",
        "\n",
        "# Wrap the XGBoost regressor in a MultiOutputRegressor\n",
        "model = MultiOutputRegressor(xgb)\n",
        "model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss is 0.0003\n",
            "MAE is 0.0079\n",
            "RMSE is 0.0181\n",
            "R² is 0.9997\n",
            "\n",
            "\n",
            "Loss is 0.0407\n",
            "MAE is 0.0920\n",
            "RMSE is 0.2016\n",
            "R² is 0.9627\n",
            "\n",
            "\n",
            "Loss is 0.0048\n",
            "MAE is 0.0511\n",
            "RMSE is 0.0696\n",
            "R² is 0.7992\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_metrics = evaluate('train', model)\n",
        "val_sizemetrics = evaluate('val', model)\n",
        "test_metrics = evaluate('test', model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_model(model, \"current\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files have been renamed successfully.\n"
          ]
        }
      ],
      "source": [
        "label_model_files(old_name='current', new_name='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(\"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss is 0.0043\n",
            "MAE is 0.0481\n",
            "RMSE is 0.0656\n",
            "R² is 0.8202\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions_with_history_graphs(model, visualization_test_loader, path + \"/Models/Global/XGBoost/Graphs\")\n",
        "predictions_graphs(model, visualization_test_loader, path + \"/Models/Global/XGBoost/Graphs\")\n",
        "all_predictions_graphs(model, data, data_test, path + \"/Models/Global/XGBoost/Graphs\")\n",
        "all_predictions_with_gaps_graphs(model, data, data_test, path + \"/Models/Global/XGBoost/Graphs\")\n",
        "test_metrics = evaluate('test', model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
