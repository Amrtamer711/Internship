{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "UiR3fmx7CA4k",
        "outputId": "0bc76cb5-4eef-4f5b-d17f-3a312ac0eb32"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import optuna\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from matplotlib.backends.backend_pdf import PdfPages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "kHGp1xjdeuoP"
      },
      "outputs": [],
      "source": [
        "path = \"/Users/amrtamer/Documents/Internship\"\n",
        "# path = \"/content/drive/MyDrive/Internship\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "oMm8nN82aHf-",
        "outputId": "af7ebad3-5206-4dd9-e0d2-806809812f0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>WELL_BORE_CODE</th>\n",
              "      <th>date</th>\n",
              "      <th>prod_hrs</th>\n",
              "      <th>bhp</th>\n",
              "      <th>bht</th>\n",
              "      <th>dp_tubing</th>\n",
              "      <th>AVG_ANNULUS_PRESS</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>whp</th>\n",
              "      <th>...</th>\n",
              "      <th>linear_regressor</th>\n",
              "      <th>EMA_short</th>\n",
              "      <th>EMA_medium</th>\n",
              "      <th>EMA_long</th>\n",
              "      <th>Rolling_short</th>\n",
              "      <th>Rolling_medium</th>\n",
              "      <th>Rolling_long</th>\n",
              "      <th>Lag_short</th>\n",
              "      <th>Lag_medium</th>\n",
              "      <th>Lag_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>1.029309</td>\n",
              "      <td>0.605973</td>\n",
              "      <td>0.396165</td>\n",
              "      <td>-2.015211</td>\n",
              "      <td>-0.533280</td>\n",
              "      <td>3.281836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.489929</td>\n",
              "      <td>-0.495877</td>\n",
              "      <td>-0.498713</td>\n",
              "      <td>-0.502834</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.845793</td>\n",
              "      <td>0.634777</td>\n",
              "      <td>0.239816</td>\n",
              "      <td>0.088574</td>\n",
              "      <td>-0.419656</td>\n",
              "      <td>2.849981</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.489929</td>\n",
              "      <td>-0.363747</td>\n",
              "      <td>-0.426301</td>\n",
              "      <td>-0.464667</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.775023</td>\n",
              "      <td>0.639809</td>\n",
              "      <td>0.199889</td>\n",
              "      <td>-0.687843</td>\n",
              "      <td>-0.402874</td>\n",
              "      <td>2.607708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.146007</td>\n",
              "      <td>-0.180982</td>\n",
              "      <td>-0.315168</td>\n",
              "      <td>-0.402787</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.09810136648612545]</td>\n",
              "      <td>[0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.705031</td>\n",
              "      <td>0.642083</td>\n",
              "      <td>0.161491</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.379061</td>\n",
              "      <td>2.364038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024781</td>\n",
              "      <td>-0.133505</td>\n",
              "      <td>-0.264997</td>\n",
              "      <td>-0.368282</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[-0.4905010756171413, -0.09810136648612545, 0....</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413, -0.09810136648...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-26</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.625355</td>\n",
              "      <td>0.643889</td>\n",
              "      <td>0.117219</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.340115</td>\n",
              "      <td>2.088747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057726</td>\n",
              "      <td>-0.077878</td>\n",
              "      <td>-0.210807</td>\n",
              "      <td>-0.330137</td>\n",
              "      <td>-0.084172</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>[-0.09810136648612545, 0.18307478352672518, -0...</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.0981013664861254...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   well_name WELL_BORE_CODE        date  prod_hrs       bhp       bht  \\\n",
              "0       7405  NO 15/9-F-1 C  2014-04-22  0.268405  1.029309  0.605973   \n",
              "1       7405  NO 15/9-F-1 C  2014-04-23  0.268405  0.845793  0.634777   \n",
              "2       7405  NO 15/9-F-1 C  2014-04-24  0.268405  0.775023  0.639809   \n",
              "3       7405  NO 15/9-F-1 C  2014-04-25  0.268405  0.705031  0.642083   \n",
              "4       7405  NO 15/9-F-1 C  2014-04-26  0.268405  0.625355  0.643889   \n",
              "\n",
              "   dp_tubing  AVG_ANNULUS_PRESS  AVG_CHOKE_SIZE_P       whp  ...  \\\n",
              "0   0.396165          -2.015211         -0.533280  3.281836  ...   \n",
              "1   0.239816           0.088574         -0.419656  2.849981  ...   \n",
              "2   0.199889          -0.687843         -0.402874  2.607708  ...   \n",
              "3   0.161491           1.145565         -0.379061  2.364038  ...   \n",
              "4   0.117219           1.145565         -0.340115  2.088747  ...   \n",
              "\n",
              "   linear_regressor  EMA_short  EMA_medium  EMA_long  Rolling_short  \\\n",
              "0         -0.489929  -0.495877   -0.498713 -0.502834      -0.001433   \n",
              "1         -0.489929  -0.363747   -0.426301 -0.464667      -0.001433   \n",
              "2         -0.146007  -0.180982   -0.315168 -0.402787      -0.001433   \n",
              "3          0.024781  -0.133505   -0.264997 -0.368282      -0.001433   \n",
              "4          0.057726  -0.077878   -0.210807 -0.330137      -0.084172   \n",
              "\n",
              "   Rolling_medium  Rolling_long  \\\n",
              "0         -0.0027     -0.005271   \n",
              "1         -0.0027     -0.005271   \n",
              "2         -0.0027     -0.005271   \n",
              "3         -0.0027     -0.005271   \n",
              "4         -0.0027     -0.005271   \n",
              "\n",
              "                                           Lag_short  \\\n",
              "0                                    [0.0, 0.0, 0.0]   \n",
              "1                    [0.0, 0.0, -0.4905010756171413]   \n",
              "2   [0.0, -0.4905010756171413, -0.09810136648612545]   \n",
              "3  [-0.4905010756171413, -0.09810136648612545, 0....   \n",
              "4  [-0.09810136648612545, 0.18307478352672518, -0...   \n",
              "\n",
              "                                          Lag_medium  \\\n",
              "0                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "1          [0.0, 0.0, 0.0, 0.0, -0.4905010756171413]   \n",
              "2  [0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...   \n",
              "3  [0.0, 0.0, -0.4905010756171413, -0.09810136648...   \n",
              "4  [0.0, -0.4905010756171413, -0.0981013664861254...   \n",
              "\n",
              "                                            Lag_long  \n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...  \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 303,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(path + r'/data/Volve/Volve_cleaned_prepared.csv')\n",
        "if \"Unnamed: 0\" in data.columns:\n",
        "    data = data.drop(columns=\"Unnamed: 0\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZmGsFefnB3G",
        "outputId": "b292ccb7-229f-4e81-93a7-5e73a095cd2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{7405: 'NO 15/9-F-1 C',\n",
              " 7078: 'NO 15/9-F-11 H',\n",
              " 5599: 'NO 15/9-F-12 H',\n",
              " 7289: 'NO 15/9-F-15 D',\n",
              " 5351: 'NO 15/9-F-14 H',\n",
              " 5769: 'NO 15/9-F-5 AH'}"
            ]
          },
          "execution_count": 304,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "well_info = dict(set([(j, i) for i, j in data[['WELL_BORE_CODE', 'well_name']].values.tolist()])) # creating a dictionary of well identiification with {code: name} structure\n",
        "well_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['well_name', 'WELL_BORE_CODE', 'date', 'prod_hrs', 'bhp', 'bht',\n",
              "       'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht',\n",
              "       'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'oil_rate',\n",
              "       'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long',\n",
              "       'Rolling_short', 'Rolling_medium', 'Rolling_long', 'Lag_short',\n",
              "       'Lag_medium', 'Lag_long'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 305,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "KJZoa8Qneyzy"
      },
      "outputs": [],
      "source": [
        "identification_column = ['well_name', 'WELL_BORE_CODE', 'date']\n",
        "single_feature_columns = ['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']\n",
        "multiple_feature_columns = ['Lag_short', 'Lag_medium', 'Lag_long']\n",
        "feature_columns = single_feature_columns + multiple_feature_columns\n",
        "target_column = ['oil_rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr-v7jdxLqsb",
        "outputId": "c6baddd3-c5c4-48e4-e360-92bb0f37b089"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7987, 26)"
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[identification_column + feature_columns]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prod_hrs                -0.0\n",
            "bhp                      0.0\n",
            "bht                     -0.0\n",
            "dp_tubing                0.0\n",
            "AVG_ANNULUS_PRESS        0.0\n",
            "AVG_CHOKE_SIZE_P        -0.0\n",
            "whp                     -0.0\n",
            "wht                     -0.0\n",
            "choke_size_percentage    0.0\n",
            "oil_vol                  0.0\n",
            "gas_vol                  0.0\n",
            "water_vol                0.0\n",
            "linear_regressor        -0.0\n",
            "EMA_short                0.0\n",
            "EMA_medium              -0.0\n",
            "EMA_long                 0.0\n",
            "Rolling_short           -0.0\n",
            "Rolling_medium           0.0\n",
            "Rolling_long             0.0\n",
            "oil_rate                -0.0\n",
            "dtype: float64\n",
            "prod_hrs                 1.0\n",
            "bhp                      1.0\n",
            "bht                      1.0\n",
            "dp_tubing                1.0\n",
            "AVG_ANNULUS_PRESS        1.0\n",
            "AVG_CHOKE_SIZE_P         1.0\n",
            "whp                      1.0\n",
            "wht                      1.0\n",
            "choke_size_percentage    1.0\n",
            "oil_vol                  1.0\n",
            "gas_vol                  1.0\n",
            "water_vol                1.0\n",
            "linear_regressor         1.0\n",
            "EMA_short                1.0\n",
            "EMA_medium               1.0\n",
            "EMA_long                 1.0\n",
            "Rolling_short            1.0\n",
            "Rolling_medium           1.0\n",
            "Rolling_long             1.0\n",
            "oil_rate                 1.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(data[['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']].mean().round(4))\n",
        "print(data[['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']].std().round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "58-XDpb-EO82",
        "outputId": "f2517c61-2691-476e-dc5c-2a7ddad922b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>WELL_BORE_CODE</th>\n",
              "      <th>date</th>\n",
              "      <th>prod_hrs</th>\n",
              "      <th>bhp</th>\n",
              "      <th>bht</th>\n",
              "      <th>dp_tubing</th>\n",
              "      <th>AVG_ANNULUS_PRESS</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>whp</th>\n",
              "      <th>...</th>\n",
              "      <th>EMA_short</th>\n",
              "      <th>EMA_medium</th>\n",
              "      <th>EMA_long</th>\n",
              "      <th>Rolling_short</th>\n",
              "      <th>Rolling_medium</th>\n",
              "      <th>Rolling_long</th>\n",
              "      <th>oil_rate</th>\n",
              "      <th>Lag_short</th>\n",
              "      <th>Lag_medium</th>\n",
              "      <th>Lag_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>1.029309</td>\n",
              "      <td>0.605973</td>\n",
              "      <td>0.396165</td>\n",
              "      <td>-2.015211</td>\n",
              "      <td>-0.533280</td>\n",
              "      <td>3.281836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.495877</td>\n",
              "      <td>-0.498713</td>\n",
              "      <td>-0.502834</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.002700</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>-0.490501</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.845793</td>\n",
              "      <td>0.634777</td>\n",
              "      <td>0.239816</td>\n",
              "      <td>0.088574</td>\n",
              "      <td>-0.419656</td>\n",
              "      <td>2.849981</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.363747</td>\n",
              "      <td>-0.426301</td>\n",
              "      <td>-0.464667</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.002700</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>-0.098101</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, -0.4905010756171413]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.775023</td>\n",
              "      <td>0.639809</td>\n",
              "      <td>0.199889</td>\n",
              "      <td>-0.687843</td>\n",
              "      <td>-0.402874</td>\n",
              "      <td>2.607708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.180982</td>\n",
              "      <td>-0.315168</td>\n",
              "      <td>-0.402787</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.002700</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>0.183075</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.09810136648612545]</td>\n",
              "      <td>[0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.705031</td>\n",
              "      <td>0.642083</td>\n",
              "      <td>0.161491</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.379061</td>\n",
              "      <td>2.364038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.133505</td>\n",
              "      <td>-0.264997</td>\n",
              "      <td>-0.368282</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.002700</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>-0.037781</td>\n",
              "      <td>[-0.4905010756171413, -0.09810136648612545, 0....</td>\n",
              "      <td>[0.0, 0.0, -0.4905010756171413, -0.09810136648...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-26</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.625355</td>\n",
              "      <td>0.643889</td>\n",
              "      <td>0.117219</td>\n",
              "      <td>1.145565</td>\n",
              "      <td>-0.340115</td>\n",
              "      <td>2.088747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.077878</td>\n",
              "      <td>-0.210807</td>\n",
              "      <td>-0.330137</td>\n",
              "      <td>-0.084172</td>\n",
              "      <td>-0.002700</td>\n",
              "      <td>-0.005271</td>\n",
              "      <td>0.033425</td>\n",
              "      <td>[-0.09810136648612545, 0.18307478352672518, -0...</td>\n",
              "      <td>[0.0, -0.4905010756171413, -0.0981013664861254...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7982</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814176</td>\n",
              "      <td>1.149547</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.140330</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.693212</td>\n",
              "      <td>-0.702888</td>\n",
              "      <td>-0.716277</td>\n",
              "      <td>-0.692951</td>\n",
              "      <td>-0.704178</td>\n",
              "      <td>-0.725482</td>\n",
              "      <td>-0.681306</td>\n",
              "      <td>[-0.6834479858098645, -0.6925870358402809, -0....</td>\n",
              "      <td>[-0.6915821804196012, -0.6860958165169114, -0....</td>\n",
              "      <td>[-0.7117159623886966, -0.7111878631895072, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7983</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814176</td>\n",
              "      <td>1.159077</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.136215</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.689899</td>\n",
              "      <td>-0.699999</td>\n",
              "      <td>-0.713993</td>\n",
              "      <td>-0.690916</td>\n",
              "      <td>-0.700610</td>\n",
              "      <td>-0.723721</td>\n",
              "      <td>-0.676011</td>\n",
              "      <td>[-0.6925870358402809, -0.6822891014560878, -0....</td>\n",
              "      <td>[-0.6860958165169114, -0.6834479858098645, -0....</td>\n",
              "      <td>[-0.7111878631895072, -0.7027822842690761, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7984</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814176</td>\n",
              "      <td>1.141368</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.137527</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.688108</td>\n",
              "      <td>-0.697863</td>\n",
              "      <td>-0.712046</td>\n",
              "      <td>-0.689665</td>\n",
              "      <td>-0.698020</td>\n",
              "      <td>-0.721490</td>\n",
              "      <td>-0.677250</td>\n",
              "      <td>[-0.6822891014560878, -0.6813062501687076, -0....</td>\n",
              "      <td>[-0.6834479858098645, -0.6925870358402809, -0....</td>\n",
              "      <td>[-0.7027822842690761, -0.695718957479918, -0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7985</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-1.334973</td>\n",
              "      <td>-1.285316</td>\n",
              "      <td>-1.327392</td>\n",
              "      <td>1.140972</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.140776</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.686771</td>\n",
              "      <td>-0.696038</td>\n",
              "      <td>-0.710244</td>\n",
              "      <td>-0.686483</td>\n",
              "      <td>-0.696104</td>\n",
              "      <td>-0.719541</td>\n",
              "      <td>-0.676825</td>\n",
              "      <td>[-0.6813062501687076, -0.6760105887546141, -0....</td>\n",
              "      <td>[-0.6925870358402809, -0.6822891014560878, -0....</td>\n",
              "      <td>[-0.695718957479918, -0.689095713356751, -0.69...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7986</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-26</td>\n",
              "      <td>-0.744073</td>\n",
              "      <td>-0.434705</td>\n",
              "      <td>-0.323038</td>\n",
              "      <td>-0.323129</td>\n",
              "      <td>1.128012</td>\n",
              "      <td>0.671086</td>\n",
              "      <td>-1.123420</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.684923</td>\n",
              "      <td>-0.694020</td>\n",
              "      <td>-0.708337</td>\n",
              "      <td>-0.684807</td>\n",
              "      <td>-0.694571</td>\n",
              "      <td>-0.717138</td>\n",
              "      <td>-0.673985</td>\n",
              "      <td>[-0.6760105887546141, -0.6772501549304891, -0....</td>\n",
              "      <td>[-0.6822891014560878, -0.6813062501687076, -0....</td>\n",
              "      <td>[-0.689095713356751, -0.6915821804196012, -0.6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7987 rows Ã— 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      well_name  WELL_BORE_CODE        date  prod_hrs       bhp       bht  \\\n",
              "0          7405   NO 15/9-F-1 C  2014-04-22  0.268405  1.029309  0.605973   \n",
              "1          7405   NO 15/9-F-1 C  2014-04-23  0.268405  0.845793  0.634777   \n",
              "2          7405   NO 15/9-F-1 C  2014-04-24  0.268405  0.775023  0.639809   \n",
              "3          7405   NO 15/9-F-1 C  2014-04-25  0.268405  0.705031  0.642083   \n",
              "4          7405   NO 15/9-F-1 C  2014-04-26  0.268405  0.625355  0.643889   \n",
              "...         ...             ...         ...       ...       ...       ...   \n",
              "7982       5769  NO 15/9-F-5 AH  2016-08-22  0.268405 -0.880933 -0.806036   \n",
              "7983       5769  NO 15/9-F-5 AH  2016-08-23  0.268405 -0.880933 -0.806036   \n",
              "7984       5769  NO 15/9-F-5 AH  2016-08-24  0.268405 -0.880933 -0.806036   \n",
              "7985       5769  NO 15/9-F-5 AH  2016-08-25  0.268405 -1.334973 -1.285316   \n",
              "7986       5769  NO 15/9-F-5 AH  2016-08-26 -0.744073 -0.434705 -0.323038   \n",
              "\n",
              "      dp_tubing  AVG_ANNULUS_PRESS  AVG_CHOKE_SIZE_P       whp  ...  \\\n",
              "0      0.396165          -2.015211         -0.533280  3.281836  ...   \n",
              "1      0.239816           0.088574         -0.419656  2.849981  ...   \n",
              "2      0.199889          -0.687843         -0.402874  2.607708  ...   \n",
              "3      0.161491           1.145565         -0.379061  2.364038  ...   \n",
              "4      0.117219           1.145565         -0.340115  2.088747  ...   \n",
              "...         ...                ...               ...       ...  ...   \n",
              "7982  -0.814176           1.149547          1.150153 -1.140330  ...   \n",
              "7983  -0.814176           1.159077          1.150153 -1.136215  ...   \n",
              "7984  -0.814176           1.141368          1.150153 -1.137527  ...   \n",
              "7985  -1.327392           1.140972          1.150153 -1.140776  ...   \n",
              "7986  -0.323129           1.128012          0.671086 -1.123420  ...   \n",
              "\n",
              "      EMA_short  EMA_medium  EMA_long  Rolling_short  Rolling_medium  \\\n",
              "0     -0.495877   -0.498713 -0.502834      -0.001433       -0.002700   \n",
              "1     -0.363747   -0.426301 -0.464667      -0.001433       -0.002700   \n",
              "2     -0.180982   -0.315168 -0.402787      -0.001433       -0.002700   \n",
              "3     -0.133505   -0.264997 -0.368282      -0.001433       -0.002700   \n",
              "4     -0.077878   -0.210807 -0.330137      -0.084172       -0.002700   \n",
              "...         ...         ...       ...            ...             ...   \n",
              "7982  -0.693212   -0.702888 -0.716277      -0.692951       -0.704178   \n",
              "7983  -0.689899   -0.699999 -0.713993      -0.690916       -0.700610   \n",
              "7984  -0.688108   -0.697863 -0.712046      -0.689665       -0.698020   \n",
              "7985  -0.686771   -0.696038 -0.710244      -0.686483       -0.696104   \n",
              "7986  -0.684923   -0.694020 -0.708337      -0.684807       -0.694571   \n",
              "\n",
              "      Rolling_long  oil_rate  \\\n",
              "0        -0.005271 -0.490501   \n",
              "1        -0.005271 -0.098101   \n",
              "2        -0.005271  0.183075   \n",
              "3        -0.005271 -0.037781   \n",
              "4        -0.005271  0.033425   \n",
              "...            ...       ...   \n",
              "7982     -0.725482 -0.681306   \n",
              "7983     -0.723721 -0.676011   \n",
              "7984     -0.721490 -0.677250   \n",
              "7985     -0.719541 -0.676825   \n",
              "7986     -0.717138 -0.673985   \n",
              "\n",
              "                                              Lag_short  \\\n",
              "0                                       [0.0, 0.0, 0.0]   \n",
              "1                       [0.0, 0.0, -0.4905010756171413]   \n",
              "2      [0.0, -0.4905010756171413, -0.09810136648612545]   \n",
              "3     [-0.4905010756171413, -0.09810136648612545, 0....   \n",
              "4     [-0.09810136648612545, 0.18307478352672518, -0...   \n",
              "...                                                 ...   \n",
              "7982  [-0.6834479858098645, -0.6925870358402809, -0....   \n",
              "7983  [-0.6925870358402809, -0.6822891014560878, -0....   \n",
              "7984  [-0.6822891014560878, -0.6813062501687076, -0....   \n",
              "7985  [-0.6813062501687076, -0.6760105887546141, -0....   \n",
              "7986  [-0.6760105887546141, -0.6772501549304891, -0....   \n",
              "\n",
              "                                             Lag_medium  \\\n",
              "0                             [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "1             [0.0, 0.0, 0.0, 0.0, -0.4905010756171413]   \n",
              "2     [0.0, 0.0, 0.0, -0.4905010756171413, -0.098101...   \n",
              "3     [0.0, 0.0, -0.4905010756171413, -0.09810136648...   \n",
              "4     [0.0, -0.4905010756171413, -0.0981013664861254...   \n",
              "...                                                 ...   \n",
              "7982  [-0.6915821804196012, -0.6860958165169114, -0....   \n",
              "7983  [-0.6860958165169114, -0.6834479858098645, -0....   \n",
              "7984  [-0.6834479858098645, -0.6925870358402809, -0....   \n",
              "7985  [-0.6925870358402809, -0.6822891014560878, -0....   \n",
              "7986  [-0.6822891014560878, -0.6813062501687076, -0....   \n",
              "\n",
              "                                               Lag_long  \n",
              "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.49...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4905010...  \n",
              "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.490501075617...  \n",
              "...                                                 ...  \n",
              "7982  [-0.7117159623886966, -0.7111878631895072, -0....  \n",
              "7983  [-0.7111878631895072, -0.7027822842690761, -0....  \n",
              "7984  [-0.7027822842690761, -0.695718957479918, -0.6...  \n",
              "7985  [-0.695718957479918, -0.689095713356751, -0.69...  \n",
              "7986  [-0.689095713356751, -0.6915821804196012, -0.6...  \n",
              "\n",
              "[7987 rows x 26 columns]"
            ]
          },
          "execution_count": 309,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in multiple_feature_columns:\n",
        "    try:\n",
        "        data[column] = data[column].apply(ast.literal_eval)\n",
        "    except Exception:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OdDuXzow20l",
        "outputId": "88285f47-248e-473a-a500-a7c9b2fd9b09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "well_name                False\n",
              "WELL_BORE_CODE           False\n",
              "date                     False\n",
              "prod_hrs                 False\n",
              "bhp                      False\n",
              "bht                      False\n",
              "dp_tubing                False\n",
              "AVG_ANNULUS_PRESS        False\n",
              "AVG_CHOKE_SIZE_P         False\n",
              "whp                      False\n",
              "wht                      False\n",
              "choke_size_percentage    False\n",
              "oil_vol                  False\n",
              "gas_vol                  False\n",
              "water_vol                False\n",
              "linear_regressor         False\n",
              "EMA_short                False\n",
              "EMA_medium               False\n",
              "EMA_long                 False\n",
              "Rolling_short            False\n",
              "Rolling_medium           False\n",
              "Rolling_long             False\n",
              "oil_rate                 False\n",
              "Lag_short                False\n",
              "Lag_medium               False\n",
              "Lag_long                 False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 311,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 312,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the numerical index of the column 'oil_rate'\n",
        "column_name = 'oil_rate'\n",
        "column_index = data[feature_columns].columns.get_loc(column_name)\n",
        "column_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "1n-IMFYvNIta"
      },
      "outputs": [],
      "source": [
        "batch_size = 96\n",
        "days_window = 5\n",
        "predictions_days = 14\n",
        "training_gap = predictions_days + days_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "H77kZkM1lU5_",
        "outputId": "c9ef2650-18de-46b7-a650-93167d737eef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>inputs_dates</th>\n",
              "      <th>targets_dates</th>\n",
              "      <th>inputs_index</th>\n",
              "      <th>targets_index</th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7405</td>\n",
              "      <td>[2014-04-22, 2014-04-23, 2014-04-24, 2014-04-2...</td>\n",
              "      <td>[2014-04-27, 2014-04-28, 2014-04-29, 2014-04-3...</td>\n",
              "      <td>[0, 1, 2, 3, 4]</td>\n",
              "      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...</td>\n",
              "      <td>[[0.2684054414666464, 1.0293086129008744, 0.60...</td>\n",
              "      <td>[[0.0361971937521761], [0.0332999828677342], [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7405</td>\n",
              "      <td>[2014-04-23, 2014-04-24, 2014-04-25, 2014-04-2...</td>\n",
              "      <td>[2014-04-28, 2014-04-29, 2014-04-30, 2014-05-0...</td>\n",
              "      <td>[1, 2, 3, 4, 5]</td>\n",
              "      <td>[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1...</td>\n",
              "      <td>[[0.2684054414666464, 0.8457926690107068, 0.63...</td>\n",
              "      <td>[[0.0332999828677342], [-0.0152191310577907], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7405</td>\n",
              "      <td>[2014-04-24, 2014-04-25, 2014-04-26, 2014-04-2...</td>\n",
              "      <td>[2014-04-29, 2014-04-30, 2014-05-01, 2014-05-0...</td>\n",
              "      <td>[2, 3, 4, 5, 6]</td>\n",
              "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, ...</td>\n",
              "      <td>[[0.2684054414666464, 0.7750228696616299, 0.63...</td>\n",
              "      <td>[[-0.0152191310577907], [-0.0547092156193974],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7405</td>\n",
              "      <td>[2014-04-25, 2014-04-26, 2014-04-27, 2014-04-2...</td>\n",
              "      <td>[2014-04-30, 2014-05-01, 2014-05-02, 2014-05-0...</td>\n",
              "      <td>[3, 4, 5, 6, 7]</td>\n",
              "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
              "      <td>[[0.2684054414666464, 0.7050308265409722, 0.64...</td>\n",
              "      <td>[[-0.0547092156193974], [-0.0640389681384098],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7405</td>\n",
              "      <td>[2014-04-26, 2014-04-27, 2014-04-28, 2014-04-2...</td>\n",
              "      <td>[2014-05-01, 2014-05-02, 2014-05-03, 2014-05-0...</td>\n",
              "      <td>[4, 5, 6, 7, 8]</td>\n",
              "      <td>[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20...</td>\n",
              "      <td>[[0.2684054414666464, 0.6253548436655879, 0.64...</td>\n",
              "      <td>[[-0.0640389681384098], [-0.1658887664709635],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7874</th>\n",
              "      <td>5769</td>\n",
              "      <td>[2016-08-04, 2016-08-05, 2016-08-06, 2016-08-0...</td>\n",
              "      <td>[2016-08-09, 2016-08-10, 2016-08-11, 2016-08-1...</td>\n",
              "      <td>[7964, 7965, 7966, 7967, 7968]</td>\n",
              "      <td>[7969, 7970, 7971, 7972, 7973, 7974, 7975, 797...</td>\n",
              "      <td>[[0.2684054414666464, -0.475522612140657, -0.3...</td>\n",
              "      <td>[[-0.730276391937718], [-0.7220799091727883], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7875</th>\n",
              "      <td>5769</td>\n",
              "      <td>[2016-08-05, 2016-08-06, 2016-08-07, 2016-08-0...</td>\n",
              "      <td>[2016-08-10, 2016-08-11, 2016-08-12, 2016-08-1...</td>\n",
              "      <td>[7965, 7966, 7967, 7968, 7969]</td>\n",
              "      <td>[7970, 7971, 7972, 7973, 7974, 7975, 7976, 797...</td>\n",
              "      <td>[[0.2684054414666464, -0.475522612140657, -0.3...</td>\n",
              "      <td>[[-0.7220799091727883], [-0.7175543924241792],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7876</th>\n",
              "      <td>5769</td>\n",
              "      <td>[2016-08-06, 2016-08-07, 2016-08-08, 2016-08-0...</td>\n",
              "      <td>[2016-08-11, 2016-08-12, 2016-08-13, 2016-08-1...</td>\n",
              "      <td>[7966, 7967, 7968, 7969, 7970]</td>\n",
              "      <td>[7971, 7972, 7973, 7974, 7975, 7976, 7977, 797...</td>\n",
              "      <td>[[0.2684054414666464, -0.475522612140657, -0.3...</td>\n",
              "      <td>[[-0.7175543924241792], [-0.7117159623886966],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7877</th>\n",
              "      <td>5769</td>\n",
              "      <td>[2016-08-07, 2016-08-08, 2016-08-09, 2016-08-1...</td>\n",
              "      <td>[2016-08-12, 2016-08-13, 2016-08-14, 2016-08-1...</td>\n",
              "      <td>[7967, 7968, 7969, 7970, 7971]</td>\n",
              "      <td>[7972, 7973, 7974, 7975, 7976, 7977, 7978, 797...</td>\n",
              "      <td>[[0.2684054414666464, -0.475522612140657, -0.3...</td>\n",
              "      <td>[[-0.7117159623886966], [-0.7111878631895072],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7878</th>\n",
              "      <td>5769</td>\n",
              "      <td>[2016-08-08, 2016-08-09, 2016-08-10, 2016-08-1...</td>\n",
              "      <td>[2016-08-13, 2016-08-14, 2016-08-15, 2016-08-1...</td>\n",
              "      <td>[7968, 7969, 7970, 7971, 7972]</td>\n",
              "      <td>[7973, 7974, 7975, 7976, 7977, 7978, 7979, 798...</td>\n",
              "      <td>[[0.2684054414666464, -0.475522612140657, -0.3...</td>\n",
              "      <td>[[-0.7111878631895072], [-0.7027822842690761],...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7879 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      well_name                                       inputs_dates  \\\n",
              "0          7405  [2014-04-22, 2014-04-23, 2014-04-24, 2014-04-2...   \n",
              "1          7405  [2014-04-23, 2014-04-24, 2014-04-25, 2014-04-2...   \n",
              "2          7405  [2014-04-24, 2014-04-25, 2014-04-26, 2014-04-2...   \n",
              "3          7405  [2014-04-25, 2014-04-26, 2014-04-27, 2014-04-2...   \n",
              "4          7405  [2014-04-26, 2014-04-27, 2014-04-28, 2014-04-2...   \n",
              "...         ...                                                ...   \n",
              "7874       5769  [2016-08-04, 2016-08-05, 2016-08-06, 2016-08-0...   \n",
              "7875       5769  [2016-08-05, 2016-08-06, 2016-08-07, 2016-08-0...   \n",
              "7876       5769  [2016-08-06, 2016-08-07, 2016-08-08, 2016-08-0...   \n",
              "7877       5769  [2016-08-07, 2016-08-08, 2016-08-09, 2016-08-1...   \n",
              "7878       5769  [2016-08-08, 2016-08-09, 2016-08-10, 2016-08-1...   \n",
              "\n",
              "                                          targets_dates  \\\n",
              "0     [2014-04-27, 2014-04-28, 2014-04-29, 2014-04-3...   \n",
              "1     [2014-04-28, 2014-04-29, 2014-04-30, 2014-05-0...   \n",
              "2     [2014-04-29, 2014-04-30, 2014-05-01, 2014-05-0...   \n",
              "3     [2014-04-30, 2014-05-01, 2014-05-02, 2014-05-0...   \n",
              "4     [2014-05-01, 2014-05-02, 2014-05-03, 2014-05-0...   \n",
              "...                                                 ...   \n",
              "7874  [2016-08-09, 2016-08-10, 2016-08-11, 2016-08-1...   \n",
              "7875  [2016-08-10, 2016-08-11, 2016-08-12, 2016-08-1...   \n",
              "7876  [2016-08-11, 2016-08-12, 2016-08-13, 2016-08-1...   \n",
              "7877  [2016-08-12, 2016-08-13, 2016-08-14, 2016-08-1...   \n",
              "7878  [2016-08-13, 2016-08-14, 2016-08-15, 2016-08-1...   \n",
              "\n",
              "                        inputs_index  \\\n",
              "0                    [0, 1, 2, 3, 4]   \n",
              "1                    [1, 2, 3, 4, 5]   \n",
              "2                    [2, 3, 4, 5, 6]   \n",
              "3                    [3, 4, 5, 6, 7]   \n",
              "4                    [4, 5, 6, 7, 8]   \n",
              "...                              ...   \n",
              "7874  [7964, 7965, 7966, 7967, 7968]   \n",
              "7875  [7965, 7966, 7967, 7968, 7969]   \n",
              "7876  [7966, 7967, 7968, 7969, 7970]   \n",
              "7877  [7967, 7968, 7969, 7970, 7971]   \n",
              "7878  [7968, 7969, 7970, 7971, 7972]   \n",
              "\n",
              "                                          targets_index  \\\n",
              "0     [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...   \n",
              "1     [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1...   \n",
              "2     [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, ...   \n",
              "3     [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
              "4     [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20...   \n",
              "...                                                 ...   \n",
              "7874  [7969, 7970, 7971, 7972, 7973, 7974, 7975, 797...   \n",
              "7875  [7970, 7971, 7972, 7973, 7974, 7975, 7976, 797...   \n",
              "7876  [7971, 7972, 7973, 7974, 7975, 7976, 7977, 797...   \n",
              "7877  [7972, 7973, 7974, 7975, 7976, 7977, 7978, 797...   \n",
              "7878  [7973, 7974, 7975, 7976, 7977, 7978, 7979, 798...   \n",
              "\n",
              "                                                 inputs  \\\n",
              "0     [[0.2684054414666464, 1.0293086129008744, 0.60...   \n",
              "1     [[0.2684054414666464, 0.8457926690107068, 0.63...   \n",
              "2     [[0.2684054414666464, 0.7750228696616299, 0.63...   \n",
              "3     [[0.2684054414666464, 0.7050308265409722, 0.64...   \n",
              "4     [[0.2684054414666464, 0.6253548436655879, 0.64...   \n",
              "...                                                 ...   \n",
              "7874  [[0.2684054414666464, -0.475522612140657, -0.3...   \n",
              "7875  [[0.2684054414666464, -0.475522612140657, -0.3...   \n",
              "7876  [[0.2684054414666464, -0.475522612140657, -0.3...   \n",
              "7877  [[0.2684054414666464, -0.475522612140657, -0.3...   \n",
              "7878  [[0.2684054414666464, -0.475522612140657, -0.3...   \n",
              "\n",
              "                                                targets  \n",
              "0     [[0.0361971937521761], [0.0332999828677342], [...  \n",
              "1     [[0.0332999828677342], [-0.0152191310577907], ...  \n",
              "2     [[-0.0152191310577907], [-0.0547092156193974],...  \n",
              "3     [[-0.0547092156193974], [-0.0640389681384098],...  \n",
              "4     [[-0.0640389681384098], [-0.1658887664709635],...  \n",
              "...                                                 ...  \n",
              "7874  [[-0.730276391937718], [-0.7220799091727883], ...  \n",
              "7875  [[-0.7220799091727883], [-0.7175543924241792],...  \n",
              "7876  [[-0.7175543924241792], [-0.7117159623886966],...  \n",
              "7877  [[-0.7117159623886966], [-0.7111878631895072],...  \n",
              "7878  [[-0.7111878631895072], [-0.7027822842690761],...  \n",
              "\n",
              "[7879 rows x 7 columns]"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sequences = []\n",
        "# for well_name in data['well_name'].unique():\n",
        "#     well_data = data[data['well_name'] == well_name].sort_values(by='date').reset_index()\n",
        "#     for i in range(len(well_data) - training_gap + 1):\n",
        "#         single_features = np.array(well_data.iloc[i:i + days_window][single_feature_columns])\n",
        "#         multiple_features = np.array(well_data.iloc[i:i + days_window][multiple_feature_columns])\n",
        "#         multiple_flattened = []\n",
        "#         for k in multiple_features:\n",
        "#            flattened_list = [item for sublist in k for item in sublist]\n",
        "#            multiple_flattened.append(flattened_list)\n",
        "#         multiple_flattened = np.array(multiple_flattened)\n",
        "#         inputs = np.concatenate((single_features, multiple_flattened), axis=1)\n",
        "#         targets = well_data.iloc[i + days_window:i + days_window + predictions_days][target_column].values\n",
        "#         inputs_dates = list(well_data.iloc[i:i + days_window]['date'])\n",
        "#         targets_dates = list(well_data.iloc[i + days_window:i + days_window + predictions_days]['date'])\n",
        "#         inputs_index = list(well_data.iloc[i:i + days_window]['index'])\n",
        "#         targets_index = list(well_data.iloc[i + days_window:i + days_window + predictions_days]['index'])\n",
        "#         sequences.append((well_name, inputs_dates, targets_dates, inputs_index, targets_index, inputs, targets))\n",
        "#         if len(well_data.iloc[i:i + days_window + predictions_days]['well_name'].unique()) > 1:\n",
        "#           print('violation')\n",
        "\n",
        "# dataset = pd.DataFrame(sequences, columns=['well_name', 'inputs_dates', 'targets_dates', 'inputs_index', 'targets_index', 'inputs', 'targets', ])\n",
        "# dataset.to_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "# dataset.to_csv(path + \"/data/Volve/all_data.csv\")\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "fibAgggFAAhT"
      },
      "outputs": [],
      "source": [
        "train_size = 0.6\n",
        "val_size = 0.2\n",
        "test_size = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "Nbxt8qRjwm4U"
      },
      "outputs": [],
      "source": [
        "test_size_param1 = test_size\n",
        "test_size_param2 = val_size / (1 - test_size_param1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLKPdjjBb6O",
        "outputId": "4f0bf1d7-932a-4cf3-a45b-231392ffaea5"
      },
      "outputs": [],
      "source": [
        "# For shuffled train/val\n",
        "\n",
        "# dataset = pd.read_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "train_wells = []\n",
        "test_wells = []\n",
        "for i in well_info.keys():\n",
        "    well = dataset[dataset['well_name'] == i]\n",
        "    train_set_length = int((train_size + val_size) * len(well))\n",
        "    train_wells.append(well[:train_set_length + 1])\n",
        "    test_set_length = int(test_size * len(well))\n",
        "    test_wells.append(well[-test_set_length:])\n",
        "\n",
        "# Flatten the lists of DataFrames\n",
        "temp_data = pd.concat(train_wells).reset_index(drop=True)\n",
        "data_test = pd.concat(test_wells).reset_index(drop=True)\n",
        "\n",
        "\n",
        "data_train, data_val = train_test_split(temp_data, test_size=test_size_param2, stratify=temp_data['well_name'], shuffle=True)\n",
        "\n",
        "data_train.reset_index(drop=True, inplace=True)\n",
        "data_val.reset_index(drop=True, inplace=True)\n",
        "data_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "data_train.to_pickle(path + \"/data/Volve/data_train.pkl\")\n",
        "data_val.to_pickle(path + \"/data/Volve/data_val.pkl\")\n",
        "data_test.to_pickle(path + \"/data/Volve/data_test.pkl\")\n",
        "\n",
        "data_train.to_csv(path + \"/data/Volve/data_train.csv\")\n",
        "data_val.to_csv(path + \"/data/Volve/data_val.csv\")\n",
        "data_test.to_csv(path + \"/data/Volve/data_test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For in order train/val\n",
        "\n",
        "# dataset = pd.read_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "\n",
        "# # Initialize lists to store DataFrames for each well\n",
        "# train_wells = []\n",
        "# val_wells = []\n",
        "# test_wells = []\n",
        "\n",
        "# # Iterate over each well and split the data\n",
        "# for well_name in well_info.keys():\n",
        "#     well = dataset[dataset['well_name'] == well_name]\n",
        "#     train_set_length = int(train_size * len(well))\n",
        "#     val_set_length = int(val_size * len(well))\n",
        "#     test_set_length = int(test_size * len(well))\n",
        "    \n",
        "#     train_wells.append(well[:train_set_length])\n",
        "#     val_wells.append(well[train_set_length:train_set_length + val_set_length])\n",
        "#     test_wells.append(well[-test_set_length:])\n",
        "\n",
        "# # Flatten the lists of DataFrames\n",
        "# data_train = pd.concat(train_wells).reset_index(drop=True)\n",
        "# data_val = pd.concat(val_wells).reset_index(drop=True)\n",
        "# data_test = pd.concat(test_wells).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data = pd.read_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "data_train = pd.read_pickle(path + \"/data/Volve/data_train.pkl\")\n",
        "data_val = pd.read_pickle(path + \"/data/Volve/data_val.pkl\")\n",
        "data_test = pd.read_pickle(path + \"/data/Volve/data_test.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all_data = pd.read_csv(path + \"/data/Volve/all_data.csv\")\n",
        "# data_train = pd.read_csv(path + \"/data/Volve/data_train.csv\")\n",
        "# data_val = pd.read_csv(path + \"/data/Volve/data_val.csv\")\n",
        "# data_test = pd.read_csv(path + \"/data/Volve/data_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for df in [all_data, data_train, data_val, data_test]:\n",
        "#     # Ensure each entry in 'inputs' and 'targets' is a NumPy array\n",
        "#     df['inputs'] = df['inputs'].apply(lambda x: np.array(x, dtype=np.float32))\n",
        "#     df['targets'] = df['targets'].apply(lambda x: np.array(x, dtype=np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4730, 7), (1577, 7), (1573, 7))"
            ]
          },
          "execution_count": 284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train.shape, data_val.shape, data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input/output gap is fine\n"
          ]
        }
      ],
      "source": [
        "check = True\n",
        "for i, j in well_info.items():\n",
        "    if len(all_data[all_data['well_name'] == i]) < 10:\n",
        "        print(\"The input/output gap is too high for well\", i)\n",
        "        check = False\n",
        "if check:\n",
        "    print(\"The input/output gap is fine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All datasets have all wells\n"
          ]
        }
      ],
      "source": [
        "check=True\n",
        "for i in [data_train, data_val, data_test]:\n",
        "    for j in well_info.keys():\n",
        "        if j not in set(list(i['well_name'])):\n",
        "            print(\"Some datasets do not have specific well\")\n",
        "            check = False\n",
        "            break\n",
        "if check:\n",
        "    print(\"All datasets have all wells\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in [data_train, data_val, data_test]:\n",
        "    for column in df.columns:\n",
        "        try:\n",
        "            data[column] = data[column].apply(ast.literal_eval)\n",
        "        except Exception:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5, 38), (14, 1))"
            ]
          },
          "execution_count": 322,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train['inputs'][0].shape, data_train['targets'][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mps'"
            ]
          },
          "execution_count": 323,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "elif torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu' \n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "SZXwNYhTO9V_"
      },
      "outputs": [],
      "source": [
        "eval_interval = 500\n",
        "test_eval_interval = 500\n",
        "test_iterations = 7500\n",
        "warmup_steps = 6000 # hyper-parameters for hyperprameter finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "DOEruC1tFSSk"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_length, hidden_length, output_length, num_layers, dropout=0):\n",
        "        super().__init__()\n",
        "        self.input_length = input_length\n",
        "        self.hidden_length = hidden_length\n",
        "        self.output_length = output_length\n",
        "        self.init_hidden = nn.Parameter(torch.zeros(num_layers, 1, hidden_length))\n",
        "        self.init_cell = nn.Parameter(torch.zeros(num_layers, 1, hidden_length))\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_cell = nn.LSTM(self.input_length, self.hidden_length, self.num_layers, batch_first=True)\n",
        "        self.output_layer = nn.Linear(self.hidden_length, self.output_length)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, targets=None):\n",
        "        B, T, C = x.shape\n",
        "        init_hidden = self.init_hidden.repeat(1, B, 1)\n",
        "        init_cell = self.init_cell.repeat(1, B, 1)\n",
        "        cell_output, _ = self.lstm_cell(x, (init_hidden, init_cell))\n",
        "        cell_dropout = self.dropout(cell_output)\n",
        "        logits = self.output_layer(cell_dropout[:, -1, :])\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T = logits.shape\n",
        "            logits = logits.view(B*T)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.mse_loss(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def get_hyperparameters(self):\n",
        "        return {'input_length': self.input_length, 'hidden_length': self.hidden_length, 'output_length': self.output_length, 'num_layers': self.num_layers, 'dropout': self.dropout}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "dPVTSvxu1cVQ"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, sequences_df):\n",
        "        self.sequences_df = sequences_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.sequences_df.iloc[idx]['inputs']\n",
        "        targets = self.sequences_df.iloc[idx]['targets']\n",
        "        torch.tensor(targets, dtype=torch.float32).squeeze()\n",
        "        # return torch.tensor(np.array(inputs, dtype=np.float32), dtype=torch.float32), torch.tensor(np.array(targets, dtype=np.float32), dtype=torch.float32).squeeze()\n",
        "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).squeeze()\n",
        "\n",
        "\n",
        "train_dataset = TimeSeriesDataset(data_train)\n",
        "val_dataset = TimeSeriesDataset(data_val)\n",
        "test_dataset = TimeSeriesDataset(data_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VisualizationTimeSeriesDataset(Dataset):\n",
        "    def __init__(self, sequences_df):\n",
        "        self.sequences_df = sequences_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.sequences_df.iloc[idx]['inputs']\n",
        "        targets = self.sequences_df.iloc[idx]['targets']\n",
        "        well_name = self.sequences_df.iloc[idx]['well_name']\n",
        "        inputs_dates = self.sequences_df.iloc[idx]['inputs_dates']\n",
        "        targets_dates = self.sequences_df.iloc[idx]['targets_dates']\n",
        "\n",
        "        return well_name, inputs_dates, targets_dates, torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).squeeze()\n",
        "\n",
        "visualization_test_dataset = VisualizationTimeSeriesDataset(data_test)\n",
        "\n",
        "visualization_test_loader = DataLoader(visualization_test_dataset, batch_size=int(len(test_dataset) / 50), shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_length = data_train['inputs'][0].shape[1]\n",
        "output_length = predictions_days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "id": "0h7KW6y9PatC"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss(model): # Function to estimate train and val loss while training\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    out = {}\n",
        "    loaders = {'train': train_loader, 'val': val_loader}\n",
        "    for mode in ['train', 'val']:\n",
        "        losses = []\n",
        "        # Iterate over the DataLoader for a fixed number of batches\n",
        "        for X_batch, Y_batch in loaders[mode]:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            logits, loss = model(X_batch, Y_batch)  # Run inputs and expected outputs through model to get loss\n",
        "            losses.append(loss.item())  # Add value to losses list\n",
        "        out[mode] = torch.tensor(losses).mean().item()  # Get mean of losses tensor and save it\n",
        "    model.train()  # Put model back in train mode\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_params(model, optimizer, scheduler, name=\"\"): # function to save parameters, optimizer and scheduler states\n",
        "    config_path = path + r'/Models/Global/LSTM/Model/State/'\n",
        "    model_path = path + r'/Models/Global/LSTM/Model/Complete/'\n",
        "    if name != \"\":\n",
        "        name = f'{name}_'\n",
        "    torch.save(model.state_dict(), config_path + f'{name}state_params.pth') # to save parameters\n",
        "    torch.save(optimizer.state_dict(), config_path + f'{name}state_optimizer.pth') # to save optimizer state\n",
        "    torch.save(scheduler.state_dict(), config_path + f'{name}state_scheduler.pth') # to save scheduler states\n",
        "    torch.save(model, model_path + f'{name}complete_params.pth')\n",
        "    torch.save(optimizer, model_path + f'{name}complete_optimizer.pth') \n",
        "    torch.save(scheduler, model_path + f'{name}complete_scheduler.pth')\n",
        "\n",
        "def get_next_log_file(log_dir, prefix=\"training_run_\"):\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "        return os.path.join(log_dir, f\"{prefix}1.txt\")\n",
        "    existing_files = os.listdir(log_dir)\n",
        "    log_numbers = []\n",
        "    for filename in existing_files:\n",
        "        match = re.match(rf\"{prefix}(\\d+).txt\", filename)\n",
        "        if match:\n",
        "            log_numbers.append(int(match.group(1)))\n",
        "    if log_numbers:\n",
        "        next_number = max(log_numbers) + 1\n",
        "    else:\n",
        "        next_number = 1\n",
        "    return os.path.join(log_dir, f\"{prefix}{next_number}.txt\")\n",
        "\n",
        "def log_to_file(log_file, message):\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(message + '\\n')\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(mode, model):\n",
        "    loader_dict = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
        "    loader = loader_dict[mode]\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    test_losses = []\n",
        "    for X_batch, Y_batch in loader:\n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "        logits, loss = model(X_batch, Y_batch)  # Run inputs and expected outputs through model to get loss\n",
        "        test_losses.append(loss.item())  # Collect test loss\n",
        "        B, T = Y_batch.shape\n",
        "        Y_batch = Y_batch.view(B*T)\n",
        "        # Convert predictions and targets to NumPy arrays\n",
        "        all_preds.append(logits.cpu().numpy())  # .cpu() moves tensor to CPU, .numpy() converts to NumPy array\n",
        "        all_targets.append(Y_batch.cpu().numpy())\n",
        "    # Concatenate all predictions and targets\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    all_targets = np.concatenate(all_targets, axis=0)\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_metrics(all_targets, all_preds)\n",
        "    metrics['Loss'] = np.mean(test_losses)\n",
        "    print(f\"Metrics on {mode} set:\\n\")\n",
        "    print(f\"Loss is {metrics['Loss']:.4f}\")\n",
        "    print(f\"MAE is {metrics['MAE']:.4f}\")\n",
        "    print(f\"RMSE is {metrics['RMSE']:.4f}\")\n",
        "    print(f\"RÂ² is {metrics['R2']:.4f}\")\n",
        "    print(\"\\n\")\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Define an objective function for Optuna\n",
        "def objective(trial):\n",
        "    vector_length = trial.suggest_int('vector_length', 16, 2048, step=16)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 5) # maybe increase it to 6\n",
        "    dropout = trial.suggest_float('dropout', 0.1, 0.6)\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
        "    gamma = trial.suggest_float('gamma', 0.95, 0.99)\n",
        "    model = LSTM(input_length=input_length, hidden_length=vector_length, output_length=output_length, num_layers=num_layers, dropout=dropout).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # setting optimizer scheduler\n",
        "    train_loader_iter = iter(train_loader)\n",
        "    # Training loop\n",
        "    for i in range(test_iterations):\n",
        "        model.train()\n",
        "        if (i % test_eval_interval == 0 or i == test_iterations - 1):\n",
        "            losses = estimate_loss(model)\n",
        "            trial.report(losses['val'], i)\n",
        "            if i != 0:\n",
        "                scheduler.step()\n",
        "            # if i >= warmup_steps and trial.should_prune():\n",
        "            #     raise optuna.TrialPruned()\n",
        "        try:\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "        except StopIteration:\n",
        "            train_loader_iter = iter(train_loader)\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "            \n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "        logits, loss = model(X_batch, Y_batch)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    val_metrics = evaluate('val', model)\n",
        "    return val_metrics['Loss']\n",
        "\n",
        "def load_model(name=\"\"): \n",
        "    config_path = path + r'/Models/Global/LSTM/Model/Complete/'\n",
        "    if name != \"\":\n",
        "        name = f'{name}_'\n",
        "    model = torch.load(config_path + f'{name}complete_params.pth')\n",
        "    optimizer = torch.load(config_path + f'{name}complete_optimizer.pth')\n",
        "    scheduler = torch.load(config_path + f'{name}complete_scheduler.pth')\n",
        "    return model, optimizer, scheduler\n",
        "\n",
        "def get_oil_history(date, well_name):\n",
        "    well = data[data[\"well_name\"] == int(well_name)].reset_index(drop=True)\n",
        "    well = well[pd.to_datetime(well['date']) < date]\n",
        "    return well['oil_rate']\n",
        "\n",
        "def rename(config_path, model_path, old_name, new_name):\n",
        "    os.rename(config_path + f'{old_name}state_params.pth', config_path + f'{new_name}state_params.pth')\n",
        "    os.rename(config_path + f'{old_name}state_optimizer.pth', config_path + f'{new_name}state_optimizer.pth')\n",
        "    os.rename(config_path + f'{old_name}state_scheduler.pth', config_path + f'{new_name}state_scheduler.pth')\n",
        "    os.rename(model_path + f'{old_name}complete_params.pth', model_path + f'{new_name}complete_params.pth')\n",
        "    os.rename(model_path + f'{old_name}complete_optimizer.pth', model_path + f'{new_name}complete_optimizer.pth')\n",
        "    os.rename(model_path + f'{old_name}complete_scheduler.pth', model_path + f'{new_name}complete_scheduler.pth')\n",
        "    \n",
        "def label_model_files(old_name=\"\", new_name=\"\"):\n",
        "    if old_name != \"\":\n",
        "        old_name = f'{old_name}_'\n",
        "    if new_name != \"\":\n",
        "        new_name = f'{new_name}_'\n",
        "    config_path = path + r'/Models/Global/LSTM/Model/State/'\n",
        "    model_path = path + r'/Models/Global/LSTM/Model/Complete/'\n",
        "    if os.path.exists(config_path + f'{new_name}state_params.pth'):\n",
        "        try:\n",
        "            user_choice = int(input(\"File with new name already exists. Enter 1 if you want to overwrite the files. Otherwise press 2: \"))\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter 1 or 2.\")\n",
        "            return\n",
        "        if user_choice == 1:\n",
        "            try:\n",
        "                rename(config_path, model_path, old_name, new_name)\n",
        "                print(\"Files have been renamed successfully.\")\n",
        "            except FileNotFoundError:\n",
        "                print(\"One or more files not found.\")\n",
        "        elif user_choice == 2:\n",
        "            print(\"Operation cancelled by the user.\")\n",
        "        else:\n",
        "            print(\"Invalid choice. Operation cancelled.\")\n",
        "    else:\n",
        "        try:\n",
        "            rename(config_path, model_path, old_name, new_name)\n",
        "            print(\"Files have been renamed successfully.\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"One or more files not found.\")\n",
        "\n",
        "def predictions_with_history_graphs(model, visualization_loader, path):\n",
        "    pdf = PdfPages(path + \"/predictions_with_history.pdf\")\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for well_name, inputs_dates, targets_dates, X_batch, Y_batch in visualization_loader:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            choice = random.randint(0, len(X_batch) - 1)\n",
        "            X_batch = X_batch[choice].unsqueeze(0)\n",
        "            Y_batch = Y_batch[choice]\n",
        "            well_name = well_name[choice]\n",
        "            inputs_dates = [i[choice] for i in inputs_dates]\n",
        "            targets_dates = [i[choice] for i in targets_dates]\n",
        "\n",
        "            history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "            logits, loss = model(X_batch, Y_batch)\n",
        "            label = Y_batch.cpu().numpy()\n",
        "            prediction = logits.cpu().numpy()\n",
        "            rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "            # Plotting\n",
        "            forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(range(1, len(history) + 1), history, label='Input Values')\n",
        "            plt.plot(forecast_index, prediction, label='Forecasted Values')\n",
        "            plt.plot(forecast_index, label, label='Actual Values')\n",
        "            # Determine the interval for ticks to have approximately 10 ticks\n",
        "            tick_interval = max(10, round((len(history) + predictions_days + 1) / 10 / 10) * 10)\n",
        "            # Generate tick positions\n",
        "            tick_positions = np.arange(0, len(history) + predictions_days + 1, tick_interval)\n",
        "            tick_positions[0] = 1  # Start tick at 1 instead of 0\n",
        "\n",
        "            # Generate tick labels\n",
        "            tick_labels = tick_positions\n",
        "            plt.xticks(ticks=tick_positions, labels=tick_labels)\n",
        "            plt.axvline(x=len(history), color='r', linestyle='--', label='Forecast Start')\n",
        "            plt.xlabel('Day')\n",
        "            plt.ylabel('Value')\n",
        "            plt.title(f'Well: {well_name}, Loss: {loss:.4f}, RMSE = {rmse:.4f}')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            # Save the current figure to the PDF\n",
        "            pdf.savefig()\n",
        "            plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def predictions_graphs(model, visualization_loader, path):\n",
        "    pdf = PdfPages(path + \"/predictions.pdf\")\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for well_name, inputs_dates, targets_dates, X_batch, Y_batch in visualization_loader:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            choice = random.randint(0, len(X_batch) - 1)\n",
        "            X_batch = X_batch[choice].unsqueeze(0)\n",
        "            Y_batch = Y_batch[choice]\n",
        "            well_name = well_name[choice]\n",
        "            logits, loss = model(X_batch, Y_batch)\n",
        "            inputs = X_batch[0][:, column_index].cpu().numpy()\n",
        "            label = Y_batch.cpu().numpy()\n",
        "            prediction = logits.cpu().numpy()\n",
        "            rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "            # Plotting\n",
        "            forecast_index = range(len(inputs) + 1, len(inputs) + predictions_days + 1)\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(range(1, len(inputs) + 1), inputs, marker='o', label='Input Values')\n",
        "            plt.plot(forecast_index, prediction, marker='o', label='Forecasted Values')\n",
        "            plt.plot(forecast_index, label, marker='o', label='Actual Values')\n",
        "            plt.xticks(ticks=np.arange(1, len(inputs) + predictions_days + 1), labels=np.arange(1, len(inputs) + predictions_days + 1))\n",
        "            plt.axvline(x=len(inputs), color='r', linestyle='--', label='Forecast Start')\n",
        "            plt.xlabel('Day')\n",
        "            plt.ylabel('Value')\n",
        "            plt.title(f'Well: {well_name}, Loss: {loss:.4f}, RMSE: {rmse:.4f}')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            # Save the current figure to the PDF\n",
        "            pdf.savefig()\n",
        "            plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def all_predictions_graphs(model, data, data_test, path):\n",
        "    well_dataloaders = {}\n",
        "    pdf = PdfPages(path + \"/all_predictions.pdf\")\n",
        "    with torch.no_grad():\n",
        "        for well_name in well_info.keys():\n",
        "            well = data[data['well_name'] == well_name].reset_index(drop=True)\n",
        "            fig, ax = plt.subplots(figsize=(15, 6))\n",
        "            ax.plot(well.index, well['oil_rate'], label='Well Production')\n",
        "            ax.axvline(x=int((1 - test_size) * len(well) - days_window - 2), color='r', linestyle='--',)\n",
        "            ax.legend()\n",
        "            well_dataset = VisualizationTimeSeriesDataset(data_test[data_test['well_name'] == well_name].reset_index(drop=True))\n",
        "            well_dataloaders[well_name] = DataLoader(well_dataset, batch_size=1, shuffle=False)\n",
        "            total_loss = 0\n",
        "            total_rmse = 0\n",
        "            for _, inputs_dates, targets_dates, X_batch, Y_batch in well_dataloaders[well_name]:\n",
        "                inputs_dates = np.array(inputs_dates).T[0]\n",
        "                targets_dates = np.array(targets_dates).T[0]\n",
        "                history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "                logits, loss = model(X_batch, Y_batch)\n",
        "                label = Y_batch.cpu().numpy().reshape(-1)\n",
        "                prediction = logits.cpu().numpy()\n",
        "                rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "                total_loss += loss\n",
        "                total_rmse += rmse\n",
        "                forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "                ax.plot(forecast_index, prediction, label='Forecasted Values', color='y')\n",
        "                if i == 0:\n",
        "                    ax.legend()\n",
        "            avg_loss = total_loss / len(well_dataloaders[well_name]) \n",
        "            avg_rmse = total_rmse / len(well_dataloaders[well_name]) \n",
        "            ax.set_xlabel('Day')\n",
        "            ax.set_ylabel('Value')\n",
        "            ax.set_title(f'Well: {well_name}, Loss: {avg_loss:.4f}, RMSE = {avg_rmse:.4f}')\n",
        "            pdf.savefig(fig)\n",
        "            plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def all_predictions_with_gaps_graphs(model, data, data_test, path):\n",
        "    well_plots = {}\n",
        "    well_dataloaders = {}   \n",
        "    pdf = PdfPages(path + \"/all_predictions_with_gaps.pdf\")\n",
        "    with torch.no_grad():\n",
        "        for well_name in well_info.keys():\n",
        "            well = data[data['well_name'] == well_name].reset_index(drop=True)\n",
        "            fig, ax = plt.subplots(figsize=(15, 6))\n",
        "            ax.plot(well.index, well['oil_rate'], label='Well Production')\n",
        "            ax.axvline(x=int((1 - test_size) * len(well) - days_window - 2), color='r', linestyle='--',)\n",
        "            ax.legend()\n",
        "            well_dataset = VisualizationTimeSeriesDataset(data_test[data_test['well_name'] == well_name].reset_index(drop=True))\n",
        "            well_dataloaders[well_name] = DataLoader(well_dataset, batch_size=1, shuffle=False)\n",
        "            total_loss = 0\n",
        "            total_rmse = 0\n",
        "            for i, (_, inputs_dates, targets_dates, X_batch, Y_batch) in enumerate(well_dataloaders[well_name]):\n",
        "                if i % predictions_days == 0 or i == len(well_dataloaders[well_name]) - 1:\n",
        "                    inputs_dates = np.array(inputs_dates).T[0]\n",
        "                    targets_dates = np.array(targets_dates).T[0]\n",
        "                    history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "                    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "                    logits, loss = model(X_batch, Y_batch)\n",
        "                    label = Y_batch.cpu().numpy().reshape(-1)\n",
        "                    prediction = logits.cpu().numpy()\n",
        "                    rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "                    total_loss += loss\n",
        "                    total_rmse += rmse\n",
        "                    forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "                    ax.plot(forecast_index, prediction, label='Forecasted Values', color='y')\n",
        "                    if i == 0:\n",
        "                        ax.legend()\n",
        "            avg_loss = total_loss / len(well_dataloaders[well_name]) \n",
        "            avg_rmse = total_rmse / len(well_dataloaders[well_name]) \n",
        "            ax.set_xlabel('Day')\n",
        "            ax.set_ylabel('Value')\n",
        "            ax.set_title(f'Well: {well_name}, Loss: {avg_loss:.4f}, RMSE = {avg_rmse:.4f}')\n",
        "            pdf.savefig(fig)\n",
        "            plt.close()\n",
        "    pdf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-07-15 15:40:07,644] A new study created in memory with name: no-name-5f93a5fc-7fd6-47b8-a694-b046706fe8fa\n",
            "[I 2024-07-15 15:42:04,866] Trial 0 finished with value: 0.03663919230594354 and parameters: {'vector_length': 640, 'num_layers': 2, 'dropout': 0.19641344503635347, 'lr': 0.002949014868913066, 'gamma': 0.9664126117454551}. Best is trial 0 with value: 0.03663919230594354.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on val set:\n",
            "\n",
            "Loss is 0.0366\n",
            "MAE is 0.0944\n",
            "RMSE is 0.1928\n",
            "RÂ² is 0.9661\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-07-15 15:44:26,417] Trial 1 finished with value: 0.039217724190915335 and parameters: {'vector_length': 272, 'num_layers': 4, 'dropout': 0.5567765324379755, 'lr': 0.0003826257965089424, 'gamma': 0.9725948077074607}. Best is trial 0 with value: 0.03663919230594354.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on val set:\n",
            "\n",
            "Loss is 0.0392\n",
            "MAE is 0.0970\n",
            "RMSE is 0.1950\n",
            "RÂ² is 0.9653\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-07-15 15:47:22,617] Trial 2 finished with value: 0.037502232829437536 and parameters: {'vector_length': 704, 'num_layers': 4, 'dropout': 0.23433615429117358, 'lr': 0.0005493286657334334, 'gamma': 0.9845257842874103}. Best is trial 0 with value: 0.03663919230594354.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on val set:\n",
            "\n",
            "Loss is 0.0375\n",
            "MAE is 0.0925\n",
            "RMSE is 0.1912\n",
            "RÂ² is 0.9666\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a study and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "print('Best hyperparameters:', best_params)\n",
        "\n",
        "# Train the final model with the best hyperparameters\n",
        "vector_length = best_params['vector_length']\n",
        "num_layers = best_params['num_layers']\n",
        "dropout = best_params['dropout']\n",
        "lr = best_params['lr']\n",
        "gamma = best_params['gamma']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_length = 1024\n",
        "num_layers = 3\n",
        "dropout = 0.19057012152026273\n",
        "lr = 0.0001911914637460164\n",
        "gamma = 0.9806898435934219 # 2nd best results on val set full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_length = 336\n",
        "num_layers = 3\n",
        "dropout = 0.12831089625320793\n",
        "lr = 0.0003724263259631224\n",
        "gamma = 0.978770138138513 # best results on val set full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>inputs_dates</th>\n",
              "      <th>targets_dates</th>\n",
              "      <th>inputs_index</th>\n",
              "      <th>targets_index</th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5599</td>\n",
              "      <td>[2012-02-07, 2012-02-08, 2012-02-09, 2012-02-1...</td>\n",
              "      <td>[2012-02-12, 2012-02-13, 2012-02-14, 2012-02-1...</td>\n",
              "      <td>[2883, 2884, 2885, 2886, 2887]</td>\n",
              "      <td>[2888, 2889, 2890, 2891, 2892, 2893, 2894, 289...</td>\n",
              "      <td>[[0.2684054414666464, -1.7396742091238298, -1....</td>\n",
              "      <td>[[-0.251118109451251], [-0.2404607742231651], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5351</td>\n",
              "      <td>[2014-11-07, 2014-11-08, 2014-11-09, 2014-11-1...</td>\n",
              "      <td>[2014-11-12, 2014-11-13, 2014-11-14, 2014-11-1...</td>\n",
              "      <td>[6489, 6490, 6491, 6492, 6493]</td>\n",
              "      <td>[6494, 6495, 6496, 6497, 6498, 6499, 6500, 650...</td>\n",
              "      <td>[[0.2684054414666464, 0.7586064622943015, 0.45...</td>\n",
              "      <td>[[-0.6863451966943063], [-0.6900785646441312],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7078</td>\n",
              "      <td>[2014-02-21, 2014-02-22, 2014-02-23, 2014-02-2...</td>\n",
              "      <td>[2014-02-26, 2014-02-27, 2014-02-28, 2014-03-0...</td>\n",
              "      <td>[627, 628, 629, 630, 631]</td>\n",
              "      <td>[632, 633, 634, 635, 636, 637, 638, 639, 640, ...</td>\n",
              "      <td>[[0.2684054414666464, 0.5594461049563565, 0.60...</td>\n",
              "      <td>[[-0.0561028107283693], [-0.0663494021348634],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7078</td>\n",
              "      <td>[2015-02-24, 2015-02-25, 2015-02-26, 2015-02-2...</td>\n",
              "      <td>[2015-03-01, 2015-03-02, 2015-03-03, 2015-03-0...</td>\n",
              "      <td>[989, 990, 991, 992, 993]</td>\n",
              "      <td>[994, 995, 996, 997, 998, 999, 1000, 1001, 100...</td>\n",
              "      <td>[[0.2684054414666464, 0.2748719780772813, 0.60...</td>\n",
              "      <td>[[-0.1789445522287011], [-0.1824285400011311],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5599</td>\n",
              "      <td>[2009-07-08, 2009-07-09, 2009-07-10, 2009-07-1...</td>\n",
              "      <td>[2009-07-13, 2009-07-14, 2009-07-15, 2009-07-1...</td>\n",
              "      <td>[2045, 2046, 2047, 2048, 2049]</td>\n",
              "      <td>[2050, 2051, 2052, 2053, 2054, 2055, 2056, 205...</td>\n",
              "      <td>[[0.2684054414666464, 0.4820166611412672, 0.60...</td>\n",
              "      <td>[[1.6604616321034416], [1.6238980972706754], [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4725</th>\n",
              "      <td>7078</td>\n",
              "      <td>[2015-04-15, 2015-04-16, 2015-04-17, 2015-04-1...</td>\n",
              "      <td>[2015-04-20, 2015-04-21, 2015-04-22, 2015-04-2...</td>\n",
              "      <td>[1039, 1040, 1041, 1042, 1043]</td>\n",
              "      <td>[1044, 1045, 1046, 1047, 1048, 1049, 1050, 105...</td>\n",
              "      <td>[[0.2684054414666464, 0.373529723656564, 0.588...</td>\n",
              "      <td>[[0.3777893590945128], [0.3903097109419611], [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4726</th>\n",
              "      <td>7289</td>\n",
              "      <td>[2014-01-19, 2014-01-20, 2014-01-21, 2014-01-2...</td>\n",
              "      <td>[2014-01-24, 2014-01-25, 2014-01-26, 2014-01-2...</td>\n",
              "      <td>[7103, 7104, 7105, 7106, 7107]</td>\n",
              "      <td>[7108, 7109, 7110, 7111, 7112, 7113, 7114, 711...</td>\n",
              "      <td>[[0.2684054414666464, 0.2032044106079711, 0.60...</td>\n",
              "      <td>[[-0.6536103810556642], [-0.6281222599836762],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4727</th>\n",
              "      <td>7289</td>\n",
              "      <td>[2014-11-11, 2014-11-12, 2014-11-13, 2014-11-1...</td>\n",
              "      <td>[2014-11-16, 2014-11-17, 2014-11-18, 2014-11-1...</td>\n",
              "      <td>[7382, 7383, 7384, 7385, 7386]</td>\n",
              "      <td>[7387, 7388, 7389, 7390, 7391, 7392, 7393, 739...</td>\n",
              "      <td>[[0.2684054414666464, 0.1758870184083419, 0.61...</td>\n",
              "      <td>[[-0.8149300169858227], [-0.8167270212052866],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4728</th>\n",
              "      <td>5351</td>\n",
              "      <td>[2013-01-01, 2013-01-02, 2013-01-03, 2013-01-0...</td>\n",
              "      <td>[2013-01-06, 2013-01-07, 2013-01-08, 2013-01-0...</td>\n",
              "      <td>[5840, 5841, 5842, 5843, 5844]</td>\n",
              "      <td>[5845, 5846, 5847, 5848, 5849, 5850, 5851, 585...</td>\n",
              "      <td>[[0.2684054414666464, 0.5794212353501313, 0.49...</td>\n",
              "      <td>[[-0.2315784390812436], [-0.2295613935287841],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4729</th>\n",
              "      <td>7078</td>\n",
              "      <td>[2013-11-26, 2013-11-27, 2013-11-28, 2013-11-2...</td>\n",
              "      <td>[2013-12-01, 2013-12-02, 2013-12-03, 2013-12-0...</td>\n",
              "      <td>[543, 544, 545, 546, 547]</td>\n",
              "      <td>[548, 549, 550, 551, 552, 553, 554, 555, 556, ...</td>\n",
              "      <td>[[0.2684054414666464, 0.6743872427017654, 0.60...</td>\n",
              "      <td>[[-0.0186811146969212], [0.019129321022819], [...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4730 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      well_name                                       inputs_dates  \\\n",
              "0          5599  [2012-02-07, 2012-02-08, 2012-02-09, 2012-02-1...   \n",
              "1          5351  [2014-11-07, 2014-11-08, 2014-11-09, 2014-11-1...   \n",
              "2          7078  [2014-02-21, 2014-02-22, 2014-02-23, 2014-02-2...   \n",
              "3          7078  [2015-02-24, 2015-02-25, 2015-02-26, 2015-02-2...   \n",
              "4          5599  [2009-07-08, 2009-07-09, 2009-07-10, 2009-07-1...   \n",
              "...         ...                                                ...   \n",
              "4725       7078  [2015-04-15, 2015-04-16, 2015-04-17, 2015-04-1...   \n",
              "4726       7289  [2014-01-19, 2014-01-20, 2014-01-21, 2014-01-2...   \n",
              "4727       7289  [2014-11-11, 2014-11-12, 2014-11-13, 2014-11-1...   \n",
              "4728       5351  [2013-01-01, 2013-01-02, 2013-01-03, 2013-01-0...   \n",
              "4729       7078  [2013-11-26, 2013-11-27, 2013-11-28, 2013-11-2...   \n",
              "\n",
              "                                          targets_dates  \\\n",
              "0     [2012-02-12, 2012-02-13, 2012-02-14, 2012-02-1...   \n",
              "1     [2014-11-12, 2014-11-13, 2014-11-14, 2014-11-1...   \n",
              "2     [2014-02-26, 2014-02-27, 2014-02-28, 2014-03-0...   \n",
              "3     [2015-03-01, 2015-03-02, 2015-03-03, 2015-03-0...   \n",
              "4     [2009-07-13, 2009-07-14, 2009-07-15, 2009-07-1...   \n",
              "...                                                 ...   \n",
              "4725  [2015-04-20, 2015-04-21, 2015-04-22, 2015-04-2...   \n",
              "4726  [2014-01-24, 2014-01-25, 2014-01-26, 2014-01-2...   \n",
              "4727  [2014-11-16, 2014-11-17, 2014-11-18, 2014-11-1...   \n",
              "4728  [2013-01-06, 2013-01-07, 2013-01-08, 2013-01-0...   \n",
              "4729  [2013-12-01, 2013-12-02, 2013-12-03, 2013-12-0...   \n",
              "\n",
              "                        inputs_index  \\\n",
              "0     [2883, 2884, 2885, 2886, 2887]   \n",
              "1     [6489, 6490, 6491, 6492, 6493]   \n",
              "2          [627, 628, 629, 630, 631]   \n",
              "3          [989, 990, 991, 992, 993]   \n",
              "4     [2045, 2046, 2047, 2048, 2049]   \n",
              "...                              ...   \n",
              "4725  [1039, 1040, 1041, 1042, 1043]   \n",
              "4726  [7103, 7104, 7105, 7106, 7107]   \n",
              "4727  [7382, 7383, 7384, 7385, 7386]   \n",
              "4728  [5840, 5841, 5842, 5843, 5844]   \n",
              "4729       [543, 544, 545, 546, 547]   \n",
              "\n",
              "                                          targets_index  \\\n",
              "0     [2888, 2889, 2890, 2891, 2892, 2893, 2894, 289...   \n",
              "1     [6494, 6495, 6496, 6497, 6498, 6499, 6500, 650...   \n",
              "2     [632, 633, 634, 635, 636, 637, 638, 639, 640, ...   \n",
              "3     [994, 995, 996, 997, 998, 999, 1000, 1001, 100...   \n",
              "4     [2050, 2051, 2052, 2053, 2054, 2055, 2056, 205...   \n",
              "...                                                 ...   \n",
              "4725  [1044, 1045, 1046, 1047, 1048, 1049, 1050, 105...   \n",
              "4726  [7108, 7109, 7110, 7111, 7112, 7113, 7114, 711...   \n",
              "4727  [7387, 7388, 7389, 7390, 7391, 7392, 7393, 739...   \n",
              "4728  [5845, 5846, 5847, 5848, 5849, 5850, 5851, 585...   \n",
              "4729  [548, 549, 550, 551, 552, 553, 554, 555, 556, ...   \n",
              "\n",
              "                                                 inputs  \\\n",
              "0     [[0.2684054414666464, -1.7396742091238298, -1....   \n",
              "1     [[0.2684054414666464, 0.7586064622943015, 0.45...   \n",
              "2     [[0.2684054414666464, 0.5594461049563565, 0.60...   \n",
              "3     [[0.2684054414666464, 0.2748719780772813, 0.60...   \n",
              "4     [[0.2684054414666464, 0.4820166611412672, 0.60...   \n",
              "...                                                 ...   \n",
              "4725  [[0.2684054414666464, 0.373529723656564, 0.588...   \n",
              "4726  [[0.2684054414666464, 0.2032044106079711, 0.60...   \n",
              "4727  [[0.2684054414666464, 0.1758870184083419, 0.61...   \n",
              "4728  [[0.2684054414666464, 0.5794212353501313, 0.49...   \n",
              "4729  [[0.2684054414666464, 0.6743872427017654, 0.60...   \n",
              "\n",
              "                                                targets  \n",
              "0     [[-0.251118109451251], [-0.2404607742231651], ...  \n",
              "1     [[-0.6863451966943063], [-0.6900785646441312],...  \n",
              "2     [[-0.0561028107283693], [-0.0663494021348634],...  \n",
              "3     [[-0.1789445522287011], [-0.1824285400011311],...  \n",
              "4     [[1.6604616321034416], [1.6238980972706754], [...  \n",
              "...                                                 ...  \n",
              "4725  [[0.3777893590945128], [0.3903097109419611], [...  \n",
              "4726  [[-0.6536103810556642], [-0.6281222599836762],...  \n",
              "4727  [[-0.8149300169858227], [-0.8167270212052866],...  \n",
              "4728  [[-0.2315784390812436], [-0.2295613935287841],...  \n",
              "4729  [[-0.0186811146969212], [0.019129321022819], [...  \n",
              "\n",
              "[4730 rows x 7 columns]"
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYRS6z8uI3Nr",
        "outputId": "9135626b-446a-427a-8dd0-f4a54073a157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of input is: torch.Size([96, 5, 38]) and the shape of the output is torch.Size([96, 14])\n",
            "The output shape of the LSTM will be (1344,) and a an example initial loss is 0.9283939003944397\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "context_size = days_window - 1\n",
        "X_batch, Y_batch = next(iter(train_loader))\n",
        "X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "print(f'The shape of input is: {X_batch.shape} and the shape of the output is {Y_batch.shape}')\n",
        "model = LSTM(input_length=input_length, hidden_length=vector_length, output_length=output_length, num_layers=num_layers, dropout=dropout).to(device)\n",
        "output, loss = model(X_batch, Y_batch)\n",
        "print(f'The output shape of the LSTM will be {tuple(output.shape)} and a an example initial loss is {loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "0eSC24XWOoMf"
      },
      "outputs": [],
      "source": [
        "model = LSTM(input_length=input_length, hidden_length=vector_length, output_length=output_length, num_layers=num_layers, dropout=dropout).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # setting optimizer scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [],
      "source": [
        "iterations = 30000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o-CnvgwmOjRW",
        "outputId": "196cb846-ee96-47a5-a867-c1a1dac00309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0: train loss 1.1191, val loss 1.1372\n",
            "step 500: train loss 0.0672, val loss 0.0662\n",
            "step 1000: train loss 0.0620, val loss 0.0615\n",
            "step 1500: train loss 0.0561, val loss 0.0570\n",
            "step 2000: train loss 0.0512, val loss 0.0524\n",
            "step 2500: train loss 0.0464, val loss 0.0499\n",
            "step 3000: train loss 0.0410, val loss 0.0488\n",
            "step 3500: train loss 0.0381, val loss 0.0467\n",
            "step 4000: train loss 0.0303, val loss 0.0404\n",
            "step 4500: train loss 0.0277, val loss 0.0406\n",
            "step 5000: train loss 0.0244, val loss 0.0369\n",
            "step 5500: train loss 0.0218, val loss 0.0368\n",
            "step 6000: train loss 0.0200, val loss 0.0358\n",
            "step 6500: train loss 0.0175, val loss 0.0362\n",
            "Training ended manually by user.\n",
            "\n",
            "Training is complete\n"
          ]
        }
      ],
      "source": [
        "train_loader_iter = iter(train_loader)\n",
        "log_file = get_next_log_file(path + \"/Models/Global/LSTM/Logs\")\n",
        "\n",
        "log_message = f\"Hyperparameters: Vector Length = {vector_length}, Number of Layers = {num_layers}, Dropout = {dropout}, Learning Rate = {lr}, Scheduler Gamma = {gamma}\\n\"\n",
        "\n",
        "log_to_file(log_file, log_message)\n",
        "model.train()\n",
        "try:\n",
        "    for i in range(iterations):\n",
        "        model.train()  # Set model to training mode\n",
        "        if i % eval_interval == 0 or i == iterations - 1:\n",
        "            # Evaluate and save model parameters periodically\n",
        "            save_params(model, optimizer, scheduler, 'current')  # Saving parameters\n",
        "            model.eval()\n",
        "            losses = estimate_loss(model)  # Estimate train and val loss\n",
        "            model.train()\n",
        "            log_message = f\"step {i}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\"\n",
        "            print(log_message)\n",
        "            log_to_file(log_file, log_message)  # Log to file\n",
        "            if i != 0:\n",
        "                scheduler.step()  # Perform scheduler step\n",
        "        try:\n",
        "            # Get the next batch\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "        except StopIteration:\n",
        "            # Reinitialize the iterator if the DataLoader is exhausted\n",
        "            train_loader_iter = iter(train_loader)\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "\n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "        logits, loss = model(X_batch, Y_batch)  # Run inputs and expected outputs through model\n",
        "        optimizer.zero_grad(set_to_none=True)  # Set gradients to 0 (to ensure gradients don't explode)\n",
        "        loss.backward()  # Perform backpropagation\n",
        "        optimizer.step()  # Perform parameter adjustment\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Training ended manually by user.\\n\")\n",
        "model.eval()\n",
        "print(\"Training is complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on train set:\n",
            "\n",
            "Loss is 0.0101\n",
            "MAE is 0.0586\n",
            "RMSE is 0.1006\n",
            "RÂ² is 0.9907\n",
            "\n",
            "\n",
            "Metrics on val set:\n",
            "\n",
            "Loss is 0.0354\n",
            "MAE is 0.0922\n",
            "RMSE is 0.1884\n",
            "RÂ² is 0.9676\n",
            "\n",
            "\n",
            "Metrics on test set:\n",
            "\n",
            "Loss is 0.0145\n",
            "MAE is 0.0896\n",
            "RMSE is 0.1219\n",
            "RÂ² is 0.3846\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "train_metrics = evaluate('train', model)\n",
        "val_metrics = evaluate('val', model)\n",
        "test_metrics = evaluate('test', model)\n",
        "log_to_file(log_file, str(f\"\\nMetrics = {test_metrics}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files have been renamed successfully.\n"
          ]
        }
      ],
      "source": [
        "label_model_files(old_name='hi', new_name='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "model, optimizer, scheduler = load_model('best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas._libs.tslibs.timestamps.Timestamp'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:182\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transposed):\n\u001b[0;32m--> 182\u001b[0m     clone[i] \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clone\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:191\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas._libs.tslibs.timestamps.Timestamp'>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[239], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictions_with_history_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualization_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Models/Global/LSTM/Graphs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m predictions_graphs(model, visualization_test_loader, path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Models/Global/LSTM/Graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m all_predictions_graphs(model, data, data_test, path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Models/Global/LSTM/Graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[232], line 179\u001b[0m, in \u001b[0;36mpredictions_with_history_graphs\u001b[0;34m(model, visualization_loader, path)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    178\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m well_name, inputs_dates, targets_dates, X_batch, Y_batch \u001b[38;5;129;01min\u001b[39;00m visualization_loader:\n\u001b[1;32m    180\u001b[0m         X_batch, Y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), Y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    181\u001b[0m         choice \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_batch) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:316\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:173\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    170\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:173\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    170\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:189\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed])\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:189\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed])\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py:191\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas._libs.tslibs.timestamps.Timestamp'>"
          ]
        }
      ],
      "source": [
        "predictions_with_history_graphs(model, visualization_test_loader, path + \"/Models/Global/LSTM/Graphs\")\n",
        "predictions_graphs(model, visualization_test_loader, path + \"/Models/Global/LSTM/Graphs\")\n",
        "all_predictions_graphs(model, data, data_test, path + \"/Models/Global/LSTM/Graphs\")\n",
        "all_predictions_with_gaps_graphs(model, data, data_test, path + \"/Models/Global/LSTM/Graphs\")\n",
        "test_metrics = evaluate('test', model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "should i adjust the data so that the lags are adjusted as if it hasnt seen it previously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   well_name                                       inputs_dates  \\\n",
            "0       7405  [2014-04-22, 2014-04-23, 2014-04-24, 2014-04-2...   \n",
            "1       7405  [2014-04-23, 2014-04-24, 2014-04-25, 2014-04-2...   \n",
            "2       7405  [2014-04-24, 2014-04-25, 2014-04-26, 2014-04-2...   \n",
            "3       7405  [2014-04-25, 2014-04-26, 2014-04-27, 2014-04-2...   \n",
            "4       7405  [2014-04-26, 2014-04-27, 2014-04-28, 2014-04-2...   \n",
            "\n",
            "                                       targets_dates     inputs_index  \\\n",
            "0  [2014-04-27, 2014-04-28, 2014-04-29, 2014-04-3...  [0, 1, 2, 3, 4]   \n",
            "1  [2014-04-28, 2014-04-29, 2014-04-30, 2014-05-0...  [1, 2, 3, 4, 5]   \n",
            "2  [2014-04-29, 2014-04-30, 2014-05-01, 2014-05-0...  [2, 3, 4, 5, 6]   \n",
            "3  [2014-04-30, 2014-05-01, 2014-05-02, 2014-05-0...  [3, 4, 5, 6, 7]   \n",
            "4  [2014-05-01, 2014-05-02, 2014-05-03, 2014-05-0...  [4, 5, 6, 7, 8]   \n",
            "\n",
            "                                       targets_index  \\\n",
            "0  [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...   \n",
            "1  [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1...   \n",
            "2  [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, ...   \n",
            "3  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
            "4  [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20...   \n",
            "\n",
            "                                              inputs  \\\n",
            "0  [[0.26840544, 1.0293086, 0.60597277, 0.3961647...   \n",
            "1  [[0.26840544, 0.84579265, 0.6347771, 0.2398162...   \n",
            "2  [[0.26840544, 0.77502286, 0.6398091, 0.1998886...   \n",
            "3  [[0.26840544, 0.7050308, 0.64208347, 0.1614912...   \n",
            "4  [[0.26840544, 0.6253548, 0.64388895, 0.1172189...   \n",
            "\n",
            "                                             targets  \n",
            "0  [[0.036197193], [0.033299983], [-0.0152191315]...  \n",
            "1  [[0.033299983], [-0.0152191315], [-0.054709215...  \n",
            "2  [[-0.0152191315], [-0.054709215], [-0.06403897...  \n",
            "3  [[-0.054709215], [-0.06403897], [-0.16588877],...  \n",
            "4  [[-0.06403897], [-0.16588877], [-0.18779755], ...  \n",
            "object\n",
            "object\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = pd.read_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "\n",
        "# Ensure each entry in 'inputs' and 'targets' is a NumPy array\n",
        "def to_numpy_array(x):\n",
        "    return np.array(x, dtype=np.float32)\n",
        "\n",
        "dataset['inputs'] = dataset['inputs'].apply(to_numpy_array)\n",
        "dataset['targets'] = dataset['targets'].apply(to_numpy_array)\n",
        "\n",
        "# Check the data structure\n",
        "print(dataset.head())\n",
        "print(dataset['inputs'].dtype)\n",
        "print(dataset['targets'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
