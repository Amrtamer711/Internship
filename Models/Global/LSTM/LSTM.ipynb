{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "UiR3fmx7CA4k",
        "outputId": "0bc76cb5-4eef-4f5b-d17f-3a312ac0eb32"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import optuna\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from matplotlib.backends.backend_pdf import PdfPages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "kHGp1xjdeuoP"
      },
      "outputs": [],
      "source": [
        "path = \"/Users/amrtamer/Documents/Internship\"\n",
        "# path = \"/content/drive/MyDrive/Internship\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "oMm8nN82aHf-",
        "outputId": "af7ebad3-5206-4dd9-e0d2-806809812f0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>WELL_BORE_CODE</th>\n",
              "      <th>date</th>\n",
              "      <th>prod_hrs</th>\n",
              "      <th>bhp</th>\n",
              "      <th>bht</th>\n",
              "      <th>dp_tubing</th>\n",
              "      <th>AVG_ANNULUS_PRESS</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>whp</th>\n",
              "      <th>...</th>\n",
              "      <th>linear_regressor</th>\n",
              "      <th>EMA_short</th>\n",
              "      <th>EMA_medium</th>\n",
              "      <th>EMA_long</th>\n",
              "      <th>Rolling_short</th>\n",
              "      <th>Rolling_medium</th>\n",
              "      <th>Rolling_long</th>\n",
              "      <th>Lag_short</th>\n",
              "      <th>Lag_medium</th>\n",
              "      <th>Lag_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>1.029311</td>\n",
              "      <td>0.605973</td>\n",
              "      <td>0.396167</td>\n",
              "      <td>-2.016027</td>\n",
              "      <td>-0.533280</td>\n",
              "      <td>3.281836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.101892</td>\n",
              "      <td>-0.103579</td>\n",
              "      <td>-0.104768</td>\n",
              "      <td>-0.106929</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.845795</td>\n",
              "      <td>0.634777</td>\n",
              "      <td>0.239818</td>\n",
              "      <td>0.088113</td>\n",
              "      <td>-0.419656</td>\n",
              "      <td>2.849981</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.101892</td>\n",
              "      <td>-0.103579</td>\n",
              "      <td>-0.104768</td>\n",
              "      <td>-0.106929</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>[0.0, 0.0, -0.10230979661544379]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, -0.10230979661544379]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.775025</td>\n",
              "      <td>0.639809</td>\n",
              "      <td>0.199890</td>\n",
              "      <td>-0.688434</td>\n",
              "      <td>-0.402874</td>\n",
              "      <td>2.607708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.101892</td>\n",
              "      <td>-0.009618</td>\n",
              "      <td>-0.053295</td>\n",
              "      <td>-0.079801</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>[0.0, -0.10230979661544379, -0.10230979661544379]</td>\n",
              "      <td>[0.0, 0.0, 0.0, -0.10230979661544379, -0.10230...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.705033</td>\n",
              "      <td>0.642084</td>\n",
              "      <td>0.161493</td>\n",
              "      <td>1.145283</td>\n",
              "      <td>-0.379061</td>\n",
              "      <td>2.364038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.114759</td>\n",
              "      <td>-0.020781</td>\n",
              "      <td>-0.051611</td>\n",
              "      <td>-0.076565</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>[-0.10230979661544379, -0.10230979661544379, 0...</td>\n",
              "      <td>[0.0, 0.0, -0.10230979661544379, -0.1023097966...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1023097...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-26</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.625357</td>\n",
              "      <td>0.643889</td>\n",
              "      <td>0.117221</td>\n",
              "      <td>1.145283</td>\n",
              "      <td>-0.340115</td>\n",
              "      <td>2.088747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082297</td>\n",
              "      <td>-0.004428</td>\n",
              "      <td>-0.037199</td>\n",
              "      <td>-0.066767</td>\n",
              "      <td>-0.009496</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>[-0.10230979661544379, 0.1777063666263608, -0....</td>\n",
              "      <td>[0.0, -0.10230979661544379, -0.102309796615443...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.102309796615...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   well_name WELL_BORE_CODE        date  prod_hrs       bhp       bht  \\\n",
              "0       7405  NO 15/9-F-1 C  2014-04-22  0.268405  1.029311  0.605973   \n",
              "1       7405  NO 15/9-F-1 C  2014-04-23  0.268405  0.845795  0.634777   \n",
              "2       7405  NO 15/9-F-1 C  2014-04-24  0.268405  0.775025  0.639809   \n",
              "3       7405  NO 15/9-F-1 C  2014-04-25  0.268405  0.705033  0.642084   \n",
              "4       7405  NO 15/9-F-1 C  2014-04-26  0.268405  0.625357  0.643889   \n",
              "\n",
              "   dp_tubing  AVG_ANNULUS_PRESS  AVG_CHOKE_SIZE_P       whp  ...  \\\n",
              "0   0.396167          -2.016027         -0.533280  3.281836  ...   \n",
              "1   0.239818           0.088113         -0.419656  2.849981  ...   \n",
              "2   0.199890          -0.688434         -0.402874  2.607708  ...   \n",
              "3   0.161493           1.145283         -0.379061  2.364038  ...   \n",
              "4   0.117221           1.145283         -0.340115  2.088747  ...   \n",
              "\n",
              "   linear_regressor  EMA_short  EMA_medium  EMA_long  Rolling_short  \\\n",
              "0         -0.101892  -0.103579   -0.104768 -0.106929      -0.001355   \n",
              "1         -0.101892  -0.103579   -0.104768 -0.106929      -0.001355   \n",
              "2         -0.101892  -0.009618   -0.053295 -0.079801      -0.001355   \n",
              "3         -0.114759  -0.020781   -0.051611 -0.076565      -0.001355   \n",
              "4          0.082297  -0.004428   -0.037199 -0.066767      -0.009496   \n",
              "\n",
              "   Rolling_medium Rolling_long  \\\n",
              "0       -0.002618     -0.00519   \n",
              "1       -0.002618     -0.00519   \n",
              "2       -0.002618     -0.00519   \n",
              "3       -0.002618     -0.00519   \n",
              "4       -0.002618     -0.00519   \n",
              "\n",
              "                                           Lag_short  \\\n",
              "0                                    [0.0, 0.0, 0.0]   \n",
              "1                   [0.0, 0.0, -0.10230979661544379]   \n",
              "2  [0.0, -0.10230979661544379, -0.10230979661544379]   \n",
              "3  [-0.10230979661544379, -0.10230979661544379, 0...   \n",
              "4  [-0.10230979661544379, 0.1777063666263608, -0....   \n",
              "\n",
              "                                          Lag_medium  \\\n",
              "0                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "1         [0.0, 0.0, 0.0, 0.0, -0.10230979661544379]   \n",
              "2  [0.0, 0.0, 0.0, -0.10230979661544379, -0.10230...   \n",
              "3  [0.0, 0.0, -0.10230979661544379, -0.1023097966...   \n",
              "4  [0.0, -0.10230979661544379, -0.102309796615443...   \n",
              "\n",
              "                                            Lag_long  \n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.10...  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1023097...  \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.102309796615...  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_pickle(path + r'/data/Volve/Volve_cleaned_prepared.pkl')\n",
        "if \"Unnamed: 0\" in data.columns:\n",
        "    data = data.drop(columns=\"Unnamed: 0\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZmGsFefnB3G",
        "outputId": "b292ccb7-229f-4e81-93a7-5e73a095cd2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{5769: 'NO 15/9-F-5 AH',\n",
              " 7078: 'NO 15/9-F-11 H',\n",
              " 5351: 'NO 15/9-F-14 H',\n",
              " 5599: 'NO 15/9-F-12 H',\n",
              " 7289: 'NO 15/9-F-15 D',\n",
              " 7405: 'NO 15/9-F-1 C'}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "well_info = dict(set([(j, i) for i, j in data[['WELL_BORE_CODE', 'well_name']].values.tolist()])) # creating a dictionary of well identiification with {code: name} structure\n",
        "well_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['well_name', 'WELL_BORE_CODE', 'date', 'prod_hrs', 'bhp', 'bht',\n",
              "       'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht',\n",
              "       'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'oil_rate',\n",
              "       'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long',\n",
              "       'Rolling_short', 'Rolling_medium', 'Rolling_long', 'Lag_short',\n",
              "       'Lag_medium', 'Lag_long'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KJZoa8Qneyzy"
      },
      "outputs": [],
      "source": [
        "identification_column = ['well_name', 'WELL_BORE_CODE', 'date']\n",
        "single_feature_columns = ['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']\n",
        "multiple_feature_columns = ['Lag_short', 'Lag_medium', 'Lag_long']\n",
        "feature_columns = single_feature_columns + multiple_feature_columns\n",
        "target_column = ['oil_rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr-v7jdxLqsb",
        "outputId": "c6baddd3-c5c4-48e4-e360-92bb0f37b089"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7987, 26)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[identification_column + feature_columns]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prod_hrs                -0.0\n",
            "bhp                     -0.0\n",
            "bht                      0.0\n",
            "dp_tubing               -0.0\n",
            "AVG_ANNULUS_PRESS       -0.0\n",
            "AVG_CHOKE_SIZE_P        -0.0\n",
            "whp                     -0.0\n",
            "wht                     -0.0\n",
            "choke_size_percentage    0.0\n",
            "oil_vol                  0.0\n",
            "gas_vol                 -0.0\n",
            "water_vol                0.0\n",
            "linear_regressor        -0.0\n",
            "EMA_short                0.0\n",
            "EMA_medium               0.0\n",
            "EMA_long                -0.0\n",
            "Rolling_short           -0.0\n",
            "Rolling_medium           0.0\n",
            "Rolling_long             0.0\n",
            "oil_rate                 0.0\n",
            "dtype: float64\n",
            "prod_hrs                 1.0\n",
            "bhp                      1.0\n",
            "bht                      1.0\n",
            "dp_tubing                1.0\n",
            "AVG_ANNULUS_PRESS        1.0\n",
            "AVG_CHOKE_SIZE_P         1.0\n",
            "whp                      1.0\n",
            "wht                      1.0\n",
            "choke_size_percentage    1.0\n",
            "oil_vol                  1.0\n",
            "gas_vol                  1.0\n",
            "water_vol                1.0\n",
            "linear_regressor         1.0\n",
            "EMA_short                1.0\n",
            "EMA_medium               1.0\n",
            "EMA_long                 1.0\n",
            "Rolling_short            1.0\n",
            "Rolling_medium           1.0\n",
            "Rolling_long             1.0\n",
            "oil_rate                 1.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(data[['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']].mean().round(4))\n",
        "print(data[['prod_hrs', 'bhp', 'bht', 'dp_tubing', 'AVG_ANNULUS_PRESS', 'AVG_CHOKE_SIZE_P', 'whp', 'wht', 'choke_size_percentage', 'oil_vol', 'gas_vol', 'water_vol', 'linear_regressor', 'EMA_short', 'EMA_medium', 'EMA_long', 'Rolling_short', 'Rolling_medium', 'Rolling_long', 'oil_rate']].std().round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "58-XDpb-EO82",
        "outputId": "f2517c61-2691-476e-dc5c-2a7ddad922b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>well_name</th>\n",
              "      <th>WELL_BORE_CODE</th>\n",
              "      <th>date</th>\n",
              "      <th>prod_hrs</th>\n",
              "      <th>bhp</th>\n",
              "      <th>bht</th>\n",
              "      <th>dp_tubing</th>\n",
              "      <th>AVG_ANNULUS_PRESS</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>whp</th>\n",
              "      <th>...</th>\n",
              "      <th>EMA_short</th>\n",
              "      <th>EMA_medium</th>\n",
              "      <th>EMA_long</th>\n",
              "      <th>Rolling_short</th>\n",
              "      <th>Rolling_medium</th>\n",
              "      <th>Rolling_long</th>\n",
              "      <th>oil_rate</th>\n",
              "      <th>Lag_short</th>\n",
              "      <th>Lag_medium</th>\n",
              "      <th>Lag_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>1.029311</td>\n",
              "      <td>0.605973</td>\n",
              "      <td>0.396167</td>\n",
              "      <td>-2.016027</td>\n",
              "      <td>-0.533280</td>\n",
              "      <td>3.281836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103579</td>\n",
              "      <td>-0.104768</td>\n",
              "      <td>-0.106929</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>-0.102310</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.845795</td>\n",
              "      <td>0.634777</td>\n",
              "      <td>0.239818</td>\n",
              "      <td>0.088113</td>\n",
              "      <td>-0.419656</td>\n",
              "      <td>2.849981</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103579</td>\n",
              "      <td>-0.104768</td>\n",
              "      <td>-0.106929</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>-0.102310</td>\n",
              "      <td>[0.0, 0.0, -0.10230979661544379]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, -0.10230979661544379]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.775025</td>\n",
              "      <td>0.639809</td>\n",
              "      <td>0.199890</td>\n",
              "      <td>-0.688434</td>\n",
              "      <td>-0.402874</td>\n",
              "      <td>2.607708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009618</td>\n",
              "      <td>-0.053295</td>\n",
              "      <td>-0.079801</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>0.177706</td>\n",
              "      <td>[0.0, -0.10230979661544379, -0.10230979661544379]</td>\n",
              "      <td>[0.0, 0.0, 0.0, -0.10230979661544379, -0.10230...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.705033</td>\n",
              "      <td>0.642084</td>\n",
              "      <td>0.161493</td>\n",
              "      <td>1.145283</td>\n",
              "      <td>-0.379061</td>\n",
              "      <td>2.364038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020781</td>\n",
              "      <td>-0.051611</td>\n",
              "      <td>-0.076565</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>-0.042238</td>\n",
              "      <td>[-0.10230979661544379, -0.10230979661544379, 0...</td>\n",
              "      <td>[0.0, 0.0, -0.10230979661544379, -0.1023097966...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1023097...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7405</td>\n",
              "      <td>NO 15/9-F-1 C</td>\n",
              "      <td>2014-04-26</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>0.625357</td>\n",
              "      <td>0.643889</td>\n",
              "      <td>0.117221</td>\n",
              "      <td>1.145283</td>\n",
              "      <td>-0.340115</td>\n",
              "      <td>2.088747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004428</td>\n",
              "      <td>-0.037199</td>\n",
              "      <td>-0.066767</td>\n",
              "      <td>-0.009496</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>-0.00519</td>\n",
              "      <td>0.028674</td>\n",
              "      <td>[-0.10230979661544379, 0.1777063666263608, -0....</td>\n",
              "      <td>[0.0, -0.10230979661544379, -0.102309796615443...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.102309796615...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7982</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-22</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814175</td>\n",
              "      <td>1.149266</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.140330</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.692802</td>\n",
              "      <td>-0.702316</td>\n",
              "      <td>-0.715245</td>\n",
              "      <td>-0.692202</td>\n",
              "      <td>-0.703021</td>\n",
              "      <td>-0.724022</td>\n",
              "      <td>-0.683109</td>\n",
              "      <td>[-0.6852415797773639, -0.6943429268335604, -0....</td>\n",
              "      <td>[-0.6933422169244923, -0.687878486910018, -0.6...</td>\n",
              "      <td>[-0.7133929373653101, -0.7128670168291575, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7983</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-23</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814175</td>\n",
              "      <td>1.158798</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.136215</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.689514</td>\n",
              "      <td>-0.699464</td>\n",
              "      <td>-0.713067</td>\n",
              "      <td>-0.690182</td>\n",
              "      <td>-0.699482</td>\n",
              "      <td>-0.722275</td>\n",
              "      <td>-0.677835</td>\n",
              "      <td>[-0.6943429268335604, -0.6840874763785847, -0....</td>\n",
              "      <td>[-0.687878486910018, -0.6852415797773639, -0.6...</td>\n",
              "      <td>[-0.7128670168291575, -0.704496114962062, -0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7984</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-24</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-0.880933</td>\n",
              "      <td>-0.806036</td>\n",
              "      <td>-0.814175</td>\n",
              "      <td>1.141085</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.137527</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.687737</td>\n",
              "      <td>-0.697357</td>\n",
              "      <td>-0.711216</td>\n",
              "      <td>-0.68894</td>\n",
              "      <td>-0.696914</td>\n",
              "      <td>-0.720063</td>\n",
              "      <td>-0.679069</td>\n",
              "      <td>[-0.6840874763785847, -0.6831086798251896, -0....</td>\n",
              "      <td>[-0.6852415797773639, -0.6943429268335604, -0....</td>\n",
              "      <td>[-0.704496114962062, -0.6974619277910209, -0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7985</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-25</td>\n",
              "      <td>0.268405</td>\n",
              "      <td>-1.334973</td>\n",
              "      <td>-1.285316</td>\n",
              "      <td>-1.327391</td>\n",
              "      <td>1.140689</td>\n",
              "      <td>1.150153</td>\n",
              "      <td>-1.140776</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.68641</td>\n",
              "      <td>-0.695555</td>\n",
              "      <td>-0.7095</td>\n",
              "      <td>-0.685783</td>\n",
              "      <td>-0.695013</td>\n",
              "      <td>-0.71813</td>\n",
              "      <td>-0.678646</td>\n",
              "      <td>[-0.6831086798251896, -0.6778348655598816, -0....</td>\n",
              "      <td>[-0.6943429268335604, -0.6840874763785847, -0....</td>\n",
              "      <td>[-0.6974619277910209, -0.6908660077334403, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7986</th>\n",
              "      <td>5769</td>\n",
              "      <td>NO 15/9-F-5 AH</td>\n",
              "      <td>2016-08-26</td>\n",
              "      <td>-0.744073</td>\n",
              "      <td>-0.434704</td>\n",
              "      <td>-0.323038</td>\n",
              "      <td>-0.323127</td>\n",
              "      <td>1.127728</td>\n",
              "      <td>0.671086</td>\n",
              "      <td>-1.123420</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.684576</td>\n",
              "      <td>-0.693562</td>\n",
              "      <td>-0.707674</td>\n",
              "      <td>-0.684119</td>\n",
              "      <td>-0.693493</td>\n",
              "      <td>-0.715748</td>\n",
              "      <td>-0.675818</td>\n",
              "      <td>[-0.6778348655598816, -0.6790693179294619, -0....</td>\n",
              "      <td>[-0.6840874763785847, -0.6831086798251896, -0....</td>\n",
              "      <td>[-0.6908660077334403, -0.6933422169244923, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7987 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      well_name  WELL_BORE_CODE        date  prod_hrs       bhp       bht  \\\n",
              "0          7405   NO 15/9-F-1 C  2014-04-22  0.268405  1.029311  0.605973   \n",
              "1          7405   NO 15/9-F-1 C  2014-04-23  0.268405  0.845795  0.634777   \n",
              "2          7405   NO 15/9-F-1 C  2014-04-24  0.268405  0.775025  0.639809   \n",
              "3          7405   NO 15/9-F-1 C  2014-04-25  0.268405  0.705033  0.642084   \n",
              "4          7405   NO 15/9-F-1 C  2014-04-26  0.268405  0.625357  0.643889   \n",
              "...         ...             ...         ...       ...       ...       ...   \n",
              "7982       5769  NO 15/9-F-5 AH  2016-08-22  0.268405 -0.880933 -0.806036   \n",
              "7983       5769  NO 15/9-F-5 AH  2016-08-23  0.268405 -0.880933 -0.806036   \n",
              "7984       5769  NO 15/9-F-5 AH  2016-08-24  0.268405 -0.880933 -0.806036   \n",
              "7985       5769  NO 15/9-F-5 AH  2016-08-25  0.268405 -1.334973 -1.285316   \n",
              "7986       5769  NO 15/9-F-5 AH  2016-08-26 -0.744073 -0.434704 -0.323038   \n",
              "\n",
              "      dp_tubing  AVG_ANNULUS_PRESS  AVG_CHOKE_SIZE_P       whp  ...  \\\n",
              "0      0.396167          -2.016027         -0.533280  3.281836  ...   \n",
              "1      0.239818           0.088113         -0.419656  2.849981  ...   \n",
              "2      0.199890          -0.688434         -0.402874  2.607708  ...   \n",
              "3      0.161493           1.145283         -0.379061  2.364038  ...   \n",
              "4      0.117221           1.145283         -0.340115  2.088747  ...   \n",
              "...         ...                ...               ...       ...  ...   \n",
              "7982  -0.814175           1.149266          1.150153 -1.140330  ...   \n",
              "7983  -0.814175           1.158798          1.150153 -1.136215  ...   \n",
              "7984  -0.814175           1.141085          1.150153 -1.137527  ...   \n",
              "7985  -1.327391           1.140689          1.150153 -1.140776  ...   \n",
              "7986  -0.323127           1.127728          0.671086 -1.123420  ...   \n",
              "\n",
              "      EMA_short  EMA_medium  EMA_long  Rolling_short  Rolling_medium  \\\n",
              "0     -0.103579   -0.104768 -0.106929      -0.001355       -0.002618   \n",
              "1     -0.103579   -0.104768 -0.106929      -0.001355       -0.002618   \n",
              "2     -0.009618   -0.053295 -0.079801      -0.001355       -0.002618   \n",
              "3     -0.020781   -0.051611 -0.076565      -0.001355       -0.002618   \n",
              "4     -0.004428   -0.037199 -0.066767      -0.009496       -0.002618   \n",
              "...         ...         ...       ...            ...             ...   \n",
              "7982  -0.692802   -0.702316 -0.715245      -0.692202       -0.703021   \n",
              "7983  -0.689514   -0.699464 -0.713067      -0.690182       -0.699482   \n",
              "7984  -0.687737   -0.697357 -0.711216       -0.68894       -0.696914   \n",
              "7985   -0.68641   -0.695555   -0.7095      -0.685783       -0.695013   \n",
              "7986  -0.684576   -0.693562 -0.707674      -0.684119       -0.693493   \n",
              "\n",
              "     Rolling_long  oil_rate  \\\n",
              "0        -0.00519 -0.102310   \n",
              "1        -0.00519 -0.102310   \n",
              "2        -0.00519  0.177706   \n",
              "3        -0.00519 -0.042238   \n",
              "4        -0.00519  0.028674   \n",
              "...           ...       ...   \n",
              "7982    -0.724022 -0.683109   \n",
              "7983    -0.722275 -0.677835   \n",
              "7984    -0.720063 -0.679069   \n",
              "7985     -0.71813 -0.678646   \n",
              "7986    -0.715748 -0.675818   \n",
              "\n",
              "                                              Lag_short  \\\n",
              "0                                       [0.0, 0.0, 0.0]   \n",
              "1                      [0.0, 0.0, -0.10230979661544379]   \n",
              "2     [0.0, -0.10230979661544379, -0.10230979661544379]   \n",
              "3     [-0.10230979661544379, -0.10230979661544379, 0...   \n",
              "4     [-0.10230979661544379, 0.1777063666263608, -0....   \n",
              "...                                                 ...   \n",
              "7982  [-0.6852415797773639, -0.6943429268335604, -0....   \n",
              "7983  [-0.6943429268335604, -0.6840874763785847, -0....   \n",
              "7984  [-0.6840874763785847, -0.6831086798251896, -0....   \n",
              "7985  [-0.6831086798251896, -0.6778348655598816, -0....   \n",
              "7986  [-0.6778348655598816, -0.6790693179294619, -0....   \n",
              "\n",
              "                                             Lag_medium  \\\n",
              "0                             [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "1            [0.0, 0.0, 0.0, 0.0, -0.10230979661544379]   \n",
              "2     [0.0, 0.0, 0.0, -0.10230979661544379, -0.10230...   \n",
              "3     [0.0, 0.0, -0.10230979661544379, -0.1023097966...   \n",
              "4     [0.0, -0.10230979661544379, -0.102309796615443...   \n",
              "...                                                 ...   \n",
              "7982  [-0.6933422169244923, -0.687878486910018, -0.6...   \n",
              "7983  [-0.687878486910018, -0.6852415797773639, -0.6...   \n",
              "7984  [-0.6852415797773639, -0.6943429268335604, -0....   \n",
              "7985  [-0.6943429268335604, -0.6840874763785847, -0....   \n",
              "7986  [-0.6840874763785847, -0.6831086798251896, -0....   \n",
              "\n",
              "                                               Lag_long  \n",
              "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.10...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1023097...  \n",
              "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.102309796615...  \n",
              "...                                                 ...  \n",
              "7982  [-0.7133929373653101, -0.7128670168291575, -0....  \n",
              "7983  [-0.7128670168291575, -0.704496114962062, -0.6...  \n",
              "7984  [-0.704496114962062, -0.6974619277910209, -0.6...  \n",
              "7985  [-0.6974619277910209, -0.6908660077334403, -0....  \n",
              "7986  [-0.6908660077334403, -0.6933422169244923, -0....  \n",
              "\n",
              "[7987 rows x 26 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in multiple_feature_columns:\n",
        "    try:\n",
        "        data[column] = data[column].apply(ast.literal_eval)\n",
        "    except Exception:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OdDuXzow20l",
        "outputId": "88285f47-248e-473a-a500-a7c9b2fd9b09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "well_name                False\n",
              "WELL_BORE_CODE           False\n",
              "date                     False\n",
              "prod_hrs                 False\n",
              "bhp                      False\n",
              "bht                      False\n",
              "dp_tubing                False\n",
              "AVG_ANNULUS_PRESS        False\n",
              "AVG_CHOKE_SIZE_P         False\n",
              "whp                      False\n",
              "wht                      False\n",
              "choke_size_percentage    False\n",
              "oil_vol                  False\n",
              "gas_vol                  False\n",
              "water_vol                False\n",
              "linear_regressor         False\n",
              "EMA_short                False\n",
              "EMA_medium               False\n",
              "EMA_long                 False\n",
              "Rolling_short            False\n",
              "Rolling_medium           False\n",
              "Rolling_long             False\n",
              "oil_rate                 False\n",
              "Lag_short                False\n",
              "Lag_medium               False\n",
              "Lag_long                 False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the numerical index of the column 'oil_rate'\n",
        "column_name = 'oil_rate'\n",
        "column_index = data[feature_columns].columns.get_loc(column_name)\n",
        "column_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1n-IMFYvNIta"
      },
      "outputs": [],
      "source": [
        "batch_size = 96\n",
        "days_window = 5\n",
        "predictions_days = 14\n",
        "training_gap = predictions_days + days_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "H77kZkM1lU5_",
        "outputId": "c9ef2650-18de-46b7-a650-93167d737eef"
      },
      "outputs": [],
      "source": [
        "# sequences = []\n",
        "# for well_name in data['well_name'].unique():\n",
        "#     well_data = data[data['well_name'] == well_name].sort_values(by='date').reset_index()\n",
        "#     for i in range(len(well_data) - training_gap + 1):\n",
        "#         single_features = np.array(well_data.iloc[i:i + days_window][single_feature_columns])\n",
        "#         multiple_features = np.array(well_data.iloc[i:i + days_window][multiple_feature_columns])\n",
        "#         multiple_flattened = []\n",
        "#         for k in multiple_features:\n",
        "#            flattened_list = [item for sublist in k for item in sublist]\n",
        "#            multiple_flattened.append(flattened_list)\n",
        "#         multiple_flattened = np.array(multiple_flattened)\n",
        "#         inputs = np.concatenate((single_features, multiple_flattened), axis=1)\n",
        "#         targets = well_data.iloc[i + days_window:i + days_window + predictions_days][target_column].values\n",
        "#         inputs_dates = list(well_data.iloc[i:i + days_window]['date'])\n",
        "#         targets_dates = list(well_data.iloc[i + days_window:i + days_window + predictions_days]['date'])\n",
        "#         inputs_index = list(well_data.iloc[i:i + days_window]['index'])\n",
        "#         targets_index = list(well_data.iloc[i + days_window:i + days_window + predictions_days]['index'])\n",
        "#         sequences.append((well_name, inputs_dates, targets_dates, inputs_index, targets_index, inputs, targets))\n",
        "#         if len(well_data.iloc[i:i + days_window + predictions_days]['well_name'].unique()) > 1:\n",
        "#           print('violation')\n",
        "\n",
        "# dataset = pd.DataFrame(sequences, columns=['well_name', 'inputs_dates', 'targets_dates', 'inputs_index', 'targets_index', 'inputs', 'targets', ])\n",
        "# dataset.to_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "fibAgggFAAhT"
      },
      "outputs": [],
      "source": [
        "train_size = 0.6\n",
        "val_size = 0.2\n",
        "test_size = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Nbxt8qRjwm4U"
      },
      "outputs": [],
      "source": [
        "test_size_param1 = test_size\n",
        "test_size_param2 = val_size / (1 - test_size_param1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLKPdjjBb6O",
        "outputId": "4f0bf1d7-932a-4cf3-a45b-231392ffaea5"
      },
      "outputs": [],
      "source": [
        "# train_wells = []\n",
        "# test_wells = []\n",
        "# for i in well_info.keys():\n",
        "#     well = dataset[dataset['well_name'] == i]\n",
        "#     train_set_length = int((train_size + val_size) * len(well))\n",
        "#     train_wells.append(well[:train_set_length + 1])\n",
        "#     test_set_length = int(test_size * len(well))\n",
        "#     test_wells.append(well[-test_set_length:])\n",
        "\n",
        "# # Flatten the lists of DataFrames\n",
        "# temp_data = pd.concat(train_wells).reset_index(drop=True)\n",
        "# data_test = pd.concat(test_wells).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# data_train, data_val = train_test_split(temp_data, test_size=test_size_param2, stratify=temp_data['well_name'], shuffle=True)\n",
        "\n",
        "# data_train.reset_index(drop=True, inplace=True)\n",
        "# data_val.reset_index(drop=True, inplace=True)\n",
        "# data_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# data_train.to_pickle(path + \"/data/Volve/data_train.pkl\")\n",
        "# data_val.to_pickle(path + \"/data/Volve/data_val.pkl\")\n",
        "# data_test.to_pickle(path + \"/data/Volve/data_test.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data = pd.read_pickle(path + \"/data/Volve/all_data.pkl\")\n",
        "data_train = pd.read_pickle(path + \"/data/Volve/data_train.pkl\")\n",
        "data_val = pd.read_pickle(path + \"/data/Volve/data_val.pkl\")\n",
        "data_test = pd.read_pickle(path + \"/data/Volve/data_test.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4730, 7), (1577, 7), (1573, 7))"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train.shape, data_val.shape, data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input/output gap is fine\n"
          ]
        }
      ],
      "source": [
        "check = True\n",
        "for i, j in well_info.items():\n",
        "    if len(all_data[all_data['well_name'] == i]) < 10:\n",
        "        print(\"The input/output gap is too high for well\", i)\n",
        "        check = False\n",
        "if check:\n",
        "    print(\"The input/output gap is fine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All datasets have all wells\n"
          ]
        }
      ],
      "source": [
        "check=True\n",
        "for i in [data_train, data_val, data_test]:\n",
        "    for j in well_info.keys():\n",
        "        if j not in set(list(i['well_name'])):\n",
        "            print(\"Some datasets do not have specific well\")\n",
        "            check = False\n",
        "            break\n",
        "if check:\n",
        "    print(\"All datasets have all wells\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5, 38), (14, 1))"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train['inputs'][0].shape, data_train['targets'][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mps'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "elif torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu' \n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "SZXwNYhTO9V_"
      },
      "outputs": [],
      "source": [
        "eval_interval = 500\n",
        "test_eval_interval = 500\n",
        "test_iterations = 7500\n",
        "warmup_steps = 6000 # hyper-parameters for hyperprameter finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "DOEruC1tFSSk"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_length, hidden_length, output_length, num_layers, dropout=0):\n",
        "        super().__init__()\n",
        "        self.input_length = input_length\n",
        "        self.hidden_length = hidden_length\n",
        "        self.output_length = output_length\n",
        "        self.init_hidden = nn.Parameter(torch.zeros(num_layers, 1, hidden_length))\n",
        "        self.init_cell = nn.Parameter(torch.zeros(num_layers, 1, hidden_length))\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_cell = nn.LSTM(self.input_length, self.hidden_length, self.num_layers, batch_first=True)\n",
        "        self.output_layer = nn.Linear(self.hidden_length, self.output_length)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, targets=None):\n",
        "        B, T, C = x.shape\n",
        "        init_hidden = self.init_hidden.repeat(1, B, 1)\n",
        "        init_cell = self.init_cell.repeat(1, B, 1)\n",
        "        cell_output, _ = self.lstm_cell(x, (init_hidden, init_cell))\n",
        "        cell_dropout = self.dropout(cell_output)\n",
        "        logits = self.output_layer(cell_dropout[:, -1, :])\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T = logits.shape\n",
        "            logits = logits.view(B*T)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.mse_loss(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def get_hyperparameters(self):\n",
        "        return {'input_length': self.input_length, 'hidden_length': self.hidden_length, 'output_length': self.output_length, 'num_layers': self.num_layers, 'dropout': self.dropout}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "dPVTSvxu1cVQ"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, sequences_df):\n",
        "        self.sequences_df = sequences_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.sequences_df.iloc[idx]['inputs']\n",
        "        targets = self.sequences_df.iloc[idx]['targets']\n",
        "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).squeeze()\n",
        "\n",
        "train_dataset = TimeSeriesDataset(data_train)\n",
        "val_dataset = TimeSeriesDataset(data_val)\n",
        "test_dataset = TimeSeriesDataset(data_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VisualizationTimeSeriesDataset(Dataset):\n",
        "    def __init__(self, sequences_df):\n",
        "        self.sequences_df = sequences_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.sequences_df.iloc[idx]['inputs']\n",
        "        targets = self.sequences_df.iloc[idx]['targets']\n",
        "        well_name = self.sequences_df.iloc[idx]['well_name']\n",
        "        inputs_dates = self.sequences_df.iloc[idx]['inputs_dates']\n",
        "        targets_dates = self.sequences_df.iloc[idx]['targets_dates']\n",
        "\n",
        "        return well_name, inputs_dates, targets_dates, torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).squeeze()\n",
        "\n",
        "visualization_test_dataset = VisualizationTimeSeriesDataset(data_test)\n",
        "\n",
        "visualization_test_loader = DataLoader(visualization_test_dataset, batch_size=int(len(test_dataset) / 50), shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_length = data_train['inputs'][0].shape[1]\n",
        "output_length = predictions_days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "0h7KW6y9PatC"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss(model): # Function to estimate train and val loss while training\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    out = {}\n",
        "    loaders = {'train': train_loader, 'val': val_loader}\n",
        "    for mode in ['train', 'val']:\n",
        "        losses = []\n",
        "        # Iterate over the DataLoader for a fixed number of batches\n",
        "        for X_batch, Y_batch in loaders[mode]:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            logits, loss = model(X_batch, Y_batch)  # Run inputs and expected outputs through model to get loss\n",
        "            losses.append(loss.item())  # Add value to losses list\n",
        "        out[mode] = torch.tensor(losses).mean().item()  # Get mean of losses tensor and save it\n",
        "    model.train()  # Put model back in train mode\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_params(model, optimizer, scheduler, name=\"\"): # function to save parameters, optimizer and scheduler states\n",
        "    config_path = path + r'/Models/Global/LSTM/Model/State/'\n",
        "    model_path = path + r'/Models/Global/LSTM/Model/Complete/'\n",
        "    if name != \"\":\n",
        "        name = f'{name}_'\n",
        "    torch.save(model.state_dict(), config_path + f'{name}state_params.pth') # to save parameters\n",
        "    torch.save(optimizer.state_dict(), config_path + f'{name}state_optimizer.pth') # to save optimizer state\n",
        "    torch.save(scheduler.state_dict(), config_path + f'{name}state_scheduler.pth') # to save scheduler states\n",
        "    torch.save(model, model_path + f'{name}complete_params.pth')\n",
        "    torch.save(optimizer, model_path + f'{name}complete_optimizer.pth') \n",
        "    torch.save(scheduler, model_path + f'{name}complete_scheduler.pth')\n",
        "\n",
        "def get_next_log_file(log_dir, prefix=\"training_run_\"):\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "        return os.path.join(log_dir, f\"{prefix}1.txt\")\n",
        "    existing_files = os.listdir(log_dir)\n",
        "    log_numbers = []\n",
        "    for filename in existing_files:\n",
        "        match = re.match(rf\"{prefix}(\\d+).txt\", filename)\n",
        "        if match:\n",
        "            log_numbers.append(int(match.group(1)))\n",
        "    if log_numbers:\n",
        "        next_number = max(log_numbers) + 1\n",
        "    else:\n",
        "        next_number = 1\n",
        "    return os.path.join(log_dir, f\"{prefix}{next_number}.txt\")\n",
        "\n",
        "def log_to_file(log_file, message):\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(message + '\\n')\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(mode, model):\n",
        "    loader_dict = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
        "    loader = loader_dict[mode]\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    test_losses = []\n",
        "    for X_batch, Y_batch in loader:\n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "        logits, loss = model(X_batch, Y_batch)  # Run inputs and expected outputs through model to get loss\n",
        "        test_losses.append(loss.item())  # Collect test loss\n",
        "        B, T = Y_batch.shape\n",
        "        Y_batch = Y_batch.view(B*T)\n",
        "        # Convert predictions and targets to NumPy arrays\n",
        "        all_preds.append(logits.cpu().numpy())  # .cpu() moves tensor to CPU, .numpy() converts to NumPy array\n",
        "        all_targets.append(Y_batch.cpu().numpy())\n",
        "    # Concatenate all predictions and targets\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    all_targets = np.concatenate(all_targets, axis=0)\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_metrics(all_targets, all_preds)\n",
        "    metrics['Loss'] = np.mean(test_losses)\n",
        "    print(f\"Metrics on {mode} set:\\n\")\n",
        "    print(f\"Loss is {metrics['Loss']:.4f}\")\n",
        "    print(f\"MAE is {metrics['MAE']:.4f}\")\n",
        "    print(f\"RMSE is {metrics['RMSE']:.4f}\")\n",
        "    print(f\"R² is {metrics['R2']:.4f}\")\n",
        "    print(\"\\n\")\n",
        "    return metrics\n",
        "\n",
        "@torch.no_grad()\n",
        "# Define an objective function for Optuna\n",
        "def objective(trial):\n",
        "    vector_length = trial.suggest_int('vector_length', 16, 2048, step=16)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 5) # maybe increase it to 6\n",
        "    dropout = trial.suggest_float('dropout', 0.1, 0.6)\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
        "    gamma = trial.suggest_float('gamma', 0.95, 0.99)\n",
        "    model = LSTM(input_length=input_length, hidden_length=vector_length, output_length=output_length, num_layers=num_layers, dropout=dropout).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # setting optimizer scheduler\n",
        "    train_loader_iter = iter(train_loader)\n",
        "    # Training loop\n",
        "    for i in range(test_iterations):\n",
        "        model.train()\n",
        "        if (i % test_eval_interval == 0 or i == test_iterations - 1):\n",
        "            losses = estimate_loss(model)\n",
        "            trial.report(losses['val'], i)\n",
        "            if i != 0:\n",
        "                scheduler.step()\n",
        "            # if i >= warmup_steps and trial.should_prune():\n",
        "            #     raise optuna.TrialPruned()\n",
        "        try:\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "        except StopIteration:\n",
        "            train_loader_iter = iter(train_loader)\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "            \n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "        logits, loss = model(X_batch, Y_batch)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    val_metrics = evaluate('val', model)\n",
        "    return val_metrics['Loss']\n",
        "\n",
        "def load_model(name=\"\"): \n",
        "    config_path = path + r'/Models/Global/LSTM/Model/Complete/'\n",
        "    if name != \"\":\n",
        "        name = f'{name}_'\n",
        "    model = torch.load(config_path + f'{name}complete_params.pth')\n",
        "    optimizer = torch.load(config_path + f'{name}complete_optimizer.pth')\n",
        "    scheduler = torch.load(config_path + f'{name}complete_scheduler.pth')\n",
        "    return model, optimizer, scheduler\n",
        "\n",
        "def get_oil_history(date, well_name):\n",
        "    well = data[data[\"well_name\"] == int(well_name)].reset_index(drop=True)\n",
        "    well = well[pd.to_datetime(well['date']) < date]\n",
        "    return well['oil_rate']\n",
        "\n",
        "def rename(config_path, model_path, old_name, new_name):\n",
        "    os.rename(config_path + f'{old_name}state_params.pth', config_path + f'{new_name}state_params.pth')\n",
        "    os.rename(config_path + f'{old_name}state_optimizer.pth', config_path + f'{new_name}state_optimizer.pth')\n",
        "    os.rename(config_path + f'{old_name}state_scheduler.pth', config_path + f'{new_name}state_scheduler.pth')\n",
        "    os.rename(model_path + f'{old_name}complete_params.pth', model_path + f'{new_name}complete_params.pth')\n",
        "    os.rename(model_path + f'{old_name}complete_optimizer.pth', model_path + f'{new_name}complete_optimizer.pth')\n",
        "    os.rename(model_path + f'{old_name}complete_scheduler.pth', model_path + f'{new_name}complete_scheduler.pth')\n",
        "    \n",
        "def label_model_files(old_name=\"\", new_name=\"\"):\n",
        "    if old_name != \"\":\n",
        "        old_name = f'{old_name}_'\n",
        "    if new_name != \"\":\n",
        "        new_name = f'{new_name}_'\n",
        "    config_path = path + r'/Models/Global/LSTM/Model/State/'\n",
        "    model_path = path + r'/Models/Global/LSTM/Model/Complete/'\n",
        "    if os.path.exists(config_path + f'{new_name}state_params.pth'):\n",
        "        try:\n",
        "            user_choice = int(input(\"File with new name already exists. Enter 1 if you want to overwrite the files. Otherwise press 2: \"))\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter 1 or 2.\")\n",
        "            return\n",
        "        if user_choice == 1:\n",
        "            try:\n",
        "                rename(config_path, model_path, old_name, new_name)\n",
        "                print(\"Files have been renamed successfully.\")\n",
        "            except FileNotFoundError:\n",
        "                print(\"One or more files not found.\")\n",
        "        elif user_choice == 2:\n",
        "            print(\"Operation cancelled by the user.\")\n",
        "        else:\n",
        "            print(\"Invalid choice. Operation cancelled.\")\n",
        "    else:\n",
        "        try:\n",
        "            rename(config_path, model_path, old_name, new_name)\n",
        "            print(\"Files have been renamed successfully.\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"One or more files not found.\")\n",
        "\n",
        "def predictions_with_history_graphs(model, visualization_loader, path):\n",
        "    pdf = PdfPages(path + \"/predictions_with_history.pdf\")\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for well_name, inputs_dates, targets_dates, X_batch, Y_batch in visualization_loader:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            choice = random.randint(0, len(X_batch) - 1)\n",
        "            X_batch = X_batch[choice].unsqueeze(0)\n",
        "            Y_batch = Y_batch[choice]\n",
        "            well_name = well_name[choice]\n",
        "            inputs_dates = [i[choice] for i in inputs_dates]\n",
        "            targets_dates = [i[choice] for i in targets_dates]\n",
        "\n",
        "            history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "            logits, loss = model(X_batch, Y_batch)\n",
        "            label = Y_batch.cpu().numpy()\n",
        "            prediction = logits.cpu().numpy()\n",
        "            rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "            # Plotting\n",
        "            forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(range(1, len(history) + 1), history, label='Input Values')\n",
        "            plt.plot(forecast_index, prediction, label='Forecasted Values')\n",
        "            plt.plot(forecast_index, label, label='Actual Values')\n",
        "            # Determine the interval for ticks to have approximately 10 ticks\n",
        "            tick_interval = max(10, round((len(history) + predictions_days + 1) / 10 / 10) * 10)\n",
        "            # Generate tick positions\n",
        "            tick_positions = np.arange(0, len(history) + predictions_days + 1, tick_interval)\n",
        "            tick_positions[0] = 1  # Start tick at 1 instead of 0\n",
        "\n",
        "            # Generate tick labels\n",
        "            tick_labels = tick_positions\n",
        "            plt.xticks(ticks=tick_positions, labels=tick_labels)\n",
        "            plt.axvline(x=len(history), color='r', linestyle='--', label='Forecast Start')\n",
        "            plt.xlabel('Day')\n",
        "            plt.ylabel('Value')\n",
        "            plt.title(f'Well: {well_name}, Loss: {loss:.4f}, RMSE = {rmse:.4f}')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            # Save the current figure to the PDF\n",
        "            pdf.savefig()\n",
        "            plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def predictions_graphs(model, visualization_loader, path):\n",
        "    pdf = PdfPages(path + \"/predictions.pdf\")\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for well_name, inputs_dates, targets_dates, X_batch, Y_batch in visualization_loader:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            choice = random.randint(0, len(X_batch) - 1)\n",
        "            X_batch = X_batch[choice].unsqueeze(0)\n",
        "            Y_batch = Y_batch[choice]\n",
        "            well_name = well_name[choice]\n",
        "            logits, loss = model(X_batch, Y_batch)\n",
        "            inputs = X_batch[0][:, column_index].cpu().numpy()\n",
        "            label = Y_batch.cpu().numpy()\n",
        "            prediction = logits.cpu().numpy()\n",
        "            rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "            # Plotting\n",
        "            forecast_index = range(len(inputs) + 1, len(inputs) + predictions_days + 1)\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(range(1, len(inputs) + 1), inputs, marker='o', label='Input Values')\n",
        "            plt.plot(forecast_index, prediction, marker='o', label='Forecasted Values')\n",
        "            plt.plot(forecast_index, label, marker='o', label='Actual Values')\n",
        "            plt.xticks(ticks=np.arange(1, len(inputs) + predictions_days + 1), labels=np.arange(1, len(inputs) + predictions_days + 1))\n",
        "            plt.axvline(x=len(inputs), color='r', linestyle='--', label='Forecast Start')\n",
        "            plt.xlabel('Day')\n",
        "            plt.ylabel('Value')\n",
        "            plt.title(f'Well: {well_name}, Loss: {loss:.4f}, RMSE: {rmse:.4f}')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            # Save the current figure to the PDF\n",
        "            pdf.savefig()\n",
        "            plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def all_predictions_graphs(model, data, data_test, path):\n",
        "    well_dataloaders = {}\n",
        "    pdf = PdfPages(path + \"/all_predictions.pdf\")\n",
        "    with torch.no_grad():\n",
        "        for well_name in well_info.keys():\n",
        "            well = data[data['well_name'] == well_name].reset_index(drop=True)\n",
        "            fig, ax = plt.subplots(figsize=(15, 6))\n",
        "            ax.plot(well.index, well['oil_rate'], label='Well Production')\n",
        "            ax.axvline(x=int((1 - test_size) * len(well) - days_window - 2), color='r', linestyle='--',)\n",
        "            ax.legend()\n",
        "            well_dataset = VisualizationTimeSeriesDataset(data_test[data_test['well_name'] == well_name].reset_index(drop=True))\n",
        "            well_dataloaders[well_name] = DataLoader(well_dataset, batch_size=1, shuffle=False)\n",
        "            total_loss = 0\n",
        "            total_rmse = 0\n",
        "            for _, inputs_dates, targets_dates, X_batch, Y_batch in well_dataloaders[well_name]:\n",
        "                inputs_dates = np.array(inputs_dates).T[0]\n",
        "                targets_dates = np.array(targets_dates).T[0]\n",
        "                history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "                logits, loss = model(X_batch, Y_batch)\n",
        "                label = Y_batch.cpu().numpy().reshape(-1)\n",
        "                prediction = logits.cpu().numpy()\n",
        "                rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "                total_loss += loss\n",
        "                total_rmse += rmse\n",
        "                forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "                ax.plot(forecast_index, prediction, label='Forecasted Values', color='y')\n",
        "                if i == 0:\n",
        "                    ax.legend()\n",
        "            avg_loss = total_loss / len(well_dataloaders[well_name]) \n",
        "            avg_rmse = total_rmse / len(well_dataloaders[well_name]) \n",
        "            ax.set_xlabel('Day')\n",
        "            ax.set_ylabel('Value')\n",
        "            ax.set_title(f'Well: {well_name}, Loss: {avg_loss:.4f}, RMSE = {avg_rmse:.4f}')\n",
        "            pdf.savefig(fig)\n",
        "            plt.close()\n",
        "    pdf.close()\n",
        "\n",
        "def all_predictions_with_gaps_graphs(model, data, data_test, path):\n",
        "    well_plots = {}\n",
        "    well_dataloaders = {}   \n",
        "    pdf = PdfPages(path + \"/all_predictions_with_gaps.pdf\")\n",
        "    with torch.no_grad():\n",
        "        for well_name in well_info.keys():\n",
        "            well = data[data['well_name'] == well_name].reset_index(drop=True)\n",
        "            fig, ax = plt.subplots(figsize=(15, 6))\n",
        "            ax.plot(well.index, well['oil_rate'], label='Well Production')\n",
        "            ax.axvline(x=int((1 - test_size) * len(well) - days_window - 2), color='r', linestyle='--',)\n",
        "            ax.legend()\n",
        "            well_dataset = VisualizationTimeSeriesDataset(data_test[data_test['well_name'] == well_name].reset_index(drop=True))\n",
        "            well_dataloaders[well_name] = DataLoader(well_dataset, batch_size=1, shuffle=False)\n",
        "            total_loss = 0\n",
        "            total_rmse = 0\n",
        "            for i, (_, inputs_dates, targets_dates, X_batch, Y_batch) in enumerate(well_dataloaders[well_name]):\n",
        "                if i % predictions_days == 0 or i == len(well_dataloaders[well_name]) - 1:\n",
        "                    inputs_dates = np.array(inputs_dates).T[0]\n",
        "                    targets_dates = np.array(targets_dates).T[0]\n",
        "                    history = get_oil_history(pd.to_datetime(targets_dates[0]), well_name)\n",
        "                    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "                    logits, loss = model(X_batch, Y_batch)\n",
        "                    label = Y_batch.cpu().numpy().reshape(-1)\n",
        "                    prediction = logits.cpu().numpy()\n",
        "                    rmse = np.sqrt(mean_squared_error(label, prediction))\n",
        "                    total_loss += loss\n",
        "                    total_rmse += rmse\n",
        "                    forecast_index = range(len(history) + 1, len(history) + predictions_days + 1)\n",
        "                    ax.plot(forecast_index, prediction, label='Forecasted Values', color='y')\n",
        "                    if i == 0:\n",
        "                        ax.legend()\n",
        "            avg_loss = total_loss / len(well_dataloaders[well_name]) \n",
        "            avg_rmse = total_rmse / len(well_dataloaders[well_name]) \n",
        "            ax.set_xlabel('Day')\n",
        "            ax.set_ylabel('Value')\n",
        "            ax.set_title(f'Well: {well_name}, Loss: {avg_loss:.4f}, RMSE = {avg_rmse:.4f}')\n",
        "            pdf.savefig(fig)\n",
        "            plt.close()\n",
        "    pdf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-07-10 15:10:24,804] A new study created in memory with name: no-name-9e7184b8-4ecb-4e1f-9052-7b364ed21a05\n",
            "[W 2024-07-10 15:10:32,291] Trial 0 failed with parameters: {'vector_length': 1664, 'num_layers': 3, 'dropout': 0.4907871574431366, 'lr': 0.00021124431751369142, 'gamma': 0.9844411121769495} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/amrtamer/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/var/folders/d8/xf5yjrpn5zvd1j56c42jys2w0000gn/T/ipykernel_806/3476955214.py\", line 114, in objective\n",
            "    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
            "KeyboardInterrupt\n",
            "[W 2024-07-10 15:10:32,295] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a study and optimize the objective function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[65], line 114\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    111\u001b[0m     train_loader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m    112\u001b[0m     X_batch, Y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_loader_iter)\n\u001b[0;32m--> 114\u001b[0m X_batch, Y_batch \u001b[38;5;241m=\u001b[39m \u001b[43mX_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, Y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    115\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m model(X_batch, Y_batch)\n\u001b[1;32m    116\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create a study and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "print('Best hyperparameters:', best_params)\n",
        "\n",
        "# Train the final model with the best hyperparameters\n",
        "vector_length = best_params['vector_length']\n",
        "num_layers = best_params['num_layers']\n",
        "dropout = best_params['dropout']\n",
        "lr = best_params['lr']\n",
        "gamma = best_params['gamma']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_length = 1024\n",
        "num_layers = 3\n",
        "dropout = 0.19057012152026273\n",
        "lr = 0.0001911914637460164\n",
        "gamma = 0.9806898435934219 # 2nd best results on val set full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_length = 336\n",
        "num_layers = 3\n",
        "dropout = 0.12831089625320793\n",
        "lr = 0.0003724263259631224\n",
        "gamma = 0.978770138138513 # best results on val set full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYRS6z8uI3Nr",
        "outputId": "9135626b-446a-427a-8dd0-f4a54073a157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of input is: torch.Size([96, 5, 38]) and the shape of the output is torch.Size([96, 14])\n",
            "The output shape of the LSTM will be (1344,) and a an example initial loss is 1.220238447189331\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "context_size = days_window - 1\n",
        "X_batch, Y_batch = next(iter(train_loader))\n",
        "X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "print(f'The shape of input is: {X_batch.shape} and the shape of the output is {Y_batch.shape}')\n",
        "model = LSTM(input_length=input_length, hidden_length=vector_length, output_length=output_length, num_layers=num_layers, dropout=dropout).to(device)\n",
        "output, loss = model(X_batch, Y_batch)\n",
        "print(f'The output shape of the LSTM will be {tuple(output.shape)} and a an example initial loss is {loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "0eSC24XWOoMf"
      },
      "outputs": [],
      "source": [
        "model = LSTM(input_length=input_length, hidden_length=vector_length, output_length=output_length, num_layers=num_layers, dropout=dropout).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) # setting optimizer scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "iterations = 30000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o-CnvgwmOjRW",
        "outputId": "196cb846-ee96-47a5-a867-c1a1dac00309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0: train loss 1.1364, val loss 1.0948\n",
            "step 500: train loss 0.0552, val loss 0.0535\n",
            "step 1000: train loss 0.0515, val loss 0.0535\n",
            "step 1500: train loss 0.0449, val loss 0.0485\n",
            "step 2000: train loss 0.0427, val loss 0.0483\n",
            "step 2500: train loss 0.0359, val loss 0.0467\n",
            "step 3000: train loss 0.0293, val loss 0.0433\n",
            "step 3500: train loss 0.0267, val loss 0.0392\n",
            "step 4000: train loss 0.0218, val loss 0.0347\n",
            "step 4500: train loss 0.0191, val loss 0.0335\n",
            "step 5000: train loss 0.0168, val loss 0.0301\n",
            "step 5500: train loss 0.0160, val loss 0.0296\n",
            "step 6000: train loss 0.0145, val loss 0.0307\n",
            "step 6500: train loss 0.0128, val loss 0.0271\n",
            "step 7000: train loss 0.0120, val loss 0.0278\n",
            "step 7500: train loss 0.0120, val loss 0.0261\n",
            "step 8000: train loss 0.0100, val loss 0.0241\n",
            "step 8500: train loss 0.0097, val loss 0.0250\n",
            "step 9000: train loss 0.0088, val loss 0.0229\n",
            "step 9500: train loss 0.0085, val loss 0.0239\n",
            "step 10000: train loss 0.0076, val loss 0.0232\n",
            "step 10500: train loss 0.0073, val loss 0.0243\n",
            "step 11000: train loss 0.0070, val loss 0.0220\n",
            "step 11500: train loss 0.0088, val loss 0.0243\n",
            "step 12000: train loss 0.0064, val loss 0.0218\n",
            "step 12500: train loss 0.0059, val loss 0.0215\n",
            "step 13000: train loss 0.0058, val loss 0.0217\n",
            "step 13500: train loss 0.0058, val loss 0.0219\n",
            "step 14000: train loss 0.0054, val loss 0.0232\n",
            "step 14500: train loss 0.0068, val loss 0.0253\n",
            "step 15000: train loss 0.0046, val loss 0.0221\n",
            "step 15500: train loss 0.0048, val loss 0.0222\n",
            "Training ended manually by user.\n",
            "\n",
            "Training is complete\n"
          ]
        }
      ],
      "source": [
        "train_loader_iter = iter(train_loader)\n",
        "log_file = get_next_log_file(path + \"/Models/Global/LSTM/Logs\")\n",
        "\n",
        "log_message = f\"Hyperparameters: Vector Length = {vector_length}, Number of Layers = {num_layers}, Dropout = {dropout}, Learning Rate = {lr}, Scheduler Gamma = {gamma}\\n\"\n",
        "\n",
        "log_to_file(log_file, log_message)\n",
        "model.train()\n",
        "try:\n",
        "    for i in range(iterations):\n",
        "        model.train()  # Set model to training mode\n",
        "        if i % eval_interval == 0 or i == iterations - 1:\n",
        "            # Evaluate and save model parameters periodically\n",
        "            save_params(model, optimizer, scheduler, 'current')  # Saving parameters\n",
        "            model.eval()\n",
        "            losses = estimate_loss(model)  # Estimate train and val loss\n",
        "            model.train()\n",
        "            log_message = f\"step {i}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\"\n",
        "            print(log_message)\n",
        "            log_to_file(log_file, log_message)  # Log to file\n",
        "            if i != 0:\n",
        "                scheduler.step()  # Perform scheduler step\n",
        "        try:\n",
        "            # Get the next batch\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "        except StopIteration:\n",
        "            # Reinitialize the iterator if the DataLoader is exhausted\n",
        "            train_loader_iter = iter(train_loader)\n",
        "            X_batch, Y_batch = next(train_loader_iter)\n",
        "\n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "        logits, loss = model(X_batch, Y_batch)  # Run inputs and expected outputs through model\n",
        "        optimizer.zero_grad(set_to_none=True)  # Set gradients to 0 (to ensure gradients don't explode)\n",
        "        loss.backward()  # Perform backpropagation\n",
        "        optimizer.step()  # Perform parameter adjustment\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Training ended manually by user.\\n\")\n",
        "model.eval()\n",
        "print(\"Training is complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on train set:\n",
            "\n",
            "Loss is 0.0046\n",
            "MAE is 0.0421\n",
            "RMSE is 0.0680\n",
            "R² is 0.9958\n",
            "\n",
            "\n",
            "Metrics on val set:\n",
            "\n",
            "Loss is 0.0217\n",
            "MAE is 0.0762\n",
            "RMSE is 0.1488\n",
            "R² is 0.9788\n",
            "\n",
            "\n",
            "Metrics on test set:\n",
            "\n",
            "Loss is 0.0125\n",
            "MAE is 0.0874\n",
            "RMSE is 0.1123\n",
            "R² is 0.4735\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "train_metrics = evaluate('train', model)\n",
        "val_metrics = evaluate('val', model)\n",
        "test_metrics = evaluate('test', model)\n",
        "log_to_file(log_file, str(f\"\\nMetrics = {test_metrics}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files have been renamed successfully.\n"
          ]
        }
      ],
      "source": [
        "label_model_files(old_name='hi', new_name='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "model, optimizer, scheduler = load_model('best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on test set:\n",
            "\n",
            "Loss is 0.0136\n",
            "MAE is 0.0890\n",
            "RMSE is 0.1168\n",
            "R² is 0.4306\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions_with_history_graphs(model, visualization_test_loader, path + \"/Models/Global/LSTM/Graphs\")\n",
        "predictions_graphs(model, visualization_test_loader, path + \"/Models/Global/LSTM/Graphs\")\n",
        "all_predictions_graphs(model, data, data_test, path + \"/Models/Global/LSTM/Graphs\")\n",
        "all_predictions_with_gaps_graphs(model, data, data_test, path + \"/Models/Global/LSTM/Graphs\")\n",
        "test_metrics = evaluate('test', model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8qFMjwdKPpn"
      },
      "source": [
        "1. add time elapsed column\n",
        "2. find a way to fill gaps\n",
        "3. overfitting (add dropout)\n",
        "5. deal with wht and whp\n",
        "4. load model\n",
        "evaulatiob=n on all e`xamples\n",
        "6. Check if you need to further nromalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "should i adjust the data so that the lags are adjusted as if it hasnt seen it previously"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
