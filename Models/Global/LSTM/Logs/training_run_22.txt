Hyperparameters: Vector Length = 336, Number of Layers = 3, Dropout = 0.12831089625320793, Learning Rate = 0.0003724263259631224, Scheduler Gamma = 0.978770138138513

step 0: train loss 1.1399, val loss 1.0684
step 500: train loss 0.0561, val loss 0.0561
step 1000: train loss 0.0497, val loss 0.0525
step 1500: train loss 0.0444, val loss 0.0479
step 2000: train loss 0.0378, val loss 0.0448
step 2500: train loss 0.0351, val loss 0.0443
step 3000: train loss 0.0320, val loss 0.0419
step 3500: train loss 0.0259, val loss 0.0376
step 4000: train loss 0.0219, val loss 0.0345
step 4500: train loss 0.0203, val loss 0.0346
step 5000: train loss 0.0167, val loss 0.0311
step 5500: train loss 0.0187, val loss 0.0346
step 6000: train loss 0.0142, val loss 0.0284
step 6500: train loss 0.0130, val loss 0.0270
step 7000: train loss 0.0129, val loss 0.0293
step 7500: train loss 0.0108, val loss 0.0259
step 8000: train loss 0.0108, val loss 0.0275
step 8500: train loss 0.0101, val loss 0.0274
step 9000: train loss 0.0089, val loss 0.0255
step 9500: train loss 0.0089, val loss 0.0263
step 10000: train loss 0.0082, val loss 0.0265
step 10500: train loss 0.0076, val loss 0.0253
step 11000: train loss 0.0075, val loss 0.0250
step 11500: train loss 0.0069, val loss 0.0252
step 12000: train loss 0.0072, val loss 0.0253
step 12500: train loss 0.0066, val loss 0.0263
step 13000: train loss 0.0070, val loss 0.0262
step 13500: train loss 0.0056, val loss 0.0246
step 14000: train loss 0.0061, val loss 0.0255
step 14500: train loss 0.0051, val loss 0.0249
step 15000: train loss 0.0062, val loss 0.0268
step 15500: train loss 0.0047, val loss 0.0267
