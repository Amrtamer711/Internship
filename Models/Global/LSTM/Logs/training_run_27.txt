Hyperparameters: Vector Length = 336, Number of Layers = 3, Dropout = 0.12831089625320793, Learning Rate = 0.0003724263259631224, Scheduler Gamma = 0.978770138138513

step 0: train loss 1.1340, val loss 1.1203
step 500: train loss 0.0579, val loss 0.0555
step 1000: train loss 0.0494, val loss 0.0497
step 1500: train loss 0.0428, val loss 0.0457
step 2000: train loss 0.0392, val loss 0.0428
step 2500: train loss 0.0392, val loss 0.0457
step 3000: train loss 0.0292, val loss 0.0396
step 3500: train loss 0.0248, val loss 0.0383
step 4000: train loss 0.0198, val loss 0.0313
step 4500: train loss 0.0182, val loss 0.0333
step 5000: train loss 0.0181, val loss 0.0321
step 5500: train loss 0.0146, val loss 0.0286
step 6000: train loss 0.0140, val loss 0.0277
step 6500: train loss 0.0158, val loss 0.0295
step 7000: train loss 0.0128, val loss 0.0281
step 7500: train loss 0.0112, val loss 0.0268
step 8000: train loss 0.0099, val loss 0.0257
step 8500: train loss 0.0090, val loss 0.0262
step 9000: train loss 0.0089, val loss 0.0247
step 9500: train loss 0.0089, val loss 0.0265
step 10000: train loss 0.0101, val loss 0.0276
step 10500: train loss 0.0077, val loss 0.0246
step 11000: train loss 0.0071, val loss 0.0248
step 11500: train loss 0.0065, val loss 0.0247
step 12000: train loss 0.0063, val loss 0.0261
step 12500: train loss 0.0061, val loss 0.0254
step 13000: train loss 0.0060, val loss 0.0255
step 13500: train loss 0.0054, val loss 0.0253
step 14000: train loss 0.0055, val loss 0.0250
step 14500: train loss 0.0049, val loss 0.0259
step 15000: train loss 0.0046, val loss 0.0239
step 15500: train loss 0.0046, val loss 0.0244
step 16000: train loss 0.0043, val loss 0.0236
step 16500: train loss 0.0043, val loss 0.0257
step 17000: train loss 0.0043, val loss 0.0248
step 17500: train loss 0.0041, val loss 0.0241
step 18000: train loss 0.0038, val loss 0.0241
step 18500: train loss 0.0038, val loss 0.0249
step 19000: train loss 0.0046, val loss 0.0247

Metrics = {'MAE': 0.10693267, 'RMSE': 0.14771904, 'R2': 0.08888837662343563, 'Loss': 0.0221113235456869}
